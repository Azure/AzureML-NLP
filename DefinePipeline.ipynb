{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "gather": {
          "logged": 1663358373030
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SDK version: 1.45.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.core.runconfig import JarLibrary\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.core.databricks import PyPiLibrary\n",
        "\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import DatabricksStep, PythonScriptStep\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "gather": {
          "logged": 1663358373831
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "distributeddeeplearningqmx\n",
            "deep-learning-challenge\n",
            "westus2\n",
            "3df1840f-dd4b-4f54-a831-e20536439b3a\n"
          ]
        }
      ],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "gather": {
          "logged": 1663358374418
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datastore workspaceblobstore will be used\n"
          ]
        }
      ],
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\n",
        "\n",
        "def_blob_store = ws.get_default_datastore()\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "gather": {
          "logged": 1663358375082
        }
      },
      "outputs": [],
      "source": [
        "source_directory = \"./project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "gather": {
          "logged": 1663358376307
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cluster_name = \"gpucluster\"\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%writefile conda_dependencies.yml\n",
        "# \n",
        "# channels:\n",
        "#   - pytorch\n",
        "#   - anaconda\n",
        "#   - conda-forge\n",
        "# dependencies:\n",
        "#   - python=3.7\n",
        "#   - pip=21.1.2\n",
        "#   - pip:\n",
        "#       - azureml-core==1.44.0\n",
        "#       - azureml-mlflow==1.44.0\n",
        "#       - azureml-automl-core==1.44.0\n",
        "#       - azureml-automl-dnn-nlp==1.44.0\n",
        "#       - azureml-responsibleai==1.44.0\n",
        "#       - azureml-automl-runtime==1.44.0\n",
        "#       - azureml-train-automl-client==1.44.0\n",
        "#       - azureml-train-automl-runtime==1.44.0\n",
        "#       - horovod==0.21.3\n",
        "#   - numpy~=1.18.5\n",
        "#   - pandas~=1.1.5\n",
        "#   - scikit-learn~=0.22.1\n",
        "#   - pytorch==1.7.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "gather": {
          "logged": 1663358376576
        }
      },
      "outputs": [],
      "source": [
        "env = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN-Text-GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to get larger datasets: http://jmcauley.ucsd.edu/data/amazon/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-10-11 21:12:03--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4669048 (4.5M) [application/x-gzip]\n",
            "Saving to: ‘data/reviews_Automotive_5.json.gz.1’\n",
            "\n",
            "          reviews_A   0%[                    ]       0  --.-KB/s               ^C\n"
          ]
        }
      ],
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz -P data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20473, 9)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "pdf_main = getDF('data/reviews_Automotive_5.json.gz')\n",
        "pdf_main.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A3F73SC1LY51OO</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>Alan Montgomery</td>\n",
              "      <td>[4, 4]</td>\n",
              "      <td>I needed a set of jumper cables for my new car...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Work Well - Should Have Bought Longer Ones</td>\n",
              "      <td>1313539200</td>\n",
              "      <td>08 17, 2011</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A20S66SKYXULG2</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>alphonse</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>These long cables work fine for my truck, but ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Okay long cables</td>\n",
              "      <td>1315094400</td>\n",
              "      <td>09 4, 2011</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2I8LFSN2IS5EO</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>Chris</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>Can't comment much on these since they have no...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Looks and feels heavy Duty</td>\n",
              "      <td>1374710400</td>\n",
              "      <td>07 25, 2013</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3GT2EWQSO45ZG</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>DeusEx</td>\n",
              "      <td>[19, 19]</td>\n",
              "      <td>I absolutley love Amazon!!!  For the price of ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Excellent choice for Jumper Cables!!!</td>\n",
              "      <td>1292889600</td>\n",
              "      <td>12 21, 2010</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A3ESWJPAVRPWB4</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>E. Hernandez</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>I purchased the 12' feet long cable set and th...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Excellent, High Quality Starter Cables</td>\n",
              "      <td>1341360000</td>\n",
              "      <td>07 4, 2012</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID        asin     reviewerName   helpful  \\\n",
              "0  A3F73SC1LY51OO  B00002243X  Alan Montgomery    [4, 4]   \n",
              "1  A20S66SKYXULG2  B00002243X         alphonse    [1, 1]   \n",
              "2  A2I8LFSN2IS5EO  B00002243X            Chris    [0, 0]   \n",
              "3  A3GT2EWQSO45ZG  B00002243X           DeusEx  [19, 19]   \n",
              "4  A3ESWJPAVRPWB4  B00002243X     E. Hernandez    [0, 0]   \n",
              "\n",
              "                                          reviewText  overall  \\\n",
              "0  I needed a set of jumper cables for my new car...      5.0   \n",
              "1  These long cables work fine for my truck, but ...      4.0   \n",
              "2  Can't comment much on these since they have no...      5.0   \n",
              "3  I absolutley love Amazon!!!  For the price of ...      5.0   \n",
              "4  I purchased the 12' feet long cable set and th...      5.0   \n",
              "\n",
              "                                      summary  unixReviewTime   reviewTime  \\\n",
              "0  Work Well - Should Have Bought Longer Ones      1313539200  08 17, 2011   \n",
              "1                            Okay long cables      1315094400   09 4, 2011   \n",
              "2                  Looks and feels heavy Duty      1374710400  07 25, 2013   \n",
              "3       Excellent choice for Jumper Cables!!!      1292889600  12 21, 2010   \n",
              "4      Excellent, High Quality Starter Cables      1341360000   07 4, 2012   \n",
              "\n",
              "   sentiment  \n",
              "0        1.0  \n",
              "1        1.0  \n",
              "2        1.0  \n",
              "3        1.0  \n",
              "4        1.0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_main.loc[pdf_main['overall'] >= 4, 'sentiment'] = 1\n",
        "pdf_main.loc[pdf_main['overall'] < 3, 'sentiment'] = 0\n",
        "\n",
        "pdf_main.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_datasets(pdf_target_training, label = 'sentiment'):\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(pdf_target_training.drop(label, axis=1), pdf_target_training[label],\n",
        "                                                        stratify=pdf_target_training[label],\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.20)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        "                                                        stratify=y_test_val,\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.5)\n",
        "    pdf_X_train = X_train\n",
        "    pdf_X_val = X_val\n",
        "    pdf_X_test = X_test\n",
        "\n",
        "    pdf_X_train['sentiment'] = y_train\n",
        "    pdf_X_val['sentiment'] = y_val\n",
        "    pdf_X_test['sentiment'] = y_test\n",
        "    \n",
        "    print(f'Total records for: \"pdf_X_train\": [{pdf_X_train.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_val\": [{pdf_X_val.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_test\": [{pdf_X_test.shape[0]}]')\n",
        "    \n",
        "    return pdf_X_train, pdf_X_val, pdf_X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records for: \"pdf_X_train\": [15234]\n",
            "Total records for: \"pdf_X_val\": [1904]\n",
            "Total records for: \"pdf_X_test\": [1905]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "pdf_train, pdf_val, pdf_test = generate_datasets(pdf_main[['reviewText', 'sentiment']].dropna(), 'sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to nlp/6bf0eb7b-8b16-49cf-a32b-8dba72c46ed4/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to nlp/251d08d9-3ace-4610-b249-1fb10e2b0774/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to nlp/474207a5-0ffc-42aa-9ffe-c5fe7c0a651f/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ]
        }
      ],
      "source": [
        "def_blob_store = ws.get_default_datastore()\n",
        "\n",
        "ds_train_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_train, target=(def_blob_store, 'nlp'), name=\"train_set\", description=\"Small amazon review for sentiment analysis [train set]\")\n",
        "ds_val_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_val, target=(def_blob_store, 'nlp'), name=\"val_set\", description=\"Small amazon review for sentiment analysis [val set]\")\n",
        "ds_test_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_test, target=(def_blob_store, 'nlp'), name=\"test_set\", description=\"Small amazon review for sentiment analysis [test set]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "gather": {
          "logged": 1663358376771
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "args = [\n",
        "        '--target-name', 'sentiment',\n",
        "        '--training-dataset', ds_train_set.as_named_input('train_set'),\n",
        "        '--val-dataset', ds_val_set.as_named_input('val_set'),\n",
        "        '--test-dataset', ds_test_set.as_named_input('test_set'),\n",
        "        '--text-field', 'reviewText',\n",
        "        '--is-test', 1,\n",
        "        '--is-final', 0,\n",
        "        '--is-jump', 1,\n",
        "        '--is-local', 0,\n",
        "        '--evaluation-strategy', \"epoch\"\n",
        "]\n",
        "\n",
        "src = ScriptRunConfig(source_directory=source_directory,\n",
        "                      script='train_transformer.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=env)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "gather": {
          "logged": 1663358376946
        }
      },
      "outputs": [],
      "source": [
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "ps = RandomParameterSampling(\n",
        "    {\n",
        "        '--base-checkpoint': choice(\"bert-base-cased\"), #, \"bert-base-cased\"), # , \"bert-large-cased\", \"microsoft/deberta-v3-small\", \"distilbert-base-uncased\", \"bert-base-uncased\"),\n",
        "        '--batch-size': choice(8),\n",
        "        '--no-epochs': choice(4),\n",
        "        '--learning-rate': choice(5.5e-5), # 5e-5, 4.5e-5, 4e-5, 5.5e-5, 6e-5, 3.5e-5, 6.5e-5)\n",
        "        '--warmup-steps': choice(0),\n",
        "        '--weight-decay': choice(0.0),\n",
        "        '--adam-beta1': choice(0.9),\n",
        "        '--adam-beta2': choice(0.999),\n",
        "        '--adam-epsilon': choice(1e-8)\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "gather": {
          "logged": 1663358377133
        }
      },
      "outputs": [],
      "source": [
        "policy = BanditPolicy(evaluation_interval=5, slack_factor=0.1)\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                     hyperparameter_sampling=ps,\n",
        "                                     policy=policy,\n",
        "                                     primary_metric_name='eval_f1_weighted',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs=20,\n",
        "                                     max_concurrent_runs=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "gather": {
          "logged": 1663358377335
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n",
        "\n",
        "hd_step_name='HyperDrive_Step'\n",
        "hd_step = HyperDriveStep(\n",
        "    name=hd_step_name,\n",
        "    hyperdrive_config=hyperdrive_config,\n",
        "    allow_reuse=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "gather": {
          "logged": 1663358377523
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "reg_compute_target = ComputeTarget(workspace=ws, name=\"cpu-cluster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "env_cpu = Environment.get(workspace=ws, name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "gather": {
          "logged": 1663359576047
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=reg_compute_target,\n",
        "                                       arguments=['--is-test', 0,\n",
        "                                                  '--test-run-id', '',\n",
        "                                                  '--metric-name', 'test_f1_weighted',\n",
        "                                                  '--second-metric', 'test_f1',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "register_model_step.run_after(hd_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "dep_compute_target = ComputeTarget(workspace=ws, name=\"small-cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "gather": {
          "logged": 1663360692280
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# conda_dep = CondaDependencies()\n",
        "# conda_dep.add_pip_package(\"azureml-sdk\")\n",
        "# conda_dep.env\n",
        "\n",
        "rcfg = RunConfiguration() # conda_dependencies=conda_dep)\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=dep_compute_target,\n",
        "                                       arguments=['--endpoint-name', 'sentiment-endpoint',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "deploy_model_step.run_after(register_model_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "gather": {
          "logged": 1663360693237
        }
      },
      "outputs": [],
      "source": [
        "exp = Experiment(workspace=ws, name='transformer_hp')\n",
        "steps = [deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created step Deploy_Latest_Model [12d6f5c5][fc20ff32-9528-4819-85b1-2be15349e580], (This step will run and generate new outputs)\n",
            "Created step Register_Best_Model [32ded5af][b3a879d9-adf4-4008-97b2-fa3429037228], (This step will run and generate new outputs)\n",
            "Created step HyperDrive_Step [aa82c1f5][aa6a2b3b-fafa-4f95-9597-b9715d2d5f0f], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun acb0159a-7a86-40ca-8b98-a7e65e4955e8\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/acb0159a-7a86-40ca-8b98-a7e65e4955e8?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/deep-learning-challenge/workspaces/distributeddeeplearningqmx&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>transformer_hp</td><td>acb0159a-7a86-40ca-8b98-a7e65e4955e8</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/acb0159a-7a86-40ca-8b98-a7e65e4955e8?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/deep-learning-challenge/workspaces/distributeddeeplearningqmx&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: transformer_hp,\n",
              "Id: acb0159a-7a86-40ca-8b98-a7e65e4955e8,\n",
              "Type: azureml.PipelineRun,\n",
              "Status: Preparing)"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.submit(exp.name, credential_passthrough=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>sentiment_classifier</td><td><a href=\"https://ml.azure.com/pipelines/4df53da8-9567-4a8f-b011-aa04d12bb084?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/deep-learning-challenge/workspaces/distributeddeeplearningqmx\" target=\"_blank\" rel=\"noopener\">4df53da8-9567-4a8f-b011-aa04d12bb084</a></td><td>Active</td><td><a href=\"https://westus2.api.azureml.ms/pipelines/v1.0/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourceGroups/deep-learning-challenge/providers/Microsoft.MachineLearningServices/workspaces/distributeddeeplearningqmx/PipelineRuns/PipelineSubmit/4df53da8-9567-4a8f-b011-aa04d12bb084\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
            ],
            "text/plain": [
              "Pipeline(Name: sentiment_classifier,\n",
              "Id: 4df53da8-9567-4a8f-b011-aa04d12bb084,\n",
              "Status: Active,\n",
              "Endpoint: https://westus2.api.azureml.ms/pipelines/v1.0/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourceGroups/deep-learning-challenge/providers/Microsoft.MachineLearningServices/workspaces/distributeddeeplearningqmx/PipelineRuns/PipelineSubmit/4df53da8-9567-4a8f-b011-aa04d12bb084)"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.publish(name=\"sentiment_classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "timenow = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "\n",
        "pipeline_name = 'ECD-horizon-' + timenow + \"-Pipeline\"\n",
        "print(pipeline_name)\n",
        "\n",
        "published_pipeline = pipeline.publish(\n",
        "    name=pipeline_name, \n",
        "    description=pipeline_name)\n",
        "print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('azureml_py38')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
