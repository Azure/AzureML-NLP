{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1663358373030
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SDK version: 1.40.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.core.runconfig import JarLibrary\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.core.databricks import PyPiLibrary\n",
        "\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import DatabricksStep, PythonScriptStep\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1663358373831
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scsccps-dsai-lab-dev-mlw\n",
            "scsc-dsai-lab-dev-rg\n",
            "canadacentral\n",
            "580c0ee7-91da-497a-b61b-1a12caecdd19\n"
          ]
        }
      ],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1663358374031
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compute target Databricks already exists\n"
          ]
        }
      ],
      "source": [
        "db_compute_name = \"Databricks\" # Databricks compute name\n",
        "\n",
        "databricks_compute = DatabricksCompute(workspace=ws, name=db_compute_name)\n",
        "print('Compute target {} already exists'.format(db_compute_name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1663358374418
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datastore workspaceblobstore will be used\n"
          ]
        }
      ],
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\n",
        "\n",
        "def_blob_store = ws.get_default_datastore()\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1663358374625
        }
      },
      "outputs": [],
      "source": [
        "# step_output_train = PipelineData(\"output_train\", datastore=def_blob_store)\n",
        "# step_output_validation = PipelineData(\"output_validation\", datastore=def_blob_store)\n",
        "# step_output_test = PipelineData(\"output_test\", datastore=def_blob_store)\n",
        "# step_output_temporal_test = PipelineData(\"output_temporal_test\", datastore=def_blob_store)\n",
        "# \n",
        "# ds_step_output_train = step_output_train.as_dataset()\n",
        "# ds_step_output_validation = step_output_validation.as_dataset()\n",
        "# ds_step_output_test = step_output_test.as_dataset()\n",
        "# ds_step_output_temporal_test = step_output_temporal_test.as_dataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1663358374847
        }
      },
      "outputs": [],
      "source": [
        "# ds_base_dataframe = Dataset.get_by_name(ws, 'base_dataframe')\n",
        "# print(ds_base_dataframe.tags)\n",
        "# ds_base_dataframe.tags['temporal_date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1663358375082
        }
      },
      "outputs": [],
      "source": [
        "source_directory = \"./project\"\n",
        "\n",
        "preprocessing_script_name = \"preprocessing_factory.py\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1663358375383
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "base_file_name = \"ecd_tickets_cleaned_2_more_withNewLongDescs\"\n",
        "cluster_id = \"0916-144740-3ql755ed\" # Databricks \"AML Cluster do not use please\"\n",
        "\n",
        "adb_prep_base = DatabricksStep(\n",
        "    name=\"ADB_Prep_Base\",\n",
        "    compute_target=databricks_compute,\n",
        "    existing_cluster_id=cluster_id,\n",
        "    python_script_params=['--base_file_name', base_file_name\n",
        "                          ],\n",
        "    permit_cluster_restart=True,\n",
        "    pypi_libraries=[],\n",
        "    python_script_name='prep_base_dataset_from_SQL.py',\n",
        "    source_directory=source_directory,\n",
        "    run_name='ADB_Prep_Base',\n",
        "    allow_reuse=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1663358375611
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "cut_off_for_training = '201808'\n",
        "valid_classes_period = '202105'\n",
        "cut_off_date_recent = '202107'\n",
        "temporal_test_date = '202209' # last training date. Keep it 1 month behind current date (or keep present date)\n",
        "logic_v = '4'\n",
        "top_n = '120'\n",
        "base_file_name = \"ecd_tickets_cleaned_2_more_withNewLongDescs\"\n",
        "\n",
        "adb_prep_step = DatabricksStep(\n",
        "    name=\"ADB_Feature_Eng\",\n",
        "    compute_target=databricks_compute,\n",
        "    existing_cluster_id=cluster_id,\n",
        "    python_script_params=['--cut_off_for_training', cut_off_for_training,\n",
        "                          '--valid_classes_period', valid_classes_period,\n",
        "                          '--cut_off_date_recent', cut_off_date_recent,\n",
        "                          '--temporal_test_date', temporal_test_date,\n",
        "                          '--logic_v', logic_v,\n",
        "                          '--top_n', top_n,\n",
        "                          '--base_file_name', base_file_name\n",
        "                          ],\n",
        "    permit_cluster_restart=True,\n",
        "    pypi_libraries=[PyPiLibrary(package='azureml-sdk'), PyPiLibrary(package='fsspec'), PyPiLibrary(package='plotly'), PyPiLibrary(package='kaleido')],\n",
        "    python_script_name=preprocessing_script_name,\n",
        "    source_directory=source_directory,\n",
        "    run_name='ADB_Feature_Eng',\n",
        "    allow_reuse=True\n",
        ")\n",
        "\n",
        "adb_prep_step.run_after(adb_prep_base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1663358375838
        }
      },
      "outputs": [],
      "source": [
        "# exp = Experiment(workspace=ws, name='transformer_hp')\n",
        "# \n",
        "# steps = [dbNbStep]\n",
        "# pipeline = Pipeline(workspace=ws, steps=steps)\n",
        "# pipeline_run = exp.submit(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1663358376042
        }
      },
      "outputs": [],
      "source": [
        "# pipeline_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1663358376307
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cluster_name = \"NC6s-v3-SingleNode\"\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1663358376576
        }
      },
      "outputs": [],
      "source": [
        "env = Environment.get(workspace=ws, name=\"Transformer-DeBerta\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1663358376771
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "args = [\n",
        "        '--target-name', 'target',\n",
        "        '--text-field', 'TEXT_FINAL',\n",
        "        '--is-test', 0,\n",
        "        '--is-final', 1,\n",
        "        '--is-jump', 0,\n",
        "        '--is-local', 0,\n",
        "        '--evaluation-strategy', \"epoch\"\n",
        "]\n",
        "\n",
        "src = ScriptRunConfig(source_directory=source_directory,\n",
        "                      script='train_transformer.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=env)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1663358376946
        }
      },
      "outputs": [],
      "source": [
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "ps = RandomParameterSampling(\n",
        "    {\n",
        "        '--base-checkpoint': choice(\"bert-base-cased\"), #, \"bert-base-cased\"), # , \"bert-large-cased\", \"microsoft/deberta-v3-small\", \"distilbert-base-uncased\", \"bert-base-uncased\"),\n",
        "        '--batch-size': choice(16),\n",
        "        '--no-epochs': choice(4),\n",
        "        '--learning-rate': choice(5.5e-5), # 5e-5, 4.5e-5, 4e-5, 5.5e-5, 6e-5, 3.5e-5, 6.5e-5)\n",
        "        '--warmup-steps': choice(0),\n",
        "        '--weight-decay': choice(0.0),\n",
        "        '--adam-beta1': choice(0.9),\n",
        "        '--adam-beta2': choice(0.999),\n",
        "        '--adam-epsilon': choice(1e-8)\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1663358377133
        }
      },
      "outputs": [],
      "source": [
        "policy = BanditPolicy(evaluation_interval=5, slack_factor=0.1)\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                     hyperparameter_sampling=ps,\n",
        "                                     policy=policy,\n",
        "                                     primary_metric_name='eval_f1_weighted',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs=20,\n",
        "                                     max_concurrent_runs=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1663358377335
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n",
        "\n",
        "hd_step_name='HyperDrive_Step'\n",
        "hd_step = HyperDriveStep(\n",
        "    name=hd_step_name,\n",
        "    hyperdrive_config=hyperdrive_config,\n",
        "    allow_reuse=True)\n",
        "\n",
        "hd_step.run_after(adb_prep_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1663358377523
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "reg_compute_target = ComputeTarget(workspace=ws, name=\"NC6s-v3-SingleNode\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1663359576047
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# conda_dep = CondaDependencies()\n",
        "# conda_dep.add_pip_package(\"azureml-sdk\")\n",
        "# conda_dep.env\n",
        "\n",
        "rcfg = RunConfiguration() # conda_dependencies=conda_dep)\n",
        "rcfg.environment = env\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=reg_compute_target,\n",
        "                                       arguments=['--is-test', 0,\n",
        "                                                  '--test-run-id', '',\n",
        "                                                  '--metric-name', 'temporal_test_f1_weighted',\n",
        "                                                  '--second-metric', 'temporal_test_f1',\n",
        "                                                  '--temporal-test-date', temporal_test_date,\n",
        "                                                  '--model-name', 'service_desk_concierge'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "register_model_step.run_after(hd_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1663360692280
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# conda_dep = CondaDependencies()\n",
        "# conda_dep.add_pip_package(\"azureml-sdk\")\n",
        "# conda_dep.env\n",
        "\n",
        "rcfg = RunConfiguration() # conda_dependencies=conda_dep)\n",
        "rcfg.environment = env\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=reg_compute_target,\n",
        "                                       arguments=['--endpoint-name', 'help-desk-service-prod',\n",
        "                                                  '--model-name', 'service_desk_concierge'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "deploy_model_step.run_after(register_model_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1663360693237
        }
      },
      "outputs": [],
      "source": [
        "exp = Experiment(workspace=ws, name='transformer_hp')\n",
        "steps = [deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECD-horizon-2022-09-21-14-05-Pipeline\n",
            "Newly published pipeline id: f20109d0-1c00-4436-a30f-12076e52d3bb\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "timenow = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "\n",
        "pipeline_name = 'ECD-horizon-' + timenow + \"-Pipeline\"\n",
        "print(pipeline_name)\n",
        "\n",
        "published_pipeline = pipeline.publish(\n",
        "    name=pipeline_name, \n",
        "    description=pipeline_name)\n",
        "print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1663360704538
        },
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created step Deploy_Latest_Model [772c859d][b4efefa4-c47d-4cc2-b950-1a03f606ef9c], (This step will run and generate new outputs)Created step Register_Best_Model [be0c2d96][55e1cc41-c2fa-4831-83d5-282541cce60c], (This step will run and generate new outputs)\n",
            "\n",
            "Created step HyperDrive_Step [f884b5ab][753b3d19-85b6-4bfe-9919-228f57bbda8b], (This step will run and generate new outputs)\n",
            "Created step ADB_Feature_Eng [2f3908d3][c241586b-0619-4c62-bb7f-13e8348018fa], (This step will run and generate new outputs)\n",
            "Created step ADB_Prep_Base [4a042339][342c0148-d43d-4def-bd89-0bf1be20b73d], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun 1c2836cb-f68e-4a58-b57d-b14412214b85\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/1c2836cb-f68e-4a58-b57d-b14412214b85?wsid=/subscriptions/580c0ee7-91da-497a-b61b-1a12caecdd19/resourcegroups/scsc-dsai-lab-dev-rg/workspaces/scsccps-dsai-lab-dev-mlw&tid=d05bc194-94bf-4ad6-ae2e-1db0f2e38f5e\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>transformer_hp</td><td>1c2836cb-f68e-4a58-b57d-b14412214b85</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/1c2836cb-f68e-4a58-b57d-b14412214b85?wsid=/subscriptions/580c0ee7-91da-497a-b61b-1a12caecdd19/resourcegroups/scsc-dsai-lab-dev-rg/workspaces/scsccps-dsai-lab-dev-mlw&amp;tid=d05bc194-94bf-4ad6-ae2e-1db0f2e38f5e\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: transformer_hp,\n",
              "Id: 1c2836cb-f68e-4a58-b57d-b14412214b85,\n",
              "Type: azureml.PipelineRun,\n",
              "Status: Preparing)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.submit(exp.name, credential_passthrough=True)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
