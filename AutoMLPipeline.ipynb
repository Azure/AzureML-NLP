{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550869730
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.core.runconfig import JarLibrary\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.core.databricks import PyPiLibrary\n",
        "\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import  PythonScriptStep\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION) \n",
        "\n",
        "# Based on \n",
        "# https://learn.microsoft.com/en-us/azure/machine-learning/v1/how-to-use-automlstep-in-pipelines\n",
        "# https://github.com/Azure/azureml-examples/blob/main/v1/python-sdk/tutorials/automl-with-azureml/regression/auto-ml-regression.ipynb\n",
        "# https://github.com/Azure/azureml-examples/blob/main/v1/python-sdk/tutorials/automl-with-azureml/automl-nlp-multiclass/automl-nlp-text-classification-multiclass.ipynb\n",
        "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-with-automated-machine-learning-step.ipynb "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550870217
        }
      },
      "outputs": [],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550870555
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\n",
        "\n",
        "def_blob_store = ws.get_default_datastore()\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550870782
        }
      },
      "outputs": [],
      "source": [
        "source_directory = \"./project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550871114
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"gpu-cluster\"\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550871535
        }
      },
      "outputs": [],
      "source": [
        "# %%writefile conda_dependencies.yml\n",
        "# \n",
        "# channels:\n",
        "#   - pytorch\n",
        "#   - anaconda\n",
        "#   - conda-forge\n",
        "# dependencies:\n",
        "#   - python=3.7\n",
        "#   - pip=21.1.2\n",
        "#   - pip:\n",
        "#       - azureml-core==1.44.0\n",
        "#       - azureml-mlflow==1.44.0\n",
        "#       - azureml-automl-core==1.44.0\n",
        "#       - azureml-automl-dnn-nlp==1.44.0\n",
        "#       - azureml-responsibleai==1.44.0\n",
        "#       - azureml-automl-runtime==1.44.0\n",
        "#       - azureml-train-automl-client==1.44.0\n",
        "#       - azureml-train-automl-runtime==1.44.0\n",
        "#       - horovod==0.21.3\n",
        "#   - numpy~=1.18.5\n",
        "#   - pandas~=1.1.5\n",
        "#   - scikit-learn~=0.22.1\n",
        "#   - pytorch==1.7.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550871774
        }
      },
      "outputs": [],
      "source": [
        "if 'nlp-accelerator' not in ws.environments:\n",
        "    base_env = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN-Text-GPU\")\n",
        "    env = base_env.clone(\"nlp-accelerator\")\n",
        "\n",
        "    conda_dep = env.python.conda_dependencies\n",
        "    conda_dep.add_pip_package('nvitop')\n",
        "    conda_dep.add_pip_package('azureml-train-automl==1.48.0')\n",
        "\n",
        "\n",
        "    env.python.conda_dependencies = conda_dep\n",
        "\n",
        "    env.register(ws)\n",
        "    print(f'registering new env {env}')\n",
        "    \n",
        "else:\n",
        "    env = Environment.get(workspace=ws, name=\"nlp-accelerator\")\n",
        "    print(f'got env {env}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550872063
        }
      },
      "outputs": [],
      "source": [
        "# to get larger datasets: http://jmcauley.ucsd.edu/data/amazon/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz -P data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550874751
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "pdf_main = getDF('data/reviews_Automotive_5.json.gz')\n",
        "pdf_main.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550875071
        }
      },
      "outputs": [],
      "source": [
        "pdf_main.loc[pdf_main['overall'] >= 4, 'sentiment'] = 1\n",
        "pdf_main.loc[pdf_main['overall'] < 3, 'sentiment'] = 0\n",
        "\n",
        "pdf_main.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550875464
        }
      },
      "outputs": [],
      "source": [
        "def generate_datasets(pdf_target_training, label = 'sentiment'):\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(pdf_target_training.drop(label, axis=1), pdf_target_training[label],\n",
        "                                                        stratify=pdf_target_training[label],\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.20)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        "                                                        stratify=y_test_val,\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.5)\n",
        "    pdf_X_train = X_train\n",
        "    pdf_X_val = X_val\n",
        "    pdf_X_test = X_test\n",
        "\n",
        "    pdf_X_train['sentiment'] = y_train\n",
        "    pdf_X_val['sentiment'] = y_val\n",
        "    pdf_X_test['sentiment'] = y_test\n",
        "    \n",
        "    print(f'Total records for: \"pdf_X_train\": [{pdf_X_train.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_val\": [{pdf_X_val.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_test\": [{pdf_X_test.shape[0]}]')\n",
        "    \n",
        "    return pdf_X_train, pdf_X_val, pdf_X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550875728
        }
      },
      "outputs": [],
      "source": [
        "pdf_train, pdf_val, pdf_test = generate_datasets(pdf_main[['reviewText', 'sentiment']].dropna(), 'sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550883121
        }
      },
      "outputs": [],
      "source": [
        "def_blob_store = ws.get_default_datastore()\n",
        "\n",
        "ds_train_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_train, target=(def_blob_store, 'nlp'), name=\"train_set\", description=\"Small amazon review for sentiment analysis [train set]\")\n",
        "ds_val_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_val, target=(def_blob_store, 'nlp'), name=\"val_set\", description=\"Small amazon review for sentiment analysis [val set]\")\n",
        "ds_test_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_test, target=(def_blob_store, 'nlp'), name=\"test_set\", description=\"Small amazon review for sentiment analysis [test set]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add AutoML Step \n",
        "Compare results from AutoML steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550883405
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import TrainingOutput, PipelineData\n",
        "\n",
        "metrics_data = PipelineData(name='automl_metrics_data',\n",
        "                            datastore=def_blob_store,\n",
        "                            pipeline_output_name='metrics_output',\n",
        "                            training_output=TrainingOutput(type='Metrics'))\n",
        "\n",
        "model_data = PipelineData(name='automl_best_model_data',\n",
        "                          datastore=def_blob_store,\n",
        "                          pipeline_output_name='model_output',\n",
        "                          training_output=TrainingOutput(type='Model'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AutoML Parameters\n",
        "\n",
        "\n",
        "```json\n",
        "{ \n",
        "    \"experiment_timeout_minutes\": 120,\n",
        "    \"primary_metric\": \"accuracy\",\n",
        "    \"primary_metric\" : \"AUC_weighted\",\n",
        "    \"iteration_timeout_minutes\" : 10,\n",
        "    \"iterations\" : 20,\n",
        "    \"experiment_timeout_hours\" : 1,\n",
        "    \"max_concurrent_iterations\": 1,\n",
        "    \"max_cores_per_iteration\": -1,\n",
        "    \"enable_early_stopping\": \"True\",\n",
        "    \"enable_dnn\": \"True\",\n",
        "    \"blacklist_algos\":[\"TensorFlowDNN\",\"TensorFlowLinearRegressor\"],\n",
        "    \"max_concurrent_iterations\": 1,\n",
        "    \"enable_batch_run\":\"False\",\n",
        "    \"enable_dnn\": \"true\",\n",
        "     \"model_explainability\" : \"True\"\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550883707
        }
      },
      "outputs": [],
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "automl_settings = {\n",
        "    \"verbosity\": logging.INFO,\n",
        "    \"experiment_timeout_minutes\": 240,\n",
        "    \"primary_metric\": \"AUC_weighted\",\n",
        "    \"enable_early_stopping\" : \"true\",\n",
        "    #\"ensemble_iterations\" : 3,\n",
        "    #\"enable_stack_ensembling\" : \"true\",\n",
        "    #\"enable_ensembling\" : \"true\",\n",
        "    #\"save_mlflow\": \"true\",\n",
        "    #\"max_cores_per_iteration\": -1,\n",
        "    #\"max_concurrent_iterations\": 3,\n",
        "    \"send_telemetry\" : \"true\",\n",
        "    #\"experiment_timeout_minutes\": 1440,\n",
        "    #\"iteration_timeout_minutes\": 1440,\n",
        "    \"many_models\": True,\n",
        "    #\"pipeline_fetch_max_batch_size\": 15,\n",
        "    #\"iteration_timeout_minutes\" : 30,\n",
        "    #\"iterations\" : 5 \n",
        "}\n",
        "\n",
        "target_column_name = \"sentiment\"\n",
        "\n",
        "automl_config = AutoMLConfig(\n",
        "    task=\"text-classification\",\n",
        "    debug_log=\"automl_errors.log\",\n",
        "    compute_target=compute_target,\n",
        "    training_data=ds_train_set ,\n",
        "    validation_data=ds_val_set ,\n",
        "    featurization = 'auto',\n",
        "    label_column_name=target_column_name,\n",
        "#    blocked_models=[\"TensorFlowDNN\", \"TensorFlowLinearRegressor\"],\n",
        "    **automl_settings\n",
        ")\n",
        "\n",
        "\n",
        "automl_step = AutoMLStep(name='AutoML_Classification',\n",
        "    automl_config=automl_config,\n",
        "    passthru_automl_config=False,\n",
        "    outputs=[metrics_data,model_data],\n",
        "    enable_default_model_output=False,\n",
        "    enable_default_metrics_output=False,\n",
        "    allow_reuse=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550884041
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cpu_compute = ComputeTarget(workspace=ws, name=\"cpu-cluster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550884379
        }
      },
      "outputs": [],
      "source": [
        "env_cpu = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN\") #name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550884621
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env\n",
        "\n",
        "test_model_step = PythonScriptStep(script_name='test_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Test_AutoML_Best_Model\",\n",
        "                                       compute_target=compute_target,\n",
        "                                       arguments=[\n",
        "                                                  '--metric-name', 'AUC_weighted',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--text-field-name', 'reviewText',\n",
        "                                                  '--test_dataset', ds_test_set.as_named_input('test_dataset'),\n",
        "                                                  '--model-data', model_data\n",
        "                                                 \n",
        "                                                 ],\n",
        "                                       inputs=[ model_data],          \n",
        "                                       allow_reuse=False,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "\n",
        "\n",
        "test_model_step.run_after(automl_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550884896
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--is-test', 0,\n",
        "                                                  '--test-run-id', '',\n",
        "                                                  '--metric-name', 'test_AUC_weighted',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--model-name', 'sentiment_classifier',\n",
        "                                                \n",
        "                                                  ],\n",
        "                                             \n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "\n",
        "\n",
        "register_model_step.run_after(test_model_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550885187
        }
      },
      "outputs": [],
      "source": [
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--endpoint-name', 'sentiment-endpoint-2',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "deploy_model_step.run_after(register_model_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550885501
        }
      },
      "outputs": [],
      "source": [
        "exp = Experiment(workspace=ws, name='transformer_automl')\n",
        "steps = [deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550899158
        }
      },
      "outputs": [],
      "source": [
        "pipeline.submit(exp.name) #, credential_passthrough=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674550899608
        }
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "timenow = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "\n",
        "pipeline_name = f\"Sentiment-Classifier-{timenow}-Pipeline\"\n",
        "print(pipeline_name)\n",
        "\n",
        "published_pipeline = pipeline.publish(\n",
        "    name=pipeline_name, \n",
        "    description=pipeline_name)\n",
        "print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
