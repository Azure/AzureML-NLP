{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.core.runconfig import JarLibrary\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.core.databricks import PyPiLibrary\n",
        "\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import  PythonScriptStep\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION) \n",
        "\n",
        "# Based on \n",
        "# https://learn.microsoft.com/en-us/azure/machine-learning/v1/how-to-use-automlstep-in-pipelines\n",
        "# https://github.com/Azure/azureml-examples/blob/main/v1/python-sdk/tutorials/automl-with-azureml/regression/auto-ml-regression.ipynb\n",
        "# https://github.com/Azure/azureml-examples/blob/main/v1/python-sdk/tutorials/automl-with-azureml/automl-nlp-multiclass/automl-nlp-text-classification-multiclass.ipynb\n",
        "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-with-automated-machine-learning-step.ipynb "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.47.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1674550869730
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "nlp-workspace\nopenaml\neastus2\nf9b97038-ed78-4a26-a1a7-51e81e75d867\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1674550870217
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\n",
        "\n",
        "def_blob_store = ws.get_default_datastore()\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Datastore workspaceblobstore will be used\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1674550870555
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_directory = \"./project\""
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1674550870782
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"gpu-cluster\"\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1674550871114
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile conda_dependencies.yml\n",
        "# \n",
        "# channels:\n",
        "#   - pytorch\n",
        "#   - anaconda\n",
        "#   - conda-forge\n",
        "# dependencies:\n",
        "#   - python=3.7\n",
        "#   - pip=21.1.2\n",
        "#   - pip:\n",
        "#       - azureml-core==1.44.0\n",
        "#       - azureml-mlflow==1.44.0\n",
        "#       - azureml-automl-core==1.44.0\n",
        "#       - azureml-automl-dnn-nlp==1.44.0\n",
        "#       - azureml-responsibleai==1.44.0\n",
        "#       - azureml-automl-runtime==1.44.0\n",
        "#       - azureml-train-automl-client==1.44.0\n",
        "#       - azureml-train-automl-runtime==1.44.0\n",
        "#       - horovod==0.21.3\n",
        "#   - numpy~=1.18.5\n",
        "#   - pandas~=1.1.5\n",
        "#   - scikit-learn~=0.22.1\n",
        "#   - pytorch==1.7.1"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1674550871535
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'nlp-accelerator' not in ws.environments:\n",
        "    base_env = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN-Text-GPU\")\n",
        "    env = base_env.clone(\"nlp-accelerator\")\n",
        "\n",
        "    conda_dep = env.python.conda_dependencies\n",
        "    conda_dep.add_pip_package('nvitop')\n",
        "    conda_dep.add_pip_package('azureml-train-automl==1.48.0')\n",
        "\n",
        "\n",
        "    env.python.conda_dependencies = conda_dep\n",
        "\n",
        "    env.register(ws)\n",
        "    print(f'registering new env {env}')\n",
        "    \n",
        "else:\n",
        "    env = Environment.get(workspace=ws, name=\"nlp-accelerator\")\n",
        "    print(f'got env {env}')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "got env Environment(Name: nlp-accelerator,\nVersion: 3)\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1674550871774
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to get larger datasets: http://jmcauley.ucsd.edu/data/amazon/"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1674550872063
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz -P data/"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "--2023-01-24 09:01:12--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz\nResolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\nConnecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4669048 (4.5M) [application/x-gzip]\nSaving to: ‘data/reviews_Automotive_5.json.gz.87’\n\nreviews_Automotive_ 100%[===================>]   4.45M  4.32MB/s    in 1.0s    \n\n2023-01-24 09:01:14 (4.32 MB/s) - ‘data/reviews_Automotive_5.json.gz.87’ saved [4669048/4669048]\n\n"
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "pdf_main = getDF('data/reviews_Automotive_5.json.gz')\n",
        "pdf_main.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "(20473, 9)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1674550874751
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_main.loc[pdf_main['overall'] >= 4, 'sentiment'] = 1\n",
        "pdf_main.loc[pdf_main['overall'] < 3, 'sentiment'] = 0\n",
        "\n",
        "pdf_main.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "       reviewerID        asin     reviewerName   helpful  \\\n0  A3F73SC1LY51OO  B00002243X  Alan Montgomery    [4, 4]   \n1  A20S66SKYXULG2  B00002243X         alphonse    [1, 1]   \n2  A2I8LFSN2IS5EO  B00002243X            Chris    [0, 0]   \n3  A3GT2EWQSO45ZG  B00002243X           DeusEx  [19, 19]   \n4  A3ESWJPAVRPWB4  B00002243X     E. Hernandez    [0, 0]   \n\n                                          reviewText  overall  \\\n0  I needed a set of jumper cables for my new car...      5.0   \n1  These long cables work fine for my truck, but ...      4.0   \n2  Can't comment much on these since they have no...      5.0   \n3  I absolutley love Amazon!!!  For the price of ...      5.0   \n4  I purchased the 12' feet long cable set and th...      5.0   \n\n                                      summary  unixReviewTime   reviewTime  \\\n0  Work Well - Should Have Bought Longer Ones      1313539200  08 17, 2011   \n1                            Okay long cables      1315094400   09 4, 2011   \n2                  Looks and feels heavy Duty      1374710400  07 25, 2013   \n3       Excellent choice for Jumper Cables!!!      1292889600  12 21, 2010   \n4      Excellent, High Quality Starter Cables      1341360000   07 4, 2012   \n\n   sentiment  \n0        1.0  \n1        1.0  \n2        1.0  \n3        1.0  \n4        1.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>reviewerName</th>\n      <th>helpful</th>\n      <th>reviewText</th>\n      <th>overall</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>reviewTime</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A3F73SC1LY51OO</td>\n      <td>B00002243X</td>\n      <td>Alan Montgomery</td>\n      <td>[4, 4]</td>\n      <td>I needed a set of jumper cables for my new car...</td>\n      <td>5.0</td>\n      <td>Work Well - Should Have Bought Longer Ones</td>\n      <td>1313539200</td>\n      <td>08 17, 2011</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A20S66SKYXULG2</td>\n      <td>B00002243X</td>\n      <td>alphonse</td>\n      <td>[1, 1]</td>\n      <td>These long cables work fine for my truck, but ...</td>\n      <td>4.0</td>\n      <td>Okay long cables</td>\n      <td>1315094400</td>\n      <td>09 4, 2011</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A2I8LFSN2IS5EO</td>\n      <td>B00002243X</td>\n      <td>Chris</td>\n      <td>[0, 0]</td>\n      <td>Can't comment much on these since they have no...</td>\n      <td>5.0</td>\n      <td>Looks and feels heavy Duty</td>\n      <td>1374710400</td>\n      <td>07 25, 2013</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A3GT2EWQSO45ZG</td>\n      <td>B00002243X</td>\n      <td>DeusEx</td>\n      <td>[19, 19]</td>\n      <td>I absolutley love Amazon!!!  For the price of ...</td>\n      <td>5.0</td>\n      <td>Excellent choice for Jumper Cables!!!</td>\n      <td>1292889600</td>\n      <td>12 21, 2010</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A3ESWJPAVRPWB4</td>\n      <td>B00002243X</td>\n      <td>E. Hernandez</td>\n      <td>[0, 0]</td>\n      <td>I purchased the 12' feet long cable set and th...</td>\n      <td>5.0</td>\n      <td>Excellent, High Quality Starter Cables</td>\n      <td>1341360000</td>\n      <td>07 4, 2012</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1674550875071
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_datasets(pdf_target_training, label = 'sentiment'):\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(pdf_target_training.drop(label, axis=1), pdf_target_training[label],\n",
        "                                                        stratify=pdf_target_training[label],\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.20)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        "                                                        stratify=y_test_val,\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.5)\n",
        "    pdf_X_train = X_train\n",
        "    pdf_X_val = X_val\n",
        "    pdf_X_test = X_test\n",
        "\n",
        "    pdf_X_train['sentiment'] = y_train\n",
        "    pdf_X_val['sentiment'] = y_val\n",
        "    pdf_X_test['sentiment'] = y_test\n",
        "    \n",
        "    print(f'Total records for: \"pdf_X_train\": [{pdf_X_train.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_val\": [{pdf_X_val.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_test\": [{pdf_X_test.shape[0]}]')\n",
        "    \n",
        "    return pdf_X_train, pdf_X_val, pdf_X_test"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1674550875464
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_train, pdf_val, pdf_test = generate_datasets(pdf_main[['reviewText', 'sentiment']].dropna(), 'sentiment')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Total records for: \"pdf_X_train\": [15234]\nTotal records for: \"pdf_X_val\": [1904]\nTotal records for: \"pdf_X_test\": [1905]\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1674550875728
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def_blob_store = ws.get_default_datastore()\n",
        "\n",
        "ds_train_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_train, target=(def_blob_store, 'nlp'), name=\"train_set\", description=\"Small amazon review for sentiment analysis [train set]\")\n",
        "ds_val_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_val, target=(def_blob_store, 'nlp'), name=\"val_set\", description=\"Small amazon review for sentiment analysis [val set]\")\n",
        "ds_test_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_test, target=(def_blob_store, 'nlp'), name=\"test_set\", description=\"Small amazon review for sentiment analysis [test set]\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to nlp/ced19ab4-ec04-4702-8359-a6ea22ecb554/\nResolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\nGetting data access token with Assigned Identity (client_id=2b04d211-63bc-4fe1-895b-347244b8cdc7) and endpoint type based on configuration\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nResolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\nGetting data access token with Assigned Identity (client_id=2b04d211-63bc-4fe1-895b-347244b8cdc7) and endpoint type based on configuration\nSuccessfully created and registered a new dataset.\nValidating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to nlp/b3eab7a8-6b5f-45a6-8c2b-d9f37ad4703c/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\nValidating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to nlp/5e73f1fb-f39f-46c3-846b-270af7f5e8b5/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1674550883121
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add AutoML Step \n",
        "Compare results from AutoML steps"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import TrainingOutput, PipelineData\n",
        "\n",
        "metrics_data = PipelineData(name='automl_metrics_data',\n",
        "                            datastore=def_blob_store,\n",
        "                            pipeline_output_name='metrics_output',\n",
        "                            training_output=TrainingOutput(type='Metrics'))\n",
        "\n",
        "model_data = PipelineData(name='automl_best_model_data',\n",
        "                          datastore=def_blob_store,\n",
        "                          pipeline_output_name='model_output',\n",
        "                          training_output=TrainingOutput(type='Model'))"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1674550883405
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## AutoML Parameters\n",
        "\n",
        "\n",
        "```json\n",
        "{ \n",
        "    \"experiment_timeout_minutes\": 120,\n",
        "    \"primary_metric\": \"accuracy\",\n",
        "    \"primary_metric\" : \"AUC_weighted\",\n",
        "    \"iteration_timeout_minutes\" : 10,\n",
        "    \"iterations\" : 20,\n",
        "    \"experiment_timeout_hours\" : 1,\n",
        "    \"max_concurrent_iterations\": 1,\n",
        "    \"max_cores_per_iteration\": -1,\n",
        "    \"enable_early_stopping\": \"True\",\n",
        "    \"enable_dnn\": \"True\",\n",
        "    \"blacklist_algos\":[\"TensorFlowDNN\",\"TensorFlowLinearRegressor\"],\n",
        "    \"max_concurrent_iterations\": 1,\n",
        "    \"enable_batch_run\":\"False\",\n",
        "    \"enable_dnn\": \"true\",\n",
        "     \"model_explainability\" : \"True\"\n",
        "}\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "automl_settings = {\n",
        "    \"verbosity\": logging.INFO,\n",
        "    \"experiment_timeout_minutes\": 240,\n",
        "    \"primary_metric\": \"AUC_weighted\",\n",
        "    \"enable_early_stopping\" : \"true\",\n",
        "    #\"ensemble_iterations\" : 3,\n",
        "    #\"enable_stack_ensembling\" : \"true\",\n",
        "    #\"enable_ensembling\" : \"true\",\n",
        "    #\"save_mlflow\": \"true\",\n",
        "    #\"max_cores_per_iteration\": -1,\n",
        "    #\"max_concurrent_iterations\": 3,\n",
        "    \"send_telemetry\" : \"true\",\n",
        "    #\"experiment_timeout_minutes\": 1440,\n",
        "    #\"iteration_timeout_minutes\": 1440,\n",
        "    \"many_models\": True,\n",
        "    #\"pipeline_fetch_max_batch_size\": 15,\n",
        "    #\"iteration_timeout_minutes\" : 30,\n",
        "    #\"iterations\" : 5 \n",
        "}\n",
        "\n",
        "target_column_name = \"sentiment\"\n",
        "\n",
        "automl_config = AutoMLConfig(\n",
        "    task=\"text-classification\",\n",
        "    debug_log=\"automl_errors.log\",\n",
        "    compute_target=compute_target,\n",
        "    training_data=ds_train_set ,\n",
        "    validation_data=ds_val_set ,\n",
        "    featurization = 'auto',\n",
        "    label_column_name=target_column_name,\n",
        "#    blocked_models=[\"TensorFlowDNN\", \"TensorFlowLinearRegressor\"],\n",
        "    **automl_settings\n",
        ")\n",
        "\n",
        "\n",
        "automl_step = AutoMLStep(name='AutoML_Classification',\n",
        "    automl_config=automl_config,\n",
        "    passthru_automl_config=False,\n",
        "    outputs=[metrics_data,model_data],\n",
        "    enable_default_model_output=False,\n",
        "    enable_default_metrics_output=False,\n",
        "    allow_reuse=True)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1674550883707
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cpu_compute = ComputeTarget(workspace=ws, name=\"cpu-cluster\")"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1674550884041
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_cpu = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN\") #name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\")"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1674550884379
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env\n",
        "\n",
        "test_model_step = PythonScriptStep(script_name='test_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Test_AutoML_Best_Model\",\n",
        "                                       compute_target=compute_target,\n",
        "                                       arguments=[\n",
        "                                                  '--metric-name', 'AUC_weighted',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--text-field-name', 'reviewText',\n",
        "                                                  '--test_dataset', ds_test_set.as_named_input('test_dataset'),\n",
        "                                                  '--model-data', model_data\n",
        "                                                 \n",
        "                                                 ],\n",
        "                                       inputs=[ model_data],          \n",
        "                                       allow_reuse=False,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "\n",
        "\n",
        "test_model_step.run_after(automl_step)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674550884621
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--is-test', 0,\n",
        "                                                  '--test-run-id', '',\n",
        "                                                  '--metric-name', 'test_AUC_weighted',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--model-name', 'sentiment_classifier',\n",
        "                                                \n",
        "                                                  ],\n",
        "                                             \n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "\n",
        "\n",
        "register_model_step.run_after(test_model_step)\n"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1674550884896
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--endpoint-name', 'sentiment-endpoint-2',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "deploy_model_step.run_after(register_model_step)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1674550885187
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp = Experiment(workspace=ws, name='transformer_automl')\n",
        "steps = [deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class KubernetesCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1674550885501
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.submit(exp.name) #, credential_passthrough=True)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step Deploy_Latest_Model [d4824337][f0e30326-aaca-49fd-b664-28f6bc9c6074], (This step will run and generate new outputs)\nCreated step Register_Best_Model [92c84426][be262dbd-29e7-49b9-9fe7-7807ba1329bc], (This step will run and generate new outputs)\nCreated step Test_AutoML_Best_Model [3fec1c16][cb981bf5-de4d-4af1-b4d5-07c90833cd65], (This step will run and generate new outputs)\nCreated step AutoML_Classification [e9472371][e6af1f1f-cf86-48f6-8452-ff1c928059b1], (This step will run and generate new outputs)\nSubmitted PipelineRun d505f5fd-10c6-4050-809e-3ac469a2ff4e\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/d505f5fd-10c6-4050-809e-3ac469a2ff4e?wsid=/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourcegroups/openaml/workspaces/nlp-workspace&tid=4460d6c7-3cdd-4d85-bda4-87c85c98af04\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "Run(Experiment: transformer_automl,\nId: d505f5fd-10c6-4050-809e-3ac469a2ff4e,\nType: azureml.PipelineRun,\nStatus: Preparing)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>transformer_automl</td><td>d505f5fd-10c6-4050-809e-3ac469a2ff4e</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/d505f5fd-10c6-4050-809e-3ac469a2ff4e?wsid=/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourcegroups/openaml/workspaces/nlp-workspace&amp;tid=4460d6c7-3cdd-4d85-bda4-87c85c98af04\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1674550899158
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "timenow = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "\n",
        "pipeline_name = f\"Sentiment-Classifier-{timenow}-Pipeline\"\n",
        "print(pipeline_name)\n",
        "\n",
        "published_pipeline = pipeline.publish(\n",
        "    name=pipeline_name, \n",
        "    description=pipeline_name)\n",
        "print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sentiment-Classifier-2023-01-24-09-01-Pipeline\nNewly published pipeline id: f8cd1936-6fba-4f7d-a4ea-141c1c666fc3\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1674550899608
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}