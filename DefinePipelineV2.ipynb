{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1668533978662
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dac8073e-1c2d-4a7d-a53b-c3655e291d58\n",
            "Learning\n",
            "learningmain\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Enter details of your AML workspace\n",
        "subscription_id = \"dac8073e-1c2d-4a7d-a53b-c3655e291d58\"\n",
        "resource_group = \"Learning\"\n",
        "workspace = \"learningmain\"\n",
        "\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")\n",
        "\n",
        "print(ml_client.subscription_id, ml_client.resource_group_name, ml_client.workspace_name, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-13 18:17:55--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4669048 (4.5M) [application/x-gzip]\n",
            "Saving to: ‘data/reviews_Automotive_5.json.gz.16’\n",
            "\n",
            "reviews_Automotive_ 100%[===================>]   4.45M  3.24MB/s    in 1.4s    \n",
            "\n",
            "2023-01-13 18:17:57 (3.24 MB/s) - ‘data/reviews_Automotive_5.json.gz.16’ saved [4669048/4669048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# to get larger datasets, visit: http://jmcauley.ucsd.edu/data/amazon/\n",
        "\n",
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz -P data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20473, 9)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "pdf_main = getDF('data/reviews_Automotive_5.json.gz')\n",
        "pdf_main.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20473.000000</td>\n",
              "      <td>2.047300e+04</td>\n",
              "      <td>19043.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.471841</td>\n",
              "      <td>1.365018e+09</td>\n",
              "      <td>0.939715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.940337</td>\n",
              "      <td>3.621266e+07</td>\n",
              "      <td>0.238020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.121386e+09</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.354838e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.373414e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.390435e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.405901e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            overall  unixReviewTime     sentiment\n",
              "count  20473.000000    2.047300e+04  19043.000000\n",
              "mean       4.471841    1.365018e+09      0.939715\n",
              "std        0.940337    3.621266e+07      0.238020\n",
              "min        1.000000    1.121386e+09      0.000000\n",
              "25%        4.000000    1.354838e+09      1.000000\n",
              "50%        5.000000    1.373414e+09      1.000000\n",
              "75%        5.000000    1.390435e+09      1.000000\n",
              "max        5.000000    1.405901e+09      1.000000"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_main.loc[pdf_main['overall'] >= 4, 'sentiment'] = 1\n",
        "pdf_main.loc[pdf_main['overall'] < 3, 'sentiment'] = 0\n",
        "\n",
        "pdf_main.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_datasets(pdf_target_training, label = 'sentiment'):\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(pdf_target_training.drop(label, axis=1), pdf_target_training[label],\n",
        "                                                        stratify=pdf_target_training[label],\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.20)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        "                                                        stratify=y_test_val,\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.5)\n",
        "    pdf_X_train = X_train\n",
        "    pdf_X_val = X_val\n",
        "    pdf_X_test = X_test\n",
        "\n",
        "    pdf_X_train['sentiment'] = y_train\n",
        "    pdf_X_val['sentiment'] = y_val\n",
        "    pdf_X_test['sentiment'] = y_test\n",
        "    \n",
        "    print(f'Total records for: \"pdf_X_train\": [{pdf_X_train.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_val\": [{pdf_X_val.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_test\": [{pdf_X_test.shape[0]}]')\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "    return pdf_X_train, pdf_X_val, pdf_X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records for: \"pdf_X_train\": [15234]\n",
            "Total records for: \"pdf_X_val\": [1904]\n",
            "Total records for: \"pdf_X_test\": [1905]\n"
          ]
        }
      ],
      "source": [
        "pdf_train, pdf_val, pdf_test = generate_datasets(pdf_main[['reviewText', 'sentiment']].dropna(), 'sentiment')\n",
        "\n",
        "pdf_train.to_csv('data/pdf_train.csv')\n",
        "pdf_val.to_csv('data/pdf_val.csv')\n",
        "pdf_test.to_csv('data/pdf_test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# === Note on path ===\n",
        "# can be can be a local path or a cloud path. AzureML supports https://`, `abfss://`, `wasbs://` and `azureml://` URIs.\n",
        "# Local paths are automatically uploaded to the default datastore in the cloud.\n",
        "# More details on supported paths: https://docs.microsoft.com/azure/machine-learning/how-to-read-write-data-v2#supported-paths\n",
        "\n",
        "def gen_input_data(url):\n",
        "    return Input(type=AssetTypes.URI_FILE, path=url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_train = gen_input_data('data/pdf_train.csv')\n",
        "ds_val = gen_input_data('data/pdf_val.csv')\n",
        "ds_test = gen_input_data('data/pdf_test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "gather": {
          "logged": 1668533982929
        }
      },
      "outputs": [],
      "source": [
        "source_directory = \"./project_v2/\"\n",
        "experiment_name = 'transformer_hp_v2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "gather": {
          "logged": 1668533983332
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting environments/conda_dependencies.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile environments/conda_dependencies.yml\n",
        "\n",
        "channels:\n",
        "  - pytorch\n",
        "  - anaconda\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.7\n",
        "  - pip=21.1.2\n",
        "  - pip:\n",
        "      - azure-ai-ml==1.2.0\n",
        "      - mlflow== 1.26.1\n",
        "      - azureml-mlflow==1.42.0\n",
        "      - nvitop\n",
        "      - transformers\n",
        "      - joblib\n",
        "      - datasets\n",
        "  - numpy~=1.21.6\n",
        "  - pandas~=1.1.5\n",
        "  - shap=0.39.0\n",
        "  - scikit-learn~=0.22.1\n",
        "  - pytorch==1.7.1\n",
        "name: nlp_training_environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Environment({'is_anonymous': False, 'auto_increment_version': False, 'name': 'nlp-accelerator-sdk-v2', 'description': 'This environment is curated to run NLP Transformer based models using AML SDK-v2 and native MLFlow integration', 'tags': {}, 'properties': {}, 'id': '/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourceGroups/Learning/providers/Microsoft.MachineLearningServices/workspaces/learningmain/environments/nlp-accelerator-sdk-v2/versions/7', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/hosarsha23/code/Users/hosarsha/nlp-aml', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f23d61e3730>, 'serialize': <msrest.serialization.Serializer object at 0x7f23d61e3fa0>, 'version': '7', 'latest_version': None, 'conda_file': {'channels': ['pytorch', 'anaconda', 'conda-forge'], 'dependencies': ['python=3.7', 'pip=21.1.2', {'pip': ['azure-ai-ml==1.2.0', 'mlflow== 1.26.1', 'azureml-mlflow==1.42.0', 'nvitop', 'transformers', 'joblib', 'datasets']}, 'numpy~=1.21.6', 'pandas~=1.1.5', 'shap=0.39.0', 'scikit-learn~=0.22.1', 'pytorch==1.7.1'], 'name': 'nlp_training_environment'}, 'image': 'mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu20.04:latest', 'build': None, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"channels\": [\\n    \"pytorch\",\\n    \"anaconda\",\\n    \"conda-forge\"\\n  ],\\n  \"dependencies\": [\\n    \"python=3.7\",\\n    \"pip=21.1.2\",\\n    {\\n      \"pip\": [\\n        \"azure-ai-ml==1.2.0\",\\n        \"mlflow== 1.26.1\",\\n        \"azureml-mlflow==1.42.0\",\\n        \"nvitop\",\\n        \"transformers\",\\n        \"joblib\",\\n        \"datasets\"\\n      ]\\n    },\\n    \"numpy~=1.21.6\",\\n    \"pandas~=1.1.5\",\\n    \"shap=0.39.0\",\\n    \"scikit-learn~=0.22.1\",\\n    \"pytorch==1.7.1\"\\n  ],\\n  \"name\": \"nlp_training_environment\"\\n}'})"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "env_name = 'nlp-accelerator-sdk-v2'\n",
        "env_list = list(ml_client.environments.list(name=env_name)) # (name=\"nlp-accelerator-sdk-v2\", version='3')\n",
        "if len(env_list) > 0:\n",
        "    env = env_list[0]\n",
        "else:\n",
        "    env = Environment(\n",
        "        image=\"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu20.04:latest\",\n",
        "        conda_file='environments/conda_dependencies.yml',\n",
        "        name=env_name,\n",
        "        description='This environment is curated to run NLP Transformer based models using AML SDK-v2 and native MLFlow integration'\n",
        "    )\n",
        "\n",
        "    ml_client.environments.create_or_update(env)\n",
        "\n",
        "env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "gather": {
          "logged": 1668533987254
        }
      },
      "outputs": [],
      "source": [
        "cluster_name = \"a100-cluster\"\n",
        "compute_target = ml_client.compute.get(cluster_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "# ds_train = gen_input_data('data/pdf_test.csv')\n",
        "# ds_val = gen_input_data('data/pdf_val.csv')\n",
        "# ds_test = gen_input_data('data/pdf_test.csv')\n",
        "\n",
        "job_train = command(\n",
        "    inputs=dict(\n",
        "        training_dataset=ds_train,\n",
        "        val_dataset=ds_val,\n",
        "        test_dataset=ds_test,\n",
        "        target_name='sentiment', \n",
        "        text_field_name='reviewText',\n",
        "        is_test=1,\n",
        "        is_final=0,\n",
        "        is_local=0,\n",
        "        is_jump=0,\n",
        "        evaluation_strategy='epoch',\n",
        "        collect_resource_utilization=1,\n",
        "        resource_utilization_interval=5.0, # seconds\n",
        "        base_checkpoint='bert-base-cased',\n",
        "        batch_size=8,\n",
        "        no_epochs=4,\n",
        "        learning_rate=5.5e-5,\n",
        "        warmup_steps=0,\n",
        "        weight_decay=0.0,\n",
        "        adam_beta1=0.9,\n",
        "        adam_beta2=0.999,\n",
        "        adam_epsilon=1e-8\n",
        "    ),\n",
        "    compute=compute_target,\n",
        "    environment=env,\n",
        "    code=source_directory,  # location of source code\n",
        "    command=\"\"\"python train_transformer.py \\\n",
        "        --collect-resource-utilization ${{inputs.collect_resource_utilization}} \\\n",
        "        --resource-utilization-interval ${{inputs.resource_utilization_interval}} \\\n",
        "        --target-name ${{inputs.target_name}} \\\n",
        "        --training-dataset ${{inputs.training_dataset}} \\\n",
        "        --val-dataset ${{inputs.val_dataset}} \\\n",
        "        --test-dataset ${{inputs.test_dataset}} \\\n",
        "        --text-field-name ${{inputs.text_field_name}} \\\n",
        "        --is-test ${{inputs.is_test}} \\\n",
        "        --is-final ${{inputs.is_final}} \\\n",
        "        --is-local ${{inputs.is_local}} \\\n",
        "        --is-jump ${{inputs.is_jump}} \\\n",
        "        --evaluation-strategy ${{inputs.evaluation_strategy}} \\\n",
        "    \"\"\",\n",
        "    experiment_name=experiment_name,\n",
        "    display_name=\"HyperDrive_Step\",\n",
        ")\n",
        "\n",
        "# --base-checkpoint ${{inputs.base_checkpoint}} \\\n",
        "# --batch-size ${{inputs.batch_size}} \\\n",
        "# --no-epochs ${{inputs.no_epochs}} \\\n",
        "# --learning-rate ${{inputs.learning_rate}} \\\n",
        "# --warmup-steps ${{inputs.warmup_steps}} \\\n",
        "# --weight-decay ${{inputs.weight_decay}} \\\n",
        "# --adam-beta1 ${{inputs.adam_beta1}} \\\n",
        "# --adam-beta2 ${{inputs.adam_beta2}} \\\n",
        "# --adam-epsilon ${{inputs.adam_epsilon}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.sweep import Choice, BanditPolicy\n",
        "\n",
        "# we will reuse the command_job created before. we call it as a function so that we can apply inputs\n",
        "job_train_for_sweep = job_train(\n",
        "    base_checkpoint=Choice([\"bert-base-cased\"]), #, \"bert-base-cased\"]), # , \"bert-large-cased\", \"microsoft/deberta-v3-small\", \"distilbert-base-uncased\", \"bert-base-uncased\"]),\n",
        "    batch_size=Choice([8]),\n",
        "    no_epochs=Choice([4]),\n",
        "    learning_rate=Choice([5.5e-5, 5e-5, 4.5e-5, 4e-5, 5.5e-5, 6e-5, 3.5e-5, 6.5e-5]),\n",
        "    warmup_steps=Choice([0]),\n",
        "    weight_decay=Choice([0.0]),\n",
        "    adam_beta1=Choice([0.9]),\n",
        "    adam_beta2=Choice([0.999]),\n",
        "    adam_epsilon=Choice([1e-8])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.dsl import pipeline\n",
        "\n",
        "@pipeline(\n",
        "    # tags={\"owner\": \"sdkteam\", \"tag\": \"tagvalue\"},\n",
        ")\n",
        "def pipeline_construction():\n",
        "    \"\"\"The hello world pipeline job.\"\"\"\n",
        "    job_train_for_sweep_node = job_train_for_sweep.sweep(\n",
        "        compute=compute_target,\n",
        "        sampling_algorithm=\"random\",\n",
        "        primary_metric=\"eval_f1_weighted\",\n",
        "        goal=\"Maximize\",\n",
        "        max_total_trials=20,\n",
        "        max_concurrent_trials=3,\n",
        "        early_termination_policy=BanditPolicy(\n",
        "            slack_factor=0.1, evaluation_interval=5\n",
        "        ),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_job = pipeline_construction()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: the provided asset name 'nlp-accelerator-sdk-v2' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'nlp-accelerator-sdk-v2' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'nlp-accelerator-sdk-v2' will not be used for anonymous registration\n",
            "Uploading project_v2 (0.02 MBs): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16332/16332 [00:00<00:00, 1040911.93it/s]\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>transformer_hp_v2</td><td>silly_plow_lxlpvt9h6d</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/silly_plow_lxlpvt9h6d?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/Learning/workspaces/learningmain&amp;tid=16b3c013-d300-468d-ac64-7eda0820b6d3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
            ],
            "text/plain": [
              "PipelineJob({'inputs': {}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'name': 'azureml_anonymous', 'description': 'The hello world pipeline job.', 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': None, 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f23d551a140>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'pipeline_construction', 'is_deterministic': None, 'inputs': {}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'job_train_for_sweep_node': Sweep({'job_inputs': {'training_dataset': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/7a3ba1c409bbf7521a2bec33a3f27c4d/pdf_train.csv'}, 'val_dataset': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/c6257515eb513d715f69340106e6be7d/pdf_val.csv'}, 'test_dataset': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/fec0117b08a164a31a11b97fbc2595c4/pdf_test.csv'}, 'target_name': 'sentiment', 'text_field_name': 'reviewText', 'is_test': '1', 'is_final': '0', 'is_local': '0', 'is_jump': '0', 'evaluation_strategy': 'epoch', 'collect_resource_utilization': '1', 'resource_utilization_interval': '5.0', 'base_checkpoint': None, 'batch_size': None, 'no_epochs': None, 'learning_rate': None, 'warmup_steps': None, 'weight_decay': None, 'adam_beta1': None, 'adam_beta2': None, 'adam_epsilon': None}, 'job_outputs': {}, 'init': False, 'type': 'sweep', 'status': None, 'log_files': None, 'name': 'job_train_for_sweep_node', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': None, 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f23d553b130>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'HyperDrive_Step', 'experiment_name': None, 'compute': 'a100-cluster', 'services': None, 'comment': None, 'inputs': {'training_dataset': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553b400>, 'val_dataset': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553bd90>, 'test_dataset': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553b940>, 'target_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553beb0>, 'text_field_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553b6a0>, 'is_test': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553bb80>, 'is_final': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553bb50>, 'is_local': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553b970>, 'is_jump': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553b880>, 'evaluation_strategy': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553bdc0>, 'collect_resource_utilization': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553bdf0>, 'resource_utilization_interval': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553be20>, 'base_checkpoint': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d5538e20>, 'batch_size': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d5539ab0>, 'no_epochs': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553bc70>, 'learning_rate': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d553be80>, 'warmup_steps': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d5538160>, 'weight_decay': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d5518eb0>, 'adam_beta1': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d5518f10>, 'adam_beta2': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d5519f30>, 'adam_epsilon': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f23d5519930>}, 'outputs': {}, 'component': 'azureml_anonymous:2445ab77-4e6a-46d3-a1ba-997055e6f389', 'referenced_control_flow_node_instance_id': None, 'kwargs': {}, 'instance_id': '9c8a7d6a-2901-4686-989a-26d1b44a69a4', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'sampling_algorithm': 'random', 'early_termination': <azure.ai.ml.entities._job.sweep.early_termination_policy.BanditPolicy object at 0x7f23d551bb80>, 'limits': <azure.ai.ml.entities._job.job_limits.SweepJobLimits object at 0x7f23d5538400>, 'search_space': {'base_checkpoint': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f23d5539270>, 'batch_size': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f23d5538940>, 'no_epochs': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f23d553a4a0>, 'learning_rate': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f23d5539990>, 'warmup_steps': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f23d5538070>, 'weight_decay': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f23d5519180>, 'adam_beta1': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f23d5519de0>, 'adam_beta2': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f23d5519a80>, 'adam_epsilon': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f23d5519e10>}, 'objective': <azure.ai.ml.entities._job.sweep.objective.Objective object at 0x7f23d553ad10>, 'identity': None})}, 'job_types': {'sweep': 1}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 1}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'silly_plow_lxlpvt9h6d', 'description': 'The hello world pipeline job.', 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/classicboyir/nlp-aml.git', 'mlflow.source.git.branch': 'v2', 'mlflow.source.git.commit': '1714d09810c5b3444d4d8b22ec3d3ad831ce0a04', 'azureml.git.dirty': 'True', 'azureml.DevPlatv2': 'true', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'id': '/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourceGroups/Learning/providers/Microsoft.MachineLearningServices/workspaces/learningmain/jobs/silly_plow_lxlpvt9h6d', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/hosarsha23/code/Users/hosarsha/nlp-aml', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f23d5519090>, 'serialize': <msrest.serialization.Serializer object at 0x7f23d551b790>, 'display_name': 'pipeline_construction', 'experiment_name': 'transformer_hp_v2', 'compute': None, 'services': {'Tracking': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobService object at 0x7f23d553b370>, 'Studio': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobService object at 0x7f23d553ba60>}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=experiment_name\n",
        ")\n",
        "\n",
        "pipeline_job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "gather": {
          "logged": 1668533997479
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ds_train_set' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazureml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m ScriptRunConfig\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m args \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--target-name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m----> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--training-dataset\u001b[39m\u001b[39m'\u001b[39m, ds_train_set\u001b[39m.\u001b[39mas_named_input(\u001b[39m'\u001b[39m\u001b[39mtrain_set\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--val-dataset\u001b[39m\u001b[39m'\u001b[39m, ds_val_set\u001b[39m.\u001b[39mas_named_input(\u001b[39m'\u001b[39m\u001b[39mval_set\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--test-dataset\u001b[39m\u001b[39m'\u001b[39m, ds_test_set\u001b[39m.\u001b[39mas_named_input(\u001b[39m'\u001b[39m\u001b[39mtest_set\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--text-field\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreviewText\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--is-test\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--is-final\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--is-jump\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--is-local\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--evaluation-strategy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--collect-resource-utilization\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m# \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--resource-utilization-interval\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m5.0\u001b[39m \u001b[39m# seconds\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m ]\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m src \u001b[39m=\u001b[39m ScriptRunConfig(source_directory\u001b[39m=\u001b[39msource_directory,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m                       script\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain_transformer.py\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m                       arguments\u001b[39m=\u001b[39margs,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m                       compute_target\u001b[39m=\u001b[39mcompute_target,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m                       environment\u001b[39m=\u001b[39menv)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ds_train_set' is not defined"
          ]
        }
      ],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "args = [\n",
        "        '--target-name', 'sentiment',\n",
        "        '--training-dataset', ds_train_set.as_named_input('train_set'),\n",
        "        '--val-dataset', ds_val_set.as_named_input('val_set'),\n",
        "        '--test-dataset', ds_test_set.as_named_input('test_set'),\n",
        "        '--text-field', 'reviewText',\n",
        "        '--is-test', 1,\n",
        "        '--is-final', 0,\n",
        "        '--is-jump', 0,\n",
        "        '--is-local', 0,\n",
        "        '--evaluation-strategy', \"epoch\",\n",
        "        '--collect-resource-utilization', 1, # \n",
        "        '--resource-utilization-interval', 5.0 # seconds\n",
        "]\n",
        "\n",
        "src = ScriptRunConfig(source_directory=source_directory,\n",
        "                      script='train_transformer.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=env)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668533997662
        }
      },
      "outputs": [],
      "source": [
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "ps = RandomParameterSampling(\n",
        "    {\n",
        "        # bert-base-cased model could fit into all NC series, but if you're interested in trying larger models, then you need to make sure the VM type can handle the size of the model\n",
        "        '--base-checkpoint': choice(\"bert-base-cased\"), #, \"bert-base-cased\"), # , \"bert-large-cased\", \"microsoft/deberta-v3-small\", \"distilbert-base-uncased\", \"bert-base-uncased\"),\n",
        "        '--batch-size': choice(8),\n",
        "        '--no-epochs': choice(4),\n",
        "        '--learning-rate': choice(5.5e-5, 5e-5, 4.5e-5, 4e-5, 5.5e-5, 6e-5, 3.5e-5, 6.5e-5),\n",
        "        '--warmup-steps': choice(0),\n",
        "        '--weight-decay': choice(0.0),\n",
        "        '--adam-beta1': choice(0.9),\n",
        "        '--adam-beta2': choice(0.999),\n",
        "        '--adam-epsilon': choice(1e-8)\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668533997847
        }
      },
      "outputs": [],
      "source": [
        "policy = BanditPolicy(evaluation_interval=5, slack_factor=0.1)\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                     hyperparameter_sampling=ps,\n",
        "                                     policy=policy,\n",
        "                                     primary_metric_name='eval_f1_weighted',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs=20,\n",
        "                                     max_concurrent_runs=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668533998029
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n",
        "\n",
        "hd_step_name='HyperDrive_Step'\n",
        "hd_step = HyperDriveStep(\n",
        "    name=hd_step_name,\n",
        "    hyperdrive_config=hyperdrive_config,\n",
        "    allow_reuse=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1668533998282
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cpu_compute = ComputeTarget(workspace=ws, name=\"cpu-cluster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1668533998607
        }
      },
      "outputs": [],
      "source": [
        "env_cpu = Environment.get(workspace=ws, name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\")\n",
        "base_env = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN-Text-GPU\")\n",
        "env = base_env.clone(\"nlp-accelerator\")\n",
        "\n",
        "conda_dep = env.python.conda_dependencies\n",
        "conda_dep.add_pip_package('nvitop')\n",
        "\n",
        "env.python.conda_dependencies = conda_dep\n",
        "\n",
        "env.register(ws)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1668533998809
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--is-test', 0,\n",
        "                                                  '--test-run-id', '',\n",
        "                                                  '--metric-name', 'test_f1_weighted',\n",
        "                                                  '--second-metric', 'test_f1',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "# register_model_step.run_after(hd_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "gather": {
          "logged": 1668533998980
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "\n",
        "rcfg = RunConfiguration() # conda_dependencies=conda_dep)\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--endpoint-name', 'sentiment-endpoint-2',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "deploy_model_step.run_after(register_model_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1668534003413
        }
      },
      "outputs": [],
      "source": [
        "exp = Experiment(workspace=ws, name='transformer_hp')\n",
        "steps = [deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "gather": {
          "logged": 1668534009254
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created step Deploy_Latest_Model [29041d0f][86b676f8-33ab-4ef0-933f-cce4a7f83404], (This step will run and generate new outputs)Created step Register_Best_Model [ef3c94c2][acbc100f-c4b1-4791-94ef-821844982d35], (This step will run and generate new outputs)\n",
            "\n",
            "Submitted PipelineRun ffd4451b-385b-4959-abcc-9c2cf408d66d\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/ffd4451b-385b-4959-abcc-9c2cf408d66d?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/learning/workspaces/learningmain&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>transformer_hp</td><td>ffd4451b-385b-4959-abcc-9c2cf408d66d</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/ffd4451b-385b-4959-abcc-9c2cf408d66d?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/learning/workspaces/learningmain&amp;tid=16b3c013-d300-468d-ac64-7eda0820b6d3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: transformer_hp,\n",
              "Id: ffd4451b-385b-4959-abcc-9c2cf408d66d,\n",
              "Type: azureml.PipelineRun,\n",
              "Status: Preparing)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.submit(exp.name) # , credential_passthrough=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668534009820
        }
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "timenow = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "\n",
        "pipeline_name = f\"Sentiment-Classifier-{timenow}-Pipeline\"\n",
        "print(pipeline_name)\n",
        "\n",
        "# published_pipeline = pipeline.publish(\n",
        "#     name=pipeline_name, \n",
        "#     description=pipeline_name)\n",
        "# print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "azureml_py310_sdkv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
