{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.core.runconfig import JarLibrary\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.core.databricks import PyPiLibrary\n",
        "\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import DatabricksStep, PythonScriptStep\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.48.0\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1674086232321
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "nlp-workspace\nopenaml\neastus2\nf9b97038-ed78-4a26-a1a7-51e81e75d867\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1674086232830
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\n",
        "\n",
        "def_blob_store = ws.get_default_datastore()\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Datastore workspaceblobstore will be used\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1674086232984
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_directory = \"./project\""
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1674086233150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"gpu-cluster\"\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1674086233368
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile conda_dependencies.yml\n",
        "# \n",
        "# channels:\n",
        "#   - pytorch\n",
        "#   - anaconda\n",
        "#   - conda-forge\n",
        "# dependencies:\n",
        "#   - python=3.7\n",
        "#   - pip=21.1.2\n",
        "#   - pip:\n",
        "#       - azureml-core==1.44.0\n",
        "#       - azureml-mlflow==1.44.0\n",
        "#       - azureml-automl-core==1.44.0\n",
        "#       - azureml-automl-dnn-nlp==1.44.0\n",
        "#       - azureml-responsibleai==1.44.0\n",
        "#       - azureml-automl-runtime==1.44.0\n",
        "#       - azureml-train-automl-client==1.44.0\n",
        "#       - azureml-train-automl-runtime==1.44.0\n",
        "#       - horovod==0.21.3\n",
        "#   - numpy~=1.18.5\n",
        "#   - pandas~=1.1.5\n",
        "#   - scikit-learn~=0.22.1\n",
        "#   - pytorch==1.7.1"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1674086233542
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'nlp-accelerator' not in ws.environments:\n",
        "    base_env = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN-Text-GPU\")\n",
        "    env = base_env.clone(\"nlp-accelerator\")\n",
        "\n",
        "    conda_dep = env.python.conda_dependencies\n",
        "    conda_dep.add_pip_package('nvitop')\n",
        "\n",
        "    env.python.conda_dependencies = conda_dep\n",
        "\n",
        "    env.register(ws)\n",
        "else:\n",
        "    env = Environment.get(workspace=ws, name=\"nlp-accelerator\")\n"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1674086233844
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to get larger datasets: http://jmcauley.ucsd.edu/data/amazon/"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1674086234005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz -P data/"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "--2023-01-18 23:57:14--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz\nResolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\nConnecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4669048 (4.5M) [application/x-gzip]\nSaving to: ‘data/reviews_Automotive_5.json.gz.69’\n\nreviews_Automotive_ 100%[===================>]   4.45M  1.95MB/s    in 2.3s    \n\n2023-01-18 23:57:17 (1.95 MB/s) - ‘data/reviews_Automotive_5.json.gz.69’ saved [4669048/4669048]\n\n"
        }
      ],
      "execution_count": 36,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "pdf_main = getDF('data/reviews_Automotive_5.json.gz')\n",
        "pdf_main.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "(20473, 9)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1674086238720
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_main.loc[pdf_main['overall'] >= 4, 'sentiment'] = 1\n",
        "pdf_main.loc[pdf_main['overall'] < 3, 'sentiment'] = 0\n",
        "\n",
        "pdf_main.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "       reviewerID        asin     reviewerName   helpful  \\\n0  A3F73SC1LY51OO  B00002243X  Alan Montgomery    [4, 4]   \n1  A20S66SKYXULG2  B00002243X         alphonse    [1, 1]   \n2  A2I8LFSN2IS5EO  B00002243X            Chris    [0, 0]   \n3  A3GT2EWQSO45ZG  B00002243X           DeusEx  [19, 19]   \n4  A3ESWJPAVRPWB4  B00002243X     E. Hernandez    [0, 0]   \n\n                                          reviewText  overall  \\\n0  I needed a set of jumper cables for my new car...      5.0   \n1  These long cables work fine for my truck, but ...      4.0   \n2  Can't comment much on these since they have no...      5.0   \n3  I absolutley love Amazon!!!  For the price of ...      5.0   \n4  I purchased the 12' feet long cable set and th...      5.0   \n\n                                      summary  unixReviewTime   reviewTime  \\\n0  Work Well - Should Have Bought Longer Ones      1313539200  08 17, 2011   \n1                            Okay long cables      1315094400   09 4, 2011   \n2                  Looks and feels heavy Duty      1374710400  07 25, 2013   \n3       Excellent choice for Jumper Cables!!!      1292889600  12 21, 2010   \n4      Excellent, High Quality Starter Cables      1341360000   07 4, 2012   \n\n   sentiment  \n0        1.0  \n1        1.0  \n2        1.0  \n3        1.0  \n4        1.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>reviewerName</th>\n      <th>helpful</th>\n      <th>reviewText</th>\n      <th>overall</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>reviewTime</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A3F73SC1LY51OO</td>\n      <td>B00002243X</td>\n      <td>Alan Montgomery</td>\n      <td>[4, 4]</td>\n      <td>I needed a set of jumper cables for my new car...</td>\n      <td>5.0</td>\n      <td>Work Well - Should Have Bought Longer Ones</td>\n      <td>1313539200</td>\n      <td>08 17, 2011</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A20S66SKYXULG2</td>\n      <td>B00002243X</td>\n      <td>alphonse</td>\n      <td>[1, 1]</td>\n      <td>These long cables work fine for my truck, but ...</td>\n      <td>4.0</td>\n      <td>Okay long cables</td>\n      <td>1315094400</td>\n      <td>09 4, 2011</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A2I8LFSN2IS5EO</td>\n      <td>B00002243X</td>\n      <td>Chris</td>\n      <td>[0, 0]</td>\n      <td>Can't comment much on these since they have no...</td>\n      <td>5.0</td>\n      <td>Looks and feels heavy Duty</td>\n      <td>1374710400</td>\n      <td>07 25, 2013</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A3GT2EWQSO45ZG</td>\n      <td>B00002243X</td>\n      <td>DeusEx</td>\n      <td>[19, 19]</td>\n      <td>I absolutley love Amazon!!!  For the price of ...</td>\n      <td>5.0</td>\n      <td>Excellent choice for Jumper Cables!!!</td>\n      <td>1292889600</td>\n      <td>12 21, 2010</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A3ESWJPAVRPWB4</td>\n      <td>B00002243X</td>\n      <td>E. Hernandez</td>\n      <td>[0, 0]</td>\n      <td>I purchased the 12' feet long cable set and th...</td>\n      <td>5.0</td>\n      <td>Excellent, High Quality Starter Cables</td>\n      <td>1341360000</td>\n      <td>07 4, 2012</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1674086238929
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_datasets(pdf_target_training, label = 'sentiment'):\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(pdf_target_training.drop(label, axis=1), pdf_target_training[label],\n",
        "                                                        stratify=pdf_target_training[label],\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.20)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        "                                                        stratify=y_test_val,\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.5)\n",
        "    pdf_X_train = X_train\n",
        "    pdf_X_val = X_val\n",
        "    pdf_X_test = X_test\n",
        "\n",
        "    pdf_X_train['sentiment'] = y_train\n",
        "    pdf_X_val['sentiment'] = y_val\n",
        "    pdf_X_test['sentiment'] = y_test\n",
        "    \n",
        "    print(f'Total records for: \"pdf_X_train\": [{pdf_X_train.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_val\": [{pdf_X_val.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_test\": [{pdf_X_test.shape[0]}]')\n",
        "    \n",
        "    return pdf_X_train, pdf_X_val, pdf_X_test"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1674086239108
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_train, pdf_val, pdf_test = generate_datasets(pdf_main[['reviewText', 'sentiment']].dropna(), 'sentiment')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1674086239386
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def_blob_store = ws.get_default_datastore()\n",
        "\n",
        "ds_train_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_train, target=(def_blob_store, 'nlp'), name=\"train_set\", description=\"Small amazon review for sentiment analysis [train set]\")\n",
        "ds_val_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_val, target=(def_blob_store, 'nlp'), name=\"val_set\", description=\"Small amazon review for sentiment analysis [val set]\")\n",
        "ds_test_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_test, target=(def_blob_store, 'nlp'), name=\"test_set\", description=\"Small amazon review for sentiment analysis [test set]\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to nlp/d2cb00f3-4bf6-43bb-b42c-e531686831e2/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\nValidating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to nlp/7c63efb6-63b2-4e4b-bd8f-2705255e5f1b/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\nValidating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to nlp/8a1efe33-5a0e-46bc-ba47-f46c7a448bb3/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1674086240878
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "args = [\n",
        "        '--target-name', 'sentiment',\n",
        "        '--training-dataset', ds_train_set.as_named_input('train_set'),\n",
        "        '--val-dataset', ds_val_set.as_named_input('val_set'),\n",
        "        '--test-dataset', ds_test_set.as_named_input('test_set'),\n",
        "        '--text-field', 'reviewText',\n",
        "        '--is-test', 1,\n",
        "        '--is-final', 0,\n",
        "        '--is-jump', 0,\n",
        "        '--is-local', 0,\n",
        "        '--evaluation-strategy', \"epoch\",\n",
        "        '--collect-resource-utilization', 1, # \n",
        "        '--resource-utilization-interval', 5.0 # seconds\n",
        "]\n",
        "\n",
        "src = ScriptRunConfig(source_directory=source_directory,\n",
        "                      script='train_transformer.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=env)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:You might see network latency and increased data transfer costs if you chose a cluster in a location different from the location of your workspace\n"
        }
      ],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1674086241039
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "ps = RandomParameterSampling(\n",
        "    {\n",
        "        # bert-base-cased model could fit into all NC series, but if you're interested in trying larger models, then you need to make sure the VM type can handle the size of the model\n",
        "        '--base-checkpoint': choice(\"bert-base-cased\"), #, \"bert-base-cased\"), # , \"bert-large-cased\", \"microsoft/deberta-v3-small\", \"distilbert-base-uncased\", \"bert-base-uncased\"),\n",
        "        '--batch-size': choice(8),\n",
        "        '--no-epochs': choice(4),\n",
        "        '--learning-rate': choice(5.5e-5, 5e-5, 4.5e-5, 4e-5, 5.5e-5, 6e-5, 3.5e-5, 6.5e-5),\n",
        "        '--warmup-steps': choice(0),\n",
        "        '--weight-decay': choice(0.0),\n",
        "        '--adam-beta1': choice(0.9),\n",
        "        '--adam-beta2': choice(0.999),\n",
        "        '--adam-epsilon': choice(1e-8)\n",
        "    }\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1674086241211
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy = BanditPolicy(evaluation_interval=5, slack_factor=0.1)\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                     hyperparameter_sampling=ps,\n",
        "                                     policy=policy,\n",
        "                                     primary_metric_name='test_AUC_weighted',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs=20,\n",
        "                                     max_concurrent_runs=3)\n"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1674086241397
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n",
        "\n",
        "hd_step_name='HyperDrive_Step'\n",
        "hd_step = HyperDriveStep(\n",
        "    name=hd_step_name,\n",
        "    hyperdrive_config=hyperdrive_config,\n",
        "    allow_reuse=True)\n"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1674086241572
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add AutoML Step \n",
        "Compare results from AutoML steps"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import TrainingOutput, PipelineData\n",
        "\n",
        "metrics_data = PipelineData(name='metrics_data',\n",
        "                            datastore=def_blob_store,\n",
        "                            pipeline_output_name='metrics_output',\n",
        "                            training_output=TrainingOutput(type='Metrics'))\n",
        "\n",
        "model_data = PipelineData(name='best_model_data',\n",
        "                          datastore=def_blob_store,\n",
        "                          pipeline_output_name='model_output',\n",
        "                          training_output=TrainingOutput(type='Model'))"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1674086241747
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## AutoML Parameters\n",
        "\n",
        "```json\n",
        "{ \"experiment_timeout_minutes\": 120,\n",
        "    \"primary_metric\": \"accuracy\",\n",
        "    \"primary_metric\" : \"AUC_weighted\",\n",
        "    \"iteration_timeout_minutes\" : 10,\n",
        "    \"iterations\" : 20,\n",
        "    \"experiment_timeout_hours\" : 1,\n",
        "    \"max_concurrent_iterations\": 1,\n",
        "    \"max_cores_per_iteration\": -1,\n",
        "    \"enable_early_stopping\": \"True\",\n",
        "    \"enable_dnn\": \"True\",\n",
        "    \"blacklist_algos\":[\"TensorFlowDNN\",\"TensorFlowLinearRegressor\"],\n",
        "    \"max_concurrent_iterations\": 1,\n",
        "    \"enable_batch_run\":\"False\",\n",
        "    \"enable_dnn\": \"true\",\n",
        "     \"model_explainability\" : \"True\"\n",
        "}\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "automl_settings = {\n",
        "    \"verbosity\": logging.INFO,\n",
        "    \"experiment_timeout_minutes\": 240,\n",
        "    \"primary_metric\": \"AUC_weighted\",\n",
        "    \"enable_early_stopping\" : \"true\",\n",
        "    #\"ensemble_iterations\" : 3,\n",
        "    #\"enable_stack_ensembling\" : \"true\",\n",
        "    #\"enable_ensembling\" : \"true\",\n",
        "    \"save_mlflow\": \"true\",\n",
        "    #\"max_cores_per_iteration\": -1,\n",
        "    #\"max_concurrent_iterations\": 3,\n",
        "    \"send_telemetry\" : \"true\",\n",
        "    #\"experiment_timeout_minutes\": 1440,\n",
        "    #\"iteration_timeout_minutes\": 1440,\n",
        "    \"many_models\": True,\n",
        "    #\"pipeline_fetch_max_batch_size\": 15,\n",
        "    #\"iteration_timeout_minutes\" : 30,\n",
        "    #\"iterations\" : 5 \n",
        "}\n",
        "\n",
        "target_column_name = \"sentiment\"\n",
        "\n",
        "automl_config = AutoMLConfig(\n",
        "    task=\"text-classification\",\n",
        "    debug_log=\"automl_errors.log\",\n",
        "    compute_target=compute_target,\n",
        "    training_data=ds_train_set ,\n",
        "    validation_data=ds_val_set ,\n",
        "    featurization = 'auto',\n",
        "    label_column_name=target_column_name,\n",
        "#    blocked_models=[\"TensorFlowDNN\", \"TensorFlowLinearRegressor\"],\n",
        "    **automl_settings\n",
        ")\n",
        "\n",
        "\n",
        "automl_step = AutoMLStep(name='AutoML_Classification',\n",
        "    automl_config=automl_config,\n",
        "    passthru_automl_config=False,\n",
        "    outputs=[metrics_data,model_data],\n",
        "    enable_default_model_output=False,\n",
        "    enable_default_metrics_output=False,\n",
        "    allow_reuse=True)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:save_mlflow is an internal parameter that should not be used for regular experiments.\n"
        }
      ],
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1674086241932
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Test AutoML Trained Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env\n",
        "\n",
        "test_automl_step = PythonScriptStep(script_name='test_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Test_AutoML_Best_Model\",\n",
        "                                       compute_target=compute_target,\n",
        "                                       arguments=[\n",
        "                                                  '--metric-name', 'AUC_weighted',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--text-field-name', 'reviewText',\n",
        "                                                  '--test_dataset', ds_test_set.as_named_input('test_dataset'),\n",
        "                                                  '--model-data', model_data\n",
        "                                                 \n",
        "                                                 ],\n",
        "                                       inputs=[ model_data],          \n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "\n",
        "\n",
        "test_automl_step.run_after(automl_step)"
      ],
      "outputs": [],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1674086242119
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cpu_compute = ComputeTarget(workspace=ws, name=\"cpu-cluster\")"
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1674086242358
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_cpu = Environment.get(workspace=ws, name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\")"
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1674086242632
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--is-test', 0,\n",
        "                                                  '--test-run-id', '',\n",
        "                                                  '--metric-name', 'test_AUC_weighted',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "\n",
        "\n",
        "register_model_step.run_after(test_automl_step)\n",
        "register_model_step.run_after(hd_step)\n"
      ],
      "outputs": [],
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1674086242808
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--endpoint-name', 'sentiment-endpoint-2',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "deploy_model_step.run_after(register_model_step)\n"
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1674086242976
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp = Experiment(workspace=ws, name='transformer_hp')\n",
        "steps = [deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:azureml._base_sdk_common._docstring_wrapper:Class KubernetesCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1085, in emit\n    self.flush()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1065, in flush\n    self.stream.flush()\nOSError: [Errno 9] Bad file descriptor\nCall stack:\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n    app.start()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/asyncio/events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n    await self.process_one()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 450, in process_one\n    await dispatch(*args)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n    await result\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n    reply_content = await reply_content\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 359, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n    result = self._run_cell(\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n    return runner(coro)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_6019/1128835912.py\", line 3, in <cell line: 3>\n    pipeline = Pipeline(workspace=ws, steps=steps)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/_experiment_method.py\", line 104, in wrapper\n    return init_func(self, *args, **kwargs)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/pipeline.py\", line 180, in __init__\n    self._graph = self._graph_builder.build(self._name, steps, finalize=False)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1497, in build\n    graph = self.construct(name, steps)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1519, in construct\n    self.process_collection(steps)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1555, in process_collection\n    builder.process_collection(collection)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1846, in process_collection\n    self._base_builder.process_collection(item)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1549, in process_collection\n    return self.process_step(collection)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1607, in process_step\n    resolved_nodes.extend(self.process_step(predecessor_step))\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1607, in process_step\n    resolved_nodes.extend(self.process_step(predecessor_step))\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1599, in process_step\n    resolved_nodes = self.resolve_references([node])\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1673, in resolve_references\n    added_nodes.extend(self.process_step(peer))\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1593, in process_step\n    node = step.create_node(self._graph, self._default_datastore, self._context)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/steps/automl_step.py\", line 331, in create_node\n    settings = self._get_automl_settings(context)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/steps/automl_step.py\", line 515, in _get_automl_settings\n    dataprep_json = dataset_utilities.\\\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/core/dataset_utilities.py\", line 117, in get_datasets_json\n    dataset_json = _save_datasets_to_json(dataset_dict)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/core/dataset_utilities.py\", line 255, in _save_datasets_to_json\n    module_logger.info(\"JSON serialization of input of type {} is un-supported.\".format(type(dataset)))\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1434, in info\n    self._log(INFO, msg, args, **kwargs)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1577, in _log\n    self.handle(record)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1587, in handle\n    self.callHandlers(record)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1649, in callHandlers\n    hdlr.handle(record)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 950, in handle\n    self.emit(record)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/core/_logging/log_server.py\", line 93, in emit\n    handler.emit(record)\nMessage: \"JSON serialization of input of type <class 'NoneType'> is un-supported.\"\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1085, in emit\n    self.flush()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1065, in flush\n    self.stream.flush()\nOSError: [Errno 9] Bad file descriptor\nCall stack:\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n    app.start()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/asyncio/events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n    await self.process_one()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 450, in process_one\n    await dispatch(*args)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n    await result\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n    reply_content = await reply_content\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 359, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n    result = self._run_cell(\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n    return runner(coro)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_6019/1128835912.py\", line 3, in <cell line: 3>\n    pipeline = Pipeline(workspace=ws, steps=steps)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/_experiment_method.py\", line 104, in wrapper\n    return init_func(self, *args, **kwargs)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/pipeline.py\", line 180, in __init__\n    self._graph = self._graph_builder.build(self._name, steps, finalize=False)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1497, in build\n    graph = self.construct(name, steps)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1519, in construct\n    self.process_collection(steps)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1555, in process_collection\n    builder.process_collection(collection)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1846, in process_collection\n    self._base_builder.process_collection(item)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1549, in process_collection\n    return self.process_step(collection)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1607, in process_step\n    resolved_nodes.extend(self.process_step(predecessor_step))\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1607, in process_step\n    resolved_nodes.extend(self.process_step(predecessor_step))\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1599, in process_step\n    resolved_nodes = self.resolve_references([node])\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1673, in resolve_references\n    added_nodes.extend(self.process_step(peer))\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1593, in process_step\n    node = step.create_node(self._graph, self._default_datastore, self._context)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/steps/automl_step.py\", line 331, in create_node\n    settings = self._get_automl_settings(context)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/steps/automl_step.py\", line 534, in _get_automl_settings\n    driver_utilities.validate_input(experiment_state, parent_run_dto)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/_experiment_drivers/driver_utilities.py\", line 124, in validate_input\n    logger.info(\"Start data validation.\")\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1434, in info\n    self._log(INFO, msg, args, **kwargs)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1577, in _log\n    self.handle(record)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1587, in handle\n    self.callHandlers(record)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1649, in callHandlers\n    hdlr.handle(record)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 950, in handle\n    self.emit(record)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/core/_logging/log_server.py\", line 93, in emit\n    handler.emit(record)\nMessage: 'Start data validation.'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1085, in emit\n    self.flush()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1065, in flush\n    self.stream.flush()\nOSError: [Errno 9] Bad file descriptor\nCall stack:\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n    app.start()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/asyncio/events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n    await self.process_one()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 450, in process_one\n    await dispatch(*args)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n    await result\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n    reply_content = await reply_content\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 359, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n    result = self._run_cell(\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n    return runner(coro)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_6019/1128835912.py\", line 3, in <cell line: 3>\n    pipeline = Pipeline(workspace=ws, steps=steps)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/_experiment_method.py\", line 104, in wrapper\n    return init_func(self, *args, **kwargs)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/pipeline.py\", line 180, in __init__\n    self._graph = self._graph_builder.build(self._name, steps, finalize=False)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1497, in build\n    graph = self.construct(name, steps)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1519, in construct\n    self.process_collection(steps)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1555, in process_collection\n    builder.process_collection(collection)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1846, in process_collection\n    self._base_builder.process_collection(item)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1549, in process_collection\n    return self.process_step(collection)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1607, in process_step\n    resolved_nodes.extend(self.process_step(predecessor_step))\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1607, in process_step\n    resolved_nodes.extend(self.process_step(predecessor_step))\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1599, in process_step\n    resolved_nodes = self.resolve_references([node])\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1673, in resolve_references\n    added_nodes.extend(self.process_step(peer))\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\", line 1593, in process_step\n    node = step.create_node(self._graph, self._default_datastore, self._context)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/steps/automl_step.py\", line 331, in create_node\n    settings = self._get_automl_settings(context)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/steps/automl_step.py\", line 534, in _get_automl_settings\n    driver_utilities.validate_input(experiment_state, parent_run_dto)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/_experiment_drivers/driver_utilities.py\", line 137, in validate_input\n    logger.info(\"Validation service found the data has no errors.\")\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1434, in info\n    self._log(INFO, msg, args, **kwargs)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1577, in _log\n    self.handle(record)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1587, in handle\n    self.callHandlers(record)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 1649, in callHandlers\n    hdlr.handle(record)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/logging/__init__.py\", line 950, in handle\n    self.emit(record)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/core/_logging/log_server.py\", line 93, in emit\n    handler.emit(record)\nMessage: 'Validation service found the data has no errors.'\nArguments: ()\n"
        }
      ],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1674086243228
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.submit(exp.name) #, credential_passthrough=True)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step Deploy_Latest_Model [06d961d9][cb5c9f91-4eb9-42d7-a807-1637a4a76ff4], (This step is eligible to reuse a previous run's output)\nCreated step Register_Best_Model [618e1472][7e7c047c-9676-4af5-bbb0-707b996b68ee], (This step is eligible to reuse a previous run's output)\nCreated step Test_AutoML_Best_Model [f8343973][768e3e9c-58d0-4c0d-bd79-dccccfd8afec], (This step is eligible to reuse a previous run's output)\nCreated step AutoML_Classification [e91c065a][0181d052-72f7-42df-a5f9-939fc1616a19], (This step will run and generate new outputs)Created step HyperDrive_Step [87b5dc07][57fe8577-3714-4a80-b850-e7ec29e7c6bd], (This step is eligible to reuse a previous run's output)\n\nSubmitted PipelineRun 96ffe0c1-0cd7-4169-835e-d0c708672071\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/96ffe0c1-0cd7-4169-835e-d0c708672071?wsid=/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourcegroups/openaml/workspaces/nlp-workspace&tid=4460d6c7-3cdd-4d85-bda4-87c85c98af04\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 54,
          "data": {
            "text/plain": "Run(Experiment: transformer_hp,\nId: 96ffe0c1-0cd7-4169-835e-d0c708672071,\nType: azureml.PipelineRun,\nStatus: Preparing)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>transformer_hp</td><td>96ffe0c1-0cd7-4169-835e-d0c708672071</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/96ffe0c1-0cd7-4169-835e-d0c708672071?wsid=/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourcegroups/openaml/workspaces/nlp-workspace&amp;tid=4460d6c7-3cdd-4d85-bda4-87c85c98af04\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1674086254277
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "timenow = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "\n",
        "pipeline_name = f\"Sentiment-Classifier-{timenow}-Pipeline\"\n",
        "print(pipeline_name)\n",
        "\n",
        "published_pipeline = pipeline.publish(\n",
        "    name=pipeline_name, \n",
        "    description=pipeline_name)\n",
        "print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sentiment-Classifier-2023-01-18-23-57-Pipeline\nNewly published pipeline id: 08465d7f-0b8f-4819-af8b-edbbce327556\n"
        }
      ],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1674086254839
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}