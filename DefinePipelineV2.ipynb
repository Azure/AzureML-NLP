{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1668533978662
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dac8073e-1c2d-4a7d-a53b-c3655e291d58\n",
            "Learning\n",
            "learningmain\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Enter details of your AML workspace\n",
        "subscription_id = \"dac8073e-1c2d-4a7d-a53b-c3655e291d58\"\n",
        "resource_group = \"Learning\"\n",
        "workspace = \"learningmain\"\n",
        "\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")\n",
        "\n",
        "print(ml_client.subscription_id, ml_client.resource_group_name, ml_client.workspace_name, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-24 18:38:15--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4669048 (4.5M) [application/x-gzip]\n",
            "Saving to: ‘data/reviews_Automotive_5.json.gz.19’\n",
            "\n",
            "reviews_Automotive_ 100%[===================>]   4.45M  1.69MB/s    in 2.6s    \n",
            "\n",
            "2023-01-24 18:38:19 (1.69 MB/s) - ‘data/reviews_Automotive_5.json.gz.19’ saved [4669048/4669048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# to get larger datasets, visit: http://jmcauley.ucsd.edu/data/amazon/\n",
        "\n",
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz -P data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20473, 9)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "pdf_main = getDF('data/reviews_Automotive_5.json.gz')\n",
        "pdf_main.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20473.000000</td>\n",
              "      <td>2.047300e+04</td>\n",
              "      <td>19043.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.471841</td>\n",
              "      <td>1.365018e+09</td>\n",
              "      <td>0.939715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.940337</td>\n",
              "      <td>3.621266e+07</td>\n",
              "      <td>0.238020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.121386e+09</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.354838e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.373414e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.390435e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.405901e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            overall  unixReviewTime     sentiment\n",
              "count  20473.000000    2.047300e+04  19043.000000\n",
              "mean       4.471841    1.365018e+09      0.939715\n",
              "std        0.940337    3.621266e+07      0.238020\n",
              "min        1.000000    1.121386e+09      0.000000\n",
              "25%        4.000000    1.354838e+09      1.000000\n",
              "50%        5.000000    1.373414e+09      1.000000\n",
              "75%        5.000000    1.390435e+09      1.000000\n",
              "max        5.000000    1.405901e+09      1.000000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_main.loc[pdf_main['overall'] >= 4, 'sentiment'] = 1\n",
        "pdf_main.loc[pdf_main['overall'] < 3, 'sentiment'] = 0\n",
        "\n",
        "pdf_main.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_datasets(pdf_target_training, label = 'sentiment'):\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(pdf_target_training.drop(label, axis=1), pdf_target_training[label],\n",
        "                                                        stratify=pdf_target_training[label],\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.20)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        "                                                        stratify=y_test_val,\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.5)\n",
        "    pdf_X_train = X_train\n",
        "    pdf_X_val = X_val\n",
        "    pdf_X_test = X_test\n",
        "\n",
        "    pdf_X_train['sentiment'] = y_train\n",
        "    pdf_X_val['sentiment'] = y_val\n",
        "    pdf_X_test['sentiment'] = y_test\n",
        "    \n",
        "    print(f'Total records for: \"pdf_X_train\": [{pdf_X_train.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_val\": [{pdf_X_val.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_test\": [{pdf_X_test.shape[0]}]')\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "    return pdf_X_train, pdf_X_val, pdf_X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records for: \"pdf_X_train\": [15234]\n",
            "Total records for: \"pdf_X_val\": [1904]\n",
            "Total records for: \"pdf_X_test\": [1905]\n"
          ]
        }
      ],
      "source": [
        "pdf_train, pdf_val, pdf_test = generate_datasets(pdf_main[['reviewText', 'sentiment']].dropna(), 'sentiment')\n",
        "\n",
        "pdf_train.to_csv('data/pdf_train.csv')\n",
        "pdf_val.to_csv('data/pdf_val.csv')\n",
        "pdf_test.to_csv('data/pdf_test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# === Note on path ===\n",
        "# can be can be a local path or a cloud path. AzureML supports https://`, `abfss://`, `wasbs://` and `azureml://` URIs.\n",
        "# Local paths are automatically uploaded to the default datastore in the cloud.\n",
        "# More details on supported paths: https://docs.microsoft.com/azure/machine-learning/how-to-read-write-data-v2#supported-paths\n",
        "\n",
        "def gen_input_data(url):\n",
        "    return Input(type=AssetTypes.URI_FILE, path=url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_train = gen_input_data('data/pdf_train.csv')\n",
        "ds_val = gen_input_data('data/pdf_val.csv')\n",
        "ds_test = gen_input_data('data/pdf_test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1668533982929
        }
      },
      "outputs": [],
      "source": [
        "source_directory = \"./project_v2/\"\n",
        "experiment_name = 'transformer_hp_v2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1668533983332
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting environments/conda_dependencies.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile environments/conda_dependencies.yml\n",
        "\n",
        "channels:\n",
        "  - pytorch\n",
        "  - anaconda\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.7\n",
        "  - pip=21.1.2\n",
        "  - pip:\n",
        "      - azure-ai-ml==1.2.0\n",
        "      - mlflow== 1.26.1\n",
        "      - azureml-mlflow==1.42.0\n",
        "      - nvitop\n",
        "      - transformers\n",
        "      - inference-schema\n",
        "      - joblib\n",
        "      - datasets\n",
        "  - numpy~=1.21.6\n",
        "  - pandas~=1.1.5\n",
        "  - shap=0.39.0\n",
        "  - scikit-learn~=0.22.1\n",
        "  - pytorch==1.7.1\n",
        "name: nlp_training_environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "env_name = 'nlp-accelerator-sdk-v2'\n",
        "env_list = list(ml_client.environments.list(name=env_name)) # (name=\"nlp-accelerator-sdk-v2\", version='3')\n",
        "if len(env_list) > 0:\n",
        "    env = env_list[0]\n",
        "else:\n",
        "    env = Environment(\n",
        "        image=\"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu20.04:latest\",\n",
        "        conda_file='environments/conda_dependencies.yml',\n",
        "        name=env_name,\n",
        "        description='This environment is curated to run NLP Transformer based models using AML SDK-v2 and native MLFlow integration'\n",
        "    )\n",
        "\n",
        "    ml_client.environments.create_or_update(env)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "gather": {
          "logged": 1668533987254
        }
      },
      "outputs": [],
      "source": [
        "cluster_name = \"a100-cluster\"\n",
        "compute_target = ml_client.compute.get(cluster_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "cpu_compute_target = ml_client.compute.get(\"cpu-cluster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "job_train = command(\n",
        "    inputs=dict(\n",
        "        training_dataset=ds_train,\n",
        "        val_dataset=ds_val,\n",
        "        test_dataset=ds_test,\n",
        "        target_name='sentiment', \n",
        "        text_field_name='reviewText',\n",
        "        is_test=1,\n",
        "        is_final=0,\n",
        "        is_local=0,\n",
        "        is_jump=0,\n",
        "        evaluation_strategy='epoch',\n",
        "        collect_resource_utilization=1,\n",
        "        resource_utilization_interval=5.0, # seconds\n",
        "        base_checkpoint='bert-base-cased',\n",
        "        batch_size=8,\n",
        "        no_epochs=4,\n",
        "        learning_rate=5.5e-5,\n",
        "        warmup_steps=0,\n",
        "        weight_decay=0.0,\n",
        "        adam_beta1=0.9,\n",
        "        adam_beta2=0.999,\n",
        "        adam_epsilon=1e-8\n",
        "    ),\n",
        "    outputs=dict(\n",
        "        model_output=Output(type=\"custom_model\")\n",
        "    ),\n",
        "    compute=compute_target,\n",
        "    environment=env,\n",
        "    code=source_directory, # location of source code\n",
        "    command=\"\"\"\n",
        "    python train_transformer.py \\\n",
        "        --collect-resource-utilization ${{inputs.collect_resource_utilization}} \\\n",
        "        --resource-utilization-interval ${{inputs.resource_utilization_interval}} \\\n",
        "        --target-name ${{inputs.target_name}} \\\n",
        "        --training-dataset ${{inputs.training_dataset}} \\\n",
        "        --val-dataset ${{inputs.val_dataset}} \\\n",
        "        --test-dataset ${{inputs.test_dataset}} \\\n",
        "        --model-path ${{outputs.model_output}} \\\n",
        "        --text-field-name ${{inputs.text_field_name}} \\\n",
        "        --is-test ${{inputs.is_test}} \\\n",
        "        --is-final ${{inputs.is_final}} \\\n",
        "        --is-local ${{inputs.is_local}} \\\n",
        "        --is-jump ${{inputs.is_jump}} \\\n",
        "        --evaluation-strategy ${{inputs.evaluation_strategy}} \\\n",
        "        --base-checkpoint ${{inputs.base_checkpoint}} \\\n",
        "        --batch-size ${{inputs.batch_size}} \\\n",
        "        --no-epochs ${{inputs.no_epochs}} \\\n",
        "        --learning-rate ${{inputs.learning_rate}} \\\n",
        "        --warmup-steps ${{inputs.warmup_steps}} \\\n",
        "        --weight-decay ${{inputs.weight_decay}} \\\n",
        "        --adam-beta1 ${{inputs.adam_beta1}} \\\n",
        "        --adam-beta2 ${{inputs.adam_beta2}} \\\n",
        "        --adam-epsilon ${{inputs.adam_epsilon}}\n",
        "    \"\"\",\n",
        "    display_name=\"HyperDrive_Step\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.sweep import Choice, BanditPolicy\n",
        "\n",
        "# we will reuse the command_job created before. we call it as a function so that we can apply inputs\n",
        "job_train_for_sweep = job_train(\n",
        "    base_checkpoint=Choice([\"bert-base-cased\"]), #, \"bert-base-cased\"]), # , \"bert-large-cased\", \"microsoft/deberta-v3-small\", \"distilbert-base-uncased\", \"bert-base-uncased\"]),\n",
        "    batch_size=Choice([8]),\n",
        "    no_epochs=Choice([4]),\n",
        "    learning_rate=Choice([5.5e-5, 5e-5, 4.5e-5, 4e-5, 5.5e-5, 6e-5, 3.5e-5, 6.5e-5]),\n",
        "    warmup_steps=Choice([0]),\n",
        "    weight_decay=Choice([0.0]),\n",
        "    adam_beta1=Choice([0.9]),\n",
        "    adam_beta2=Choice([0.999]),\n",
        "    adam_epsilon=Choice([1e-8])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting environments/conda_dependencies_cpu_v2.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile environments/conda_dependencies_cpu_v2.yml\n",
        "\n",
        "channels:\n",
        "  - pytorch\n",
        "  - anaconda\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.7\n",
        "  - pip\n",
        "  - pip:\n",
        "      - azure-ai-ml\n",
        "      - mlflow\n",
        "      - azureml-mlflow\n",
        "      - nvitop\n",
        "      - transformers\n",
        "      - joblib\n",
        "      - datasets\n",
        "  - numpy\n",
        "  - pandas\n",
        "  - shap\n",
        "  - scikit-learn\n",
        "name: sdk_v2_cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "env_name_non_gpu = 'sdk-v2-cpu'\n",
        "\n",
        "try:\n",
        "    env_list = list(ml_client.environments.list(name=env_name_non_gpu)) # (name=\"nlp-accelerator-sdk-v2\", version='3')\n",
        "    env_v2 = env_list[0]\n",
        "except:\n",
        "    env_v2 = Environment(\n",
        "        image=\"mcr.microsoft.com/azureml/curated/sklearn-0.24-ubuntu18.04-py37-cpu:latest\",\n",
        "        conda_file='environments/conda_dependencies_cpu_v2.yml',\n",
        "        name=env_name_non_gpu,\n",
        "        description='This environment is curated to run sdk v2 for cpu base use-cases'\n",
        "    )\n",
        "\n",
        "    ml_client.environments.create_or_update(env_v2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name='sentiment_classifier_sdk_v2'\n",
        "\n",
        "job_register = command(\n",
        "    inputs=dict(\n",
        "        model_path=Input(type=\"custom_model\"),\n",
        "        model_name=model_name,\n",
        "        subscription_id=subscription_id,\n",
        "        resource_group=resource_group,\n",
        "        workspace=workspace\n",
        "    ),\n",
        "    outputs=dict(\n",
        "        linkage_data=Output(type=\"custom_model\")\n",
        "    ),\n",
        "    compute=cpu_compute_target,\n",
        "    # environment='AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest', # list(ml_client.environments.list(name='\"AzureML-pytorch-1.9-ubuntu18.04-py37-cuda11-gpu@latest\"'))[0],\n",
        "    environment=env_v2,\n",
        "    code=source_directory, # location of source code\n",
        "    command=\"\"\"\n",
        "    python register_model.py \\\n",
        "        --model-path ${{inputs.model_path}} \\\n",
        "        --model-name ${{inputs.model_name}} \\\n",
        "        --subscription-id ${{inputs.subscription_id}} \\\n",
        "        --resource-group ${{inputs.resource_group}} \\\n",
        "        --workspace ${{inputs.workspace}} \\\n",
        "        --model-data ${{outputs.linkage_data}}\n",
        "    \"\"\",\n",
        "    display_name=\"Register_Best_Model\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_deploy = command(\n",
        "    inputs=dict(\n",
        "        endpoint_name='sentiment-endpoint-sdkv2',\n",
        "        linkage_data=Input(type=\"custom_model\"),\n",
        "        model_name=model_name,\n",
        "        environment_name=env_name,\n",
        "        subscription_id=subscription_id,\n",
        "        resource_group=resource_group,\n",
        "        workspace=workspace\n",
        "    ),\n",
        "    compute=cpu_compute_target,\n",
        "    # environment='AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest', # list(ml_client.environments.list(name='\"AzureML-pytorch-1.9-ubuntu18.04-py37-cuda11-gpu@latest\"'))[0],\n",
        "    environment=env_v2,\n",
        "    code=source_directory, # location of source code\n",
        "    command=\"\"\"\n",
        "    python deploy_model.py \\\n",
        "        --endpoint-name ${{inputs.endpoint_name}} \\\n",
        "        --model-name ${{inputs.model_name}} \\\n",
        "        --environment-name ${{inputs.environment_name}} \\\n",
        "        --subscription-id ${{inputs.subscription_id}} \\\n",
        "        --resource-group ${{inputs.resource_group}} \\\n",
        "        --workspace ${{inputs.workspace}} \\\n",
        "        --model-data ${{inputs.linkage_data}}\n",
        "    \"\"\",\n",
        "    display_name=\"Deploy_Latest_Model\",\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.dsl import pipeline\n",
        "\n",
        "@pipeline()\n",
        "def pipeline_construction():\n",
        "    \"\"\"The hello world pipeline job.\"\"\"\n",
        "    hyper_drive = job_train_for_sweep.sweep(\n",
        "        compute=compute_target,\n",
        "        sampling_algorithm=\"random\",\n",
        "        primary_metric=\"test_f1_weighted\",\n",
        "        goal=\"Maximize\",\n",
        "        max_total_trials=1,\n",
        "        max_concurrent_trials=1,\n",
        "        early_termination_policy=BanditPolicy(\n",
        "            slack_factor=0.1, evaluation_interval=5\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    reg_step = job_register(model_path=hyper_drive.outputs.model_output)\n",
        "    dep_step = job_deploy(linkage_data=reg_step.outputs.linkage_data) # model_data=job_register.outputs.model_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_job = pipeline_construction()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: the provided asset name 'nlp-accelerator-sdk-v2' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'sdk-v2-cpu' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'sdk-v2-cpu' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'sdk-v2-cpu' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'sdk-v2-cpu' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'nlp-accelerator-sdk-v2' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'sdk-v2-cpu' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'sdk-v2-cpu' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'sdk-v2-cpu' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'sdk-v2-cpu' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'nlp-accelerator-sdk-v2' will not be used for anonymous registration\n",
            "\u001b[32mUploading project_v2 (0.03 MBs): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27073/27073 [00:00<00:00, 339023.09it/s]\u001b[0m\n",
            "\u001b[39m\n",
            "\n",
            "Warning: the provided asset name 'sdk-v2-cpu' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'sdk-v2-cpu' will not be used for anonymous registration\n"
          ]
        }
      ],
      "source": [
        "pipeline_job = ml_client.jobs.create_or_update(pipeline_job, experiment_name=experiment_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "azureml_py310_sdkv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
