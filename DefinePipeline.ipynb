{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358373030
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.core.runconfig import JarLibrary\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.core.databricks import PyPiLibrary\n",
        "\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import DatabricksStep, PythonScriptStep\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358373831
        }
      },
      "outputs": [],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358374031
        }
      },
      "outputs": [],
      "source": [
        "db_compute_name = \"Databricks\" # Databricks compute name\n",
        "\n",
        "databricks_compute = DatabricksCompute(workspace=ws, name=db_compute_name)\n",
        "print('Compute target {} already exists'.format(db_compute_name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358374418
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\n",
        "\n",
        "def_blob_store = ws.get_default_datastore()\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358374625
        }
      },
      "outputs": [],
      "source": [
        "# step_output_train = PipelineData(\"output_train\", datastore=def_blob_store)\n",
        "# step_output_validation = PipelineData(\"output_validation\", datastore=def_blob_store)\n",
        "# step_output_test = PipelineData(\"output_test\", datastore=def_blob_store)\n",
        "# step_output_temporal_test = PipelineData(\"output_temporal_test\", datastore=def_blob_store)\n",
        "# \n",
        "# ds_step_output_train = step_output_train.as_dataset()\n",
        "# ds_step_output_validation = step_output_validation.as_dataset()\n",
        "# ds_step_output_test = step_output_test.as_dataset()\n",
        "# ds_step_output_temporal_test = step_output_temporal_test.as_dataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358374847
        }
      },
      "outputs": [],
      "source": [
        "# ds_base_dataframe = Dataset.get_by_name(ws, 'base_dataframe')\n",
        "# print(ds_base_dataframe.tags)\n",
        "# ds_base_dataframe.tags['temporal_date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358375082
        }
      },
      "outputs": [],
      "source": [
        "source_directory = \"./project\"\n",
        "\n",
        "preprocessing_script_name = \"preprocessing_factory.py\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1663358375383
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "base_file_name = \"ecd_tickets_cleaned_2_more_withNewLongDescs\"\n",
        "cluster_id = \"0916-144740-3ql755ed\" # Databricks \"AML Cluster do not use please\"\n",
        "\n",
        "adb_prep_base = DatabricksStep(\n",
        "    name=\"ADB_Prep_Base\",\n",
        "    compute_target=databricks_compute,\n",
        "    existing_cluster_id=cluster_id,\n",
        "    python_script_params=['--base_file_name', base_file_name\n",
        "                          ],\n",
        "    permit_cluster_restart=True,\n",
        "    pypi_libraries=[],\n",
        "    python_script_name='prep_base_dataset_from_SQL.py',\n",
        "    source_directory=source_directory,\n",
        "    run_name='ADB_Prep_Base',\n",
        "    allow_reuse=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358375611
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "cut_off_for_training = '201808'\n",
        "valid_classes_period = '202105'\n",
        "cut_off_date_recent = '202107'\n",
        "temporal_test_date = '202209' # last training date. Keep it 1 month behind current date (or keep present date)\n",
        "logic_v = '4'\n",
        "top_n = '120'\n",
        "base_file_name = \"ecd_tickets_cleaned_2_more_withNewLongDescs\"\n",
        "\n",
        "adb_prep_step = DatabricksStep(\n",
        "    name=\"ADB_Feature_Eng\",\n",
        "    compute_target=databricks_compute,\n",
        "    existing_cluster_id=cluster_id,\n",
        "    python_script_params=['--cut_off_for_training', cut_off_for_training,\n",
        "                          '--valid_classes_period', valid_classes_period,\n",
        "                          '--cut_off_date_recent', cut_off_date_recent,\n",
        "                          '--temporal_test_date', temporal_test_date,\n",
        "                          '--logic_v', logic_v,\n",
        "                          '--top_n', top_n,\n",
        "                          '--base_file_name', base_file_name\n",
        "                          ],\n",
        "    permit_cluster_restart=True,\n",
        "    pypi_libraries=[PyPiLibrary(package='azureml-sdk'), PyPiLibrary(package='fsspec'), PyPiLibrary(package='plotly'), PyPiLibrary(package='kaleido')],\n",
        "    python_script_name=preprocessing_script_name,\n",
        "    source_directory=source_directory,\n",
        "    run_name='ADB_Feature_Eng',\n",
        "    allow_reuse=True\n",
        ")\n",
        "\n",
        "adb_prep_step.run_after(adb_prep_base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358375838
        }
      },
      "outputs": [],
      "source": [
        "# exp = Experiment(workspace=ws, name='transformer_hp')\n",
        "# \n",
        "# steps = [dbNbStep]\n",
        "# pipeline = Pipeline(workspace=ws, steps=steps)\n",
        "# pipeline_run = exp.submit(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358376042
        }
      },
      "outputs": [],
      "source": [
        "# pipeline_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358376307
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cluster_name = \"NC6s-v3-SingleNode\"\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358376576
        }
      },
      "outputs": [],
      "source": [
        "env = Environment.get(workspace=ws, name=\"Transformer-DeBerta\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358376771
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "args = [\n",
        "        '--target-name', 'target',\n",
        "        '--text-field', 'TEXT_FINAL',\n",
        "        '--is-test', 0,\n",
        "        '--is-final', 1,\n",
        "        '--is-jump', 0,\n",
        "        '--is-local', 0,\n",
        "        '--evaluation-strategy', \"epoch\"\n",
        "]\n",
        "\n",
        "src = ScriptRunConfig(source_directory=source_directory,\n",
        "                      script='train_transformer.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=env)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358376946
        }
      },
      "outputs": [],
      "source": [
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "ps = RandomParameterSampling(\n",
        "    {\n",
        "        '--base-checkpoint': choice(\"bert-base-cased\"), #, \"bert-base-cased\"), # , \"bert-large-cased\", \"microsoft/deberta-v3-small\", \"distilbert-base-uncased\", \"bert-base-uncased\"),\n",
        "        '--batch-size': choice(16),\n",
        "        '--no-epochs': choice(4),\n",
        "        '--learning-rate': choice(5.5e-5), # 5e-5, 4.5e-5, 4e-5, 5.5e-5, 6e-5, 3.5e-5, 6.5e-5)\n",
        "        '--warmup-steps': choice(0),\n",
        "        '--weight-decay': choice(0.0),\n",
        "        '--adam-beta1': choice(0.9),\n",
        "        '--adam-beta2': choice(0.999),\n",
        "        '--adam-epsilon': choice(1e-8)\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358377133
        }
      },
      "outputs": [],
      "source": [
        "policy = BanditPolicy(evaluation_interval=5, slack_factor=0.1)\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                     hyperparameter_sampling=ps,\n",
        "                                     policy=policy,\n",
        "                                     primary_metric_name='eval_f1_weighted',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs=20,\n",
        "                                     max_concurrent_runs=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358377335
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n",
        "\n",
        "hd_step_name='HyperDrive_Step'\n",
        "hd_step = HyperDriveStep(\n",
        "    name=hd_step_name,\n",
        "    hyperdrive_config=hyperdrive_config,\n",
        "    allow_reuse=True)\n",
        "\n",
        "hd_step.run_after(adb_prep_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663358377523
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "reg_compute_target = ComputeTarget(workspace=ws, name=\"NC6s-v3-SingleNode\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663359576047
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# conda_dep = CondaDependencies()\n",
        "# conda_dep.add_pip_package(\"azureml-sdk\")\n",
        "# conda_dep.env\n",
        "\n",
        "rcfg = RunConfiguration() # conda_dependencies=conda_dep)\n",
        "rcfg.environment = env\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=reg_compute_target,\n",
        "                                       arguments=['--is-test', 0,\n",
        "                                                  '--test-run-id', '',\n",
        "                                                  '--metric-name', 'temporal_test_f1_weighted',\n",
        "                                                  '--second-metric', 'temporal_test_f1',\n",
        "                                                  '--temporal-test-date', temporal_test_date,\n",
        "                                                  '--model-name', 'service_desk_concierge'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "register_model_step.run_after(hd_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663360692280
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# conda_dep = CondaDependencies()\n",
        "# conda_dep.add_pip_package(\"azureml-sdk\")\n",
        "# conda_dep.env\n",
        "\n",
        "rcfg = RunConfiguration() # conda_dependencies=conda_dep)\n",
        "rcfg.environment = env\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=reg_compute_target,\n",
        "                                       arguments=['--endpoint-name', 'help-desk-service-prod',\n",
        "                                                  '--model-name', 'service_desk_concierge'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "deploy_model_step.run_after(register_model_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663360693237
        }
      },
      "outputs": [],
      "source": [
        "exp = Experiment(workspace=ws, name='transformer_hp')\n",
        "steps = [deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "timenow = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "\n",
        "pipeline_name = 'ECD-horizon-' + timenow + \"-Pipeline\"\n",
        "print(pipeline_name)\n",
        "\n",
        "published_pipeline = pipeline.publish(\n",
        "    name=pipeline_name, \n",
        "    description=pipeline_name)\n",
        "print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663360704538
        },
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "pipeline.submit(exp.name, credential_passthrough=True)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
