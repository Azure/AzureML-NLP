{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673849306338
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.core.runconfig import JarLibrary\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.core.databricks import PyPiLibrary\n",
        "\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import DatabricksStep, PythonScriptStep \n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673849306639
        }
      },
      "outputs": [],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from transformers import TrainingArguments, Trainer, AutoTokenizer\n",
        "\n",
        "\n",
        "def get_encode_labels(pdf, text_field_name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "\n",
        "    le.fit(list(pdf[text_field_name].unique()))\n",
        "    \n",
        "    return le\n",
        "\n",
        "def adjust_tokenizer(model, tokenizer, new_tokens):\n",
        "    tokenizer.add_tokens(new_tokens)\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def tokenize_function(example, text_field_name, tokenizer):\n",
        "    tokenized_batch = tokenizer(example[text_field_name], truncation=True)\n",
        "    return tokenized_batch\n",
        "\n",
        "def generate_tokenized_dataset(pdf, fields, le, target_name, text_field_name, tokenizer):\n",
        "    from datasets import Dataset\n",
        "\n",
        "    pdf['labels'] = le.transform(pdf[target_name])\n",
        "    # pdf['labels'] = pdf[target_name]\n",
        "    \n",
        "    ds = Dataset.from_pandas(pdf[fields].dropna())\n",
        "    \n",
        "    tokenized_dataset = ds.map(tokenize_function, batched=True, fn_kwargs={\"text_field_name\": text_field_name, \"tokenizer\": tokenizer})\n",
        "    return ds, tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673849755850
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "from azureml.core import Workspace, Experiment, Environment, Model, Dataset, Run\n",
        "\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "\n",
        "\n",
        "run = ws.get_run(run_id=\"1047e487-166b-4d65-b0ca-9c03c57dad26\")\n",
        "exp = run.experiment\n",
        "\n",
        "print('Run {} will be used'.format(run))\n",
        "print('Experiment {} will be used'.format(exp))\n",
        "\n",
        "parent_id = run.parent.id\n",
        "pipeline_run = ws.get_run(parent_id)\n",
        "\n",
        "print('pipeline_run -- {} will be used'.format(pipeline_run))\n",
        "\n",
        "automl_run_found = next(r for r in pipeline_run.get_children(recursive=True) if r.name == 'AutoML_Classification')\n",
        "print('AutoML-- {}'.format(automl_run_found))\n",
        "\n",
        "automl_run = AutoMLRun(exp, run_id = automl_run_found.id)\n",
        "\n",
        "lookup_metric = \"AUC_weighted\"\n",
        "best_run, fitted_model = automl_run.get_output(metric=lookup_metric)\n",
        "print(best_run)\n",
        "print(fitted_model.tokenizer)\n",
        "\n",
        "print('Tokenizing')\n",
        "test_dataset = Dataset.get_by_name(workspace=exp.workspace, name='test_set')\n",
        "pdf_test = test_dataset.to_pandas_dataframe()\n",
        "print('Test Dataset {}'.format(pdf_test))\n",
        "\n",
        "target_name=\"sentiment\"\n",
        "text_field_name=\"reviewText\"\n",
        "\n",
        "new_tokens = []\n",
        "num_labels = len(pdf_test[target_name].unique())\n",
        "print(f'num_labels: {num_labels}')\n",
        "\n",
        "le = get_encode_labels(pdf_test, target_name)\n",
        "fields = [text_field_name, target_name, 'labels']\n",
        "print(f'le: {le}')\n",
        "print(f'fields: {fields}')\n",
        "\n",
        "test_ds, tokenized_test_ds = generate_tokenized_dataset(pdf_test, fields, le, target_name, text_field_name, fitted_model.tokenizer)\n",
        "\n",
        "print('Tokenized data is generated')\n",
        "\n",
        "print('Predictions started')\n",
        "test_predictions = fitted_model.predict(pdf_test)\n",
        "print(f'predictions: {test_predictions}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import  load_metric\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "target_name=\"sentiment\"\n",
        "# Retrieve reference labels from test set\n",
        "test_references = test_ds[target_name]\n",
        "\n",
        "# Compute AUC_weighted\n",
        "\n",
        "metric = load_metric(\"roc_auc\", average='weighted')\n",
        "final_score = metric.compute(prediction_scores=test_predictions, references=test_references)\n",
        "\n",
        "print(f'Metrics:', final_score[\"roc_auc\"])\n",
        "run.log(f'test_AUC_weighted', f'{final_score[\"roc_auc\"]}')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673849322715
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Experiment, Environment, Model, Dataset, Run\n",
        "\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "\n",
        "\n",
        "run = ws.get_run(run_id=\"1047e487-166b-4d65-b0ca-9c03c57dad26\")\n",
        "exp = run.experiment\n",
        "\n",
        "print('Run {} will be used'.format(run))\n",
        "print('Experiment {} will be used'.format(exp))\n",
        "\n",
        "parent_id = run.parent.id\n",
        "pipeline_run = ws.get_run(parent_id)\n",
        "\n",
        "print('pipeline_run -- {} will be used'.format(pipeline_run))\n",
        "\n",
        "counter = 0\n",
        "\n",
        "\n",
        "all_runs = pipeline_run.get_children(recursive=True)\n",
        "dic_runs = {}\n",
        "\n",
        "print('all runs {} '.format(all_runs))\n",
        "\n",
        "for i, runstep in enumerate(all_runs):\n",
        "        metrics = runstep.get_metrics()\n",
        "        # print('RunStep: {}  '.format(runstep))\n",
        "        if \"test_AUC_weighted\" in metrics:\n",
        "            dic_runs[runstep.id] = {\n",
        "                'run': runstep,\n",
        "                'metrics': metrics\n",
        "            }\n",
        "            print('Adding step {} and metrics: {}  '.format(runstep,metrics))\n",
        "        counter+=1\n",
        "print(f'len(dic_runs) = {len(dic_runs)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "li_test_values = []\n",
        "best_performing_run = None\n",
        "metric_name = \"test_AUC_weighted\"\n",
        "\n",
        "for run_id in dic_runs:\n",
        "    print('run_id', run_id)\n",
        "    test_metric = dic_runs[run_id]['metrics'][metric_name]\n",
        "    if (type(test_metric) == list):\n",
        "        test_metric = float(test_metric[0])\n",
        "    else:\n",
        "        test_metric = float(test_metric)\n",
        "    print(f'{metric_name} = {test_metric}')\n",
        "    \n",
        "    if len(li_test_values) == 0 or (len(li_test_values) > 0 and test_metric > max(li_test_values)):\n",
        "        # if temporal_test_date == None:\n",
        "        best_performing_run = dic_runs[run_id]\n",
        "\n",
        "    # if temporal_test_date == None:\n",
        "    li_test_values.append(test_metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Experiment, Environment, Model, Dataset, Run\n",
        "\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "\n",
        "\n",
        "run = ws.get_run(run_id=\"1047e487-166b-4d65-b0ca-9c03c57dad26\")\n",
        "exp = run.experiment\n",
        "\n",
        "print('Run {} will be used'.format(run))\n",
        "print('Run name {} will be used'.format(run.name))\n",
        "\n",
        "parent_id = run.parent.id\n",
        "pipeline_run = ws.get_run(parent_id)\n",
        "\n",
        "all_runs = pipeline_run.get_children(recursive=True)\n",
        "\n",
        "\n",
        "print('all runs {} '.format(all_runs))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674426384073
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Experiment, Environment, Model, Dataset, Run\n",
        "\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\n",
        "from shutil import copy2\n",
        "\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
        "\n",
        "best_run = ws.get_run(run_id=\"8123b373-38cb-4f14-b1ce-78e7d9aca346\")\n",
        "exp = best_run.experiment\n",
        "\n",
        "\n",
        "\n",
        "print('Run {} will be used'.format(best_run))\n",
        "print('Run name {} will be used'.format(best_run.name))\n",
        "print('Pipeline Run {} will be used'.format(best_run.parent))\n",
        "\n",
        "pipeline_run = best_run.parent\n",
        "model_output = pipeline_run.get_pipeline_output(\"model_output\")\n",
        "print(\"Pipeline Data ==============: {}\".format(model_output._path_on_datastore))\n",
        "\n",
        "model_output_dir = './model/'\n",
        "\n",
        "os.makedirs(model_output_dir, exist_ok=True)\n",
        "model_output.download(model_output_dir)\n",
        "\n",
        "\n",
        "model = Model.register(workspace=ws, \n",
        "                       model_name=\"test_model\",        \n",
        "                        model_path=model_output_dir)\n",
        "\n",
        "                        \n",
        "\n",
        "#ds_train, ds_val, ds_test = find_run_datasets(best_run)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import joblib\n",
        "import shutil\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\n",
        "\n",
        "pdf_train = ds_train.to_pandas_dataframe()\n",
        "print(f\"Train dataset name: {ds_train.name}, V:{ds_train.version}\")\n",
        "best_run.parent\n",
        "\n",
        "# Download Best Model\n",
        "dir = f'output'\n",
        "\n",
        "isdir = os.path.isdir(dir)\n",
        "if isdir:\n",
        "    shutil.rmtree(dir)\n",
        "    \n",
        "model_directory = f'{dir}/outputs/model'\n",
        "os.makedirs(model_directory,exist_ok=True)\n",
        "\n",
        "best_run.download_files(prefix=\"outputs/model\", output_directory=dir, timeout_seconds=6000)\n",
        "\n",
        "print(f'the output path: [{model_directory}]')\n",
        "shutil.copy('score.py', model_directory)\n",
        "\n",
        "num_labels = len(pdf_train[\"reviewText\"].unique())\n",
        "print(f'Number of labels: [{num_labels}]')\n",
        "\n",
        "li_target = list(pdf_train[\"reviewText\"].unique())\n",
        "with open(f\"{model_directory}/target_list.json\", \"wb\") as outfile:\n",
        "    pickle.dump(li_target, outfile)\n",
        "\n",
        "# Register the Model\n",
        "tags = {\n",
        "    'run_id': best_run.id,\n",
        "   \n",
        "}\n",
        "\n",
        "model = Model.register(workspace=ws, \n",
        "                    datasets=[('train dataset', ds_train),\n",
        "                                ('val dataset', ds_val)\n",
        "                                ], \n",
        "                    tags=tags,\n",
        "                    model_name=\"test_model\", \n",
        "                    resource_configuration=ResourceConfiguration(cpu=2, memory_in_gb=1),\n",
        "                    model_path=model_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Experiment, Environment, Model, Dataset, Run\n",
        "\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\n",
        "from shutil import copy2\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput, PipelineRun\n",
        "from azureml.pipeline.steps import  PythonScriptStep\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
        "\n",
        "\n",
        "best_run_id= \"a08dc10b-abac-4b73-8dc3-c2393373250b\"\n",
        "best_run = ws.get_run(run_id=best_run_id)\n",
        "best_exp = best_run.experiment\n",
        "pipeline_run = PipelineRun(best_exp, best_run.parent.id)\n",
        "\n",
        "saved_model = pipeline_run.get_pipeline_output(\"model_output\")\n",
        "print(f'Model output: [{saved_model}]')\n",
        "\n",
        "\n",
        "source_directory = \"./project\"\n",
        "\n",
        "\n",
        "# choose a name for your cluster\n",
        "cpu_compute = ComputeTarget(workspace=ws, name=\"cpu-cluster\")\n",
        "base_env = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN\" ) #name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\")\n",
        "#env = Environment.get(workspace=ws, name=\"nlp-accelerator\")\n",
        "env = base_env.clone(\"automml_dnn\")\n",
        "\n",
        "#env.python.conda_dependencies.add_pip_package(\"transformers[sentencepiece]==4.6.0\")\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='test_runs.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=[\n",
        "                                                  '--best_run_id', best_run_id,\n",
        "                                                  '--saved_model', saved_model\n",
        "                                                  ],\n",
        "                                        inputs=[saved_model],          \n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--endpoint-name', 'test-endpoint-en2',\n",
        "                                                  '--model-name', 'test_model'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "deploy_model_step.run_after(register_model_step)\n",
        "\n",
        "exp = Experiment(workspace=ws, name='test')\n",
        "steps = [register_model_step,deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)      \n",
        "pipeline.submit(exp.name)                          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create local deployment\n",
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "from azure.identity import DefaultAzureCredential, ManagedIdentityCredential\n",
        "\n",
        "subscription_id = \"f9b97038-ed78-4a26-a1a7-51e81e75d867\"\n",
        "resource_group = \"openaml\"\n",
        "workspace = \"nlp-workspace\"\n",
        "\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    ManagedIdentityCredential(), subscription_id, resource_group, workspace\n",
        ")\n",
        "\n",
        "# Creating a local endpoint\n",
        "import datetime\n",
        "\n",
        "local_endpoint_name = \"localautoml-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=local_endpoint_name, description=\"this is a sample local endpoint\"\n",
        ")\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Get Model object Dir ['all_results.json', 'conda_env.yml', 'conda_env_v_1_0_0.yml', 'config.json', 'generated_code', 'label_list.npy', 'max_seq_length.npy', 'model.pkl', 'pytorch_model.bin', 'run_id.txt', 'score_automl.py', 'score_script.py', 'scoring_file_v_1_0_0.py', 'special_tokens_map.json', 'tokenizer.json', 'tokenizer_config.json', 'trainer_state.json', 'training_args.bin', 'train_results.json', 'vocab.txt', '__pycache__'] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Updating local deployment (localautoml-01240249314656 / green) .\n",
            "Building Docker image from Dockerfile\n",
            "Step 1/6 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\n",
            " ---> 4bd2dec82540\n",
            "Step 2/6 : RUN mkdir -p /var/azureml-app/\n",
            " ---> Using cache\n",
            " ---> efbf049c8276\n",
            "Step 3/6 : WORKDIR /var/azureml-app/\n",
            " ---> Using cache\n",
            " ---> 625b95615298\n",
            "Step 4/6 : COPY conda.yml /var/azureml-app/\n",
            " ---> Using cache\n",
            " ---> 34db19d37c97\n",
            "Step 5/6 : RUN conda env create -n inf-conda-env --file conda.yml\n",
            " ---> Using cache\n",
            " ---> 38995073c501\n",
            "Step 6/6 : CMD [\"conda\", \"run\", \"--no-capture-output\", \"-n\", \"inf-conda-env\", \"runsvdir\", \"/var/runit\"]\n",
            " ---> Using cache\n",
            " ---> 845900be7fb6\n",
            "Successfully built 845900be7fb6\n",
            "Successfully tagged localautoml-01240249314656:green\n",
            "\n",
            "Starting up endpoint.....Done (0m 30s)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ManagedOnlineDeployment({'private_network_connection': None, 'data_collector': None, 'provisioning_state': 'Succeeded', 'endpoint_name': 'localautoml-01240249314656', 'type': 'Managed', 'name': 'green', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/eneros1/code/Users/eneros/nlp-aml-private'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fb0d48194c0>, 'model': Model({'job_name': None, 'is_anonymous': False, 'auto_increment_version': False, 'name': '77dc4e7c57e60a23fd9c55c5ba09c713', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/eneros1/code/Users/eneros/nlp-aml-private'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fb0d4812e50>, 'version': '1', 'latest_version': None, 'path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eneros1/code/Users/eneros/nlp-aml-private/outputs/model', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model'}), 'code_configuration': {'code': 'outputs/model'}, 'environment': Environment({'is_anonymous': False, 'auto_increment_version': False, 'name': 'CliV2AnonymousEnvironment', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/eneros1/code/Users/eneros/nlp-aml-private'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fb0d4819250>, 'version': '5f985c912432dab54e6a3a981e49d8ea', 'latest_version': None, 'conda_file': {'channels': ['pytorch', 'anaconda', 'conda-forge'], 'dependencies': ['python=3.7', 'pip=21.1.2', {'pip': ['azureml-core==1.48.0', 'azureml-mlflow==1.48.0', 'azureml-automl-core==1.48.0', 'azureml-automl-dnn-nlp==1.48.0', 'azureml-automl-runtime==1.48.0', 'azureml-train-automl-client==1.48.0', 'azureml-train-automl-runtime==1.48.0', 'azureml-defaults==1.48.0']}, 'numpy~=1.21.6', 'pandas~=1.1.5', 'shap=0.39.0', 'scikit-learn~=0.22.1', 'transformers[sentencepiece]==4.6.0'], 'name': 'project_environment'}, 'image': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest', 'build': None, 'inference_config': None, 'os_type': None, 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': 'channels:\\n- pytorch\\n- anaconda\\n- conda-forge\\ndependencies:\\n- python=3.7\\n- pip=21.1.2\\n- pip:\\n  - azureml-core==1.48.0\\n  - azureml-mlflow==1.48.0\\n  - azureml-automl-core==1.48.0\\n  - azureml-automl-dnn-nlp==1.48.0\\n  - azureml-automl-runtime==1.48.0\\n  - azureml-train-automl-client==1.48.0\\n  - azureml-train-automl-runtime==1.48.0\\n  - azureml-defaults==1.48.0\\n- numpy~=1.21.6\\n- pandas~=1.1.5\\n- shap=0.39.0\\n- scikit-learn~=0.22.1\\n- transformers[sentencepiece]==4.6.0\\nname: project_environment\\n'}), 'environment_variables': {}, 'app_insights_enabled': False, 'scale_settings': None, 'request_settings': None, 'liveness_probe': None, 'readiness_probe': None, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'local', 'egress_public_network_access': None})"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#from azureml.core.model import Model\n",
        "#model = Model(ws, 'test_model', version=29)\n",
        "dir = 'outputs'\n",
        "#model.download(target_dir=dir, exist_ok=True)\n",
        "\n",
        "prefix_path = \"model\"\n",
        "model_directory = f'{dir}/{prefix_path}'\n",
        "print(' Get Model object Dir {} '.format(os.listdir(model_directory)))\n",
        "\n",
        "local_model = Model(path=model_directory)\n",
        "\n",
        "env = Environment(\n",
        "    conda_file=\"./project/conda_env_automl.yml\",\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        "    #image=\"mcr.microsoft.com/azureml/curated/azureml-automl-dnn-text-gpu:56\"\n",
        ")\n",
        "\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"green\",\n",
        "    endpoint_name=local_endpoint_name,\n",
        "    model=local_model,\n",
        "    environment=env,\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=model_directory, scoring_script=\"score_automl.py\"\n",
        "    ),\n",
        "    instance_type=\"Standard_DS2_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "ml_client.online_deployments.begin_create_or_update(\n",
        "    deployment=blue_deployment, local=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Azure ML Inferencing HTTP server v0.7.7\\r\\n\\r\\n\\r\\nServer Settings\\r\\n---------------\\r\\nEntry Script Name: /var/azureml-app/model/score_automl.py\\r\\nModel Directory: /var/azureml-app/azureml-models//c0a037710bb50141f7ffce45d2e09660/1\\r\\nWorker Count: 1\\r\\nWorker Timeout (seconds): 300\\r\\nServer Port: 31311\\r\\nApplication Insights Enabled: false\\r\\nApplication Insights Key: None\\r\\nInferencing HTTP server version: azmlinfsrv/0.7.7\\r\\nCORS for the specified origins: None\\r\\n\\r\\n\\r\\nServer Routes\\r\\n---------------\\r\\nLiveness Probe: GET   127.0.0.1:31311/\\r\\nScore:          POST  127.0.0.1:31311/score\\r\\n\\r\\nStarting gunicorn 20.1.0\\r\\nListening at: http://0.0.0.0:31311 (27)\\r\\nUsing worker: sync\\r\\nBooting worker with pid: 87\\r\\nInitializing logger\\r\\n2023-01-24 04:27:38,602 | root | INFO | Starting up app insights client\\r\\nlogging socket was found. logging is available.\\r\\nlogging socket was found. logging is available.\\r\\n2023-01-24 04:27:38,606 | root | INFO | Starting up app insight hooks\\r\\n2023-01-24 04:27:43,666 | root | INFO | Found user script at /var/azureml-app/model/score_automl.py\\r\\n2023-01-24 04:27:43,666 | root | INFO | run() is decorated with @input_schema. Server will invoke it with the following arguments: Inputs, GlobalParameters.\\r\\n2023-01-24 04:27:43,667 | root | INFO | Invoking user\\'s init function\\r\\n00000000-0000-0000-0000-000000000000, ---- Get Model object Dir [\\'all_results.json\\', \\'conda_env.yml\\', \\'conda_env_v_1_0_0.yml\\', \\'config.json\\', \\'generated_code\\', \\'label_list.npy\\', \\'max_seq_length.npy\\', \\'model.pkl\\', \\'pytorch_model.bin\\', \\'run_id.txt\\', \\'score_automl.py\\', \\'score_script.py\\', \\'scoring_file_v_1_0_0.py\\', \\'special_tokens_map.json\\', \\'tokenizer.json\\', \\'tokenizer_config.json\\', \\'trainer_state.json\\', \\'training_args.bin\\', \\'train_results.json\\', \\'vocab.txt\\', \\'__pycache__\\']\\r\\n2023-01-24 04:27:52,088 | root | INFO | Users\\'s init has completed successfully\\r\\n2023-01-24 04:27:52,100 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\\r\\n2023-01-24 04:27:52,100 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\r\\n2023-01-24 04:27:52,100 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\\r\\n2023-01-24 04:28:42,681 | azureml.core.run | INFO | Could not load the run context. Logging offline\\r\\nCould not load the run context. Logging offline\\r\\n2003ff06-39af-46af-b69a-93a064d6bab1,***** Running Prediction *****\\r\\n2003ff06-39af-46af-b69a-93a064d6bab1,  Num examples = 3\\r\\n2003ff06-39af-46af-b69a-93a064d6bab1,  Batch size = 8\\r\\nIgnored unknown kwarg option direction\\r\\nIgnored unknown kwarg option direction\\r\\nIgnored unknown kwarg option direction\\r\\n2003ff06-39af-46af-b69a-93a064d6bab1,\\r  0% 0/1 [00:00<?, ?it/s]\\r\\n2003ff06-39af-46af-b69a-93a064d6bab1,\\r100% 1/1 [00:00<00:00, 969.11it/s]\\r\\n2023-01-24 04:28:43,162 | root | INFO | 200\\r\\n127.0.0.1 - - [24/Jan/2023:04:28:43 +0000] \"POST /score HTTP/1.0\" 200 34 \"-\" \"azure-ai-ml/1.2.0 azsdk-python-core/1.24.2 Python/3.8.5 (Linux-5.15.0-1017-azure-x86_64-with-glibc2.10)\"\\r\\n'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_endpoints.get(name=local_endpoint_name, local=True)\n",
        "\n",
        "ml_client.online_deployments.get_logs(\n",
        "    name=\"green\", endpoint_name=local_endpoint_name, local=True, lines=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"Results\": [\"1.0\", \"1.0\", \"0.0\"]}'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=local_endpoint_name,\n",
        "    request_file=\"./project/sample_request_automl.json\",\n",
        "    local=True,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "azureml_py38",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
