{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1670350228110
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SDK version: 1.47.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.core.runconfig import JarLibrary\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.core.databricks import PyPiLibrary\n",
        "\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import DatabricksStep, PythonScriptStep\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1670350231605
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learningmain\n",
            "learning\n",
            "eastus\n",
            "dac8073e-1c2d-4a7d-a53b-c3655e291d58\n"
          ]
        }
      ],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1670350232774
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datastore workspaceblobstore will be used\n"
          ]
        }
      ],
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\n",
        "\n",
        "def_blob_store = ws.get_default_datastore()\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1670350233346
        }
      },
      "outputs": [],
      "source": [
        "source_directory = \"./project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1670350234039
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"a100-cluster\"\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1670350234475
        }
      },
      "outputs": [],
      "source": [
        "# %%writefile conda_dependencies.yml\n",
        "# \n",
        "# channels:\n",
        "#   - pytorch\n",
        "#   - anaconda\n",
        "#   - conda-forge\n",
        "# dependencies:\n",
        "#   - python=3.7\n",
        "#   - pip=21.1.2\n",
        "#   - pip:\n",
        "#       - azureml-core==1.44.0\n",
        "#       - azureml-mlflow==1.44.0\n",
        "#       - azureml-automl-core==1.44.0\n",
        "#       - azureml-automl-dnn-nlp==1.44.0\n",
        "#       - azureml-responsibleai==1.44.0\n",
        "#       - azureml-automl-runtime==1.44.0\n",
        "#       - azureml-train-automl-client==1.44.0\n",
        "#       - azureml-train-automl-runtime==1.44.0\n",
        "#       - horovod==0.21.3\n",
        "#   - numpy~=1.18.5\n",
        "#   - pandas~=1.1.5\n",
        "#   - scikit-learn~=0.22.1\n",
        "#   - pytorch==1.7.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1670350235357
        }
      },
      "outputs": [],
      "source": [
        "if 'nlp-accelerator' in ws.environments:\n",
        "    base_env = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN-Text-GPU\")\n",
        "    env = base_env.clone(\"nlp-accelerator\")\n",
        "\n",
        "    conda_dep = env.python.conda_dependencies\n",
        "    conda_dep.add_pip_package('nvitop')\n",
        "\n",
        "    env.python.conda_dependencies = conda_dep\n",
        "\n",
        "    env.register(ws)\n",
        "else:\n",
        "    env = Environment.get(workspace=ws, name=\"nlp-accelerator\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1670350236164
        }
      },
      "outputs": [],
      "source": [
        "# to get larger datasets: http://jmcauley.ucsd.edu/data/amazon/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-12 04:46:38--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4669048 (4.5M) [application/x-gzip]\n",
            "Saving to: ‘data/reviews_Automotive_5.json.gz.14’\n",
            "\n",
            "reviews_Automotive_ 100%[===================>]   4.45M  2.35MB/s    in 1.9s    \n",
            "\n",
            "2023-01-12 04:46:41 (2.35 MB/s) - ‘data/reviews_Automotive_5.json.gz.14’ saved [4669048/4669048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz -P data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1670350241283
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20473, 9)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "pdf_main = getDF('data/reviews_Automotive_5.json.gz')\n",
        "pdf_main.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1670350241456
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A3F73SC1LY51OO</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>Alan Montgomery</td>\n",
              "      <td>[4, 4]</td>\n",
              "      <td>I needed a set of jumper cables for my new car...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Work Well - Should Have Bought Longer Ones</td>\n",
              "      <td>1313539200</td>\n",
              "      <td>08 17, 2011</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A20S66SKYXULG2</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>alphonse</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>These long cables work fine for my truck, but ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Okay long cables</td>\n",
              "      <td>1315094400</td>\n",
              "      <td>09 4, 2011</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2I8LFSN2IS5EO</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>Chris</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>Can't comment much on these since they have no...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Looks and feels heavy Duty</td>\n",
              "      <td>1374710400</td>\n",
              "      <td>07 25, 2013</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3GT2EWQSO45ZG</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>DeusEx</td>\n",
              "      <td>[19, 19]</td>\n",
              "      <td>I absolutley love Amazon!!!  For the price of ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Excellent choice for Jumper Cables!!!</td>\n",
              "      <td>1292889600</td>\n",
              "      <td>12 21, 2010</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A3ESWJPAVRPWB4</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>E. Hernandez</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>I purchased the 12' feet long cable set and th...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Excellent, High Quality Starter Cables</td>\n",
              "      <td>1341360000</td>\n",
              "      <td>07 4, 2012</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID        asin     reviewerName   helpful  \\\n",
              "0  A3F73SC1LY51OO  B00002243X  Alan Montgomery    [4, 4]   \n",
              "1  A20S66SKYXULG2  B00002243X         alphonse    [1, 1]   \n",
              "2  A2I8LFSN2IS5EO  B00002243X            Chris    [0, 0]   \n",
              "3  A3GT2EWQSO45ZG  B00002243X           DeusEx  [19, 19]   \n",
              "4  A3ESWJPAVRPWB4  B00002243X     E. Hernandez    [0, 0]   \n",
              "\n",
              "                                          reviewText  overall  \\\n",
              "0  I needed a set of jumper cables for my new car...      5.0   \n",
              "1  These long cables work fine for my truck, but ...      4.0   \n",
              "2  Can't comment much on these since they have no...      5.0   \n",
              "3  I absolutley love Amazon!!!  For the price of ...      5.0   \n",
              "4  I purchased the 12' feet long cable set and th...      5.0   \n",
              "\n",
              "                                      summary  unixReviewTime   reviewTime  \\\n",
              "0  Work Well - Should Have Bought Longer Ones      1313539200  08 17, 2011   \n",
              "1                            Okay long cables      1315094400   09 4, 2011   \n",
              "2                  Looks and feels heavy Duty      1374710400  07 25, 2013   \n",
              "3       Excellent choice for Jumper Cables!!!      1292889600  12 21, 2010   \n",
              "4      Excellent, High Quality Starter Cables      1341360000   07 4, 2012   \n",
              "\n",
              "   sentiment  \n",
              "0        1.0  \n",
              "1        1.0  \n",
              "2        1.0  \n",
              "3        1.0  \n",
              "4        1.0  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_main.loc[pdf_main['overall'] >= 4, 'sentiment'] = 1\n",
        "pdf_main.loc[pdf_main['overall'] < 3, 'sentiment'] = 0\n",
        "\n",
        "pdf_main.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1670350241576
        }
      },
      "outputs": [],
      "source": [
        "def generate_datasets(pdf_target_training, label = 'sentiment'):\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(pdf_target_training.drop(label, axis=1), pdf_target_training[label],\n",
        "                                                        stratify=pdf_target_training[label],\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.20)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        "                                                        stratify=y_test_val,\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.5)\n",
        "    pdf_X_train = X_train\n",
        "    pdf_X_val = X_val\n",
        "    pdf_X_test = X_test\n",
        "\n",
        "    pdf_X_train['sentiment'] = y_train\n",
        "    pdf_X_val['sentiment'] = y_val\n",
        "    pdf_X_test['sentiment'] = y_test\n",
        "    \n",
        "    print(f'Total records for: \"pdf_X_train\": [{pdf_X_train.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_val\": [{pdf_X_val.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_test\": [{pdf_X_test.shape[0]}]')\n",
        "        \n",
        "    return pdf_X_train, pdf_X_val, pdf_X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1670350241972
        }
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['sentiment'] not in index\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pdf_train, pdf_val, pdf_test \u001b[39m=\u001b[39m generate_datasets(pdf_main[[\u001b[39m'\u001b[39;49m\u001b[39mreviewText\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msentiment\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39mdropna(), \u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/frame.py:2912\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2910\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   2911\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 2912\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, raise_missing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   2914\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   2915\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/indexing.py:1254\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1252\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 1254\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_read_indexer(keyarr, indexer, axis, raise_missing\u001b[39m=\u001b[39;49mraise_missing)\n\u001b[1;32m   1255\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/indexing.py:1304\u001b[0m, in \u001b[0;36m_LocIndexer._validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[39mif\u001b[39;00m raise_missing:\n\u001b[1;32m   1303\u001b[0m     not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(key) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(ax))\n\u001b[0;32m-> 1304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1306\u001b[0m \u001b[39m# we skip the warning on Categorical\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m \u001b[39m# as this check is actually done (check for\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m \u001b[39m# non-missing values), but a bit later in the\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[39m# code, so we want to avoid warning & then\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[39m# just raising\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ax\u001b[39m.\u001b[39mis_categorical():\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['sentiment'] not in index\""
          ]
        }
      ],
      "source": [
        "pdf_train, pdf_val, pdf_test = generate_datasets(pdf_main[['reviewText', 'sentiment']].dropna(), 'sentiment')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670350244765
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "pdf_train.to_csv('data/pdf_train.csv', index=False)\n",
        "pdf_val.to_csv('data/pdf_val.csv', index=False)\n",
        "pdf_test.to_csv('data/pdf_test.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1670350251355
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pdf_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m def_blob_store \u001b[39m=\u001b[39m ws\u001b[39m.\u001b[39mget_default_datastore()\n\u001b[0;32m----> 3\u001b[0m ds_train_set \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mTabular\u001b[39m.\u001b[39mregister_pandas_dataframe(dataframe\u001b[39m=\u001b[39mpdf_train, target\u001b[39m=\u001b[39m(def_blob_store, \u001b[39m'\u001b[39m\u001b[39mnlp\u001b[39m\u001b[39m'\u001b[39m), name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain_set\u001b[39m\u001b[39m\"\u001b[39m, description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSmall amazon review for sentiment analysis [train set]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m ds_val_set \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mTabular\u001b[39m.\u001b[39mregister_pandas_dataframe(dataframe\u001b[39m=\u001b[39mpdf_val, target\u001b[39m=\u001b[39m(def_blob_store, \u001b[39m'\u001b[39m\u001b[39mnlp\u001b[39m\u001b[39m'\u001b[39m), name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_set\u001b[39m\u001b[39m\"\u001b[39m, description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSmall amazon review for sentiment analysis [val set]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m ds_test_set \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mTabular\u001b[39m.\u001b[39mregister_pandas_dataframe(dataframe\u001b[39m=\u001b[39mpdf_test, target\u001b[39m=\u001b[39m(def_blob_store, \u001b[39m'\u001b[39m\u001b[39mnlp\u001b[39m\u001b[39m'\u001b[39m), name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest_set\u001b[39m\u001b[39m\"\u001b[39m, description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSmall amazon review for sentiment analysis [test set]\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pdf_train' is not defined"
          ]
        }
      ],
      "source": [
        "def_blob_store = ws.get_default_datastore()\n",
        "\n",
        "ds_train_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_train, target=(def_blob_store, 'nlp'), name=\"train_set\", description=\"Small amazon review for sentiment analysis [train set]\")\n",
        "ds_val_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_val, target=(def_blob_store, 'nlp'), name=\"val_set\", description=\"Small amazon review for sentiment analysis [val set]\")\n",
        "ds_test_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_test, target=(def_blob_store, 'nlp'), name=\"test_set\", description=\"Small amazon review for sentiment analysis [test set]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1670350251488
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ds_train_set' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [14], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazureml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m ScriptRunConfig\n\u001b[1;32m      3\u001b[0m args \u001b[39m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--target-name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m----> 5\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--training-dataset\u001b[39m\u001b[39m'\u001b[39m, ds_train_set\u001b[39m.\u001b[39mas_named_input(\u001b[39m'\u001b[39m\u001b[39mtrain_set\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--val-dataset\u001b[39m\u001b[39m'\u001b[39m, ds_val_set\u001b[39m.\u001b[39mas_named_input(\u001b[39m'\u001b[39m\u001b[39mval_set\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      7\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--test-dataset\u001b[39m\u001b[39m'\u001b[39m, ds_test_set\u001b[39m.\u001b[39mas_named_input(\u001b[39m'\u001b[39m\u001b[39mtest_set\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      8\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--text-field\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreviewText\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--is-test\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m,\n\u001b[1;32m     10\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--is-final\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m,\n\u001b[1;32m     11\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--is-jump\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m,\n\u001b[1;32m     12\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--is-local\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m,\n\u001b[1;32m     13\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--evaluation-strategy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--collect-resource-utilization\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m# \u001b[39;00m\n\u001b[1;32m     15\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--resource-utilization-interval\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m5.0\u001b[39m \u001b[39m# seconds\u001b[39;00m\n\u001b[1;32m     16\u001b[0m ]\n\u001b[1;32m     18\u001b[0m src \u001b[39m=\u001b[39m ScriptRunConfig(source_directory\u001b[39m=\u001b[39msource_directory,\n\u001b[1;32m     19\u001b[0m                       script\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain_transformer.py\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m                       arguments\u001b[39m=\u001b[39margs,\n\u001b[1;32m     21\u001b[0m                       compute_target\u001b[39m=\u001b[39mcompute_target,\n\u001b[1;32m     22\u001b[0m                       environment\u001b[39m=\u001b[39menv)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ds_train_set' is not defined"
          ]
        }
      ],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "args = [\n",
        "        '--target-name', 'sentiment',\n",
        "        '--training-dataset', ds_train_set.as_named_input('train_set'),\n",
        "        '--val-dataset', ds_val_set.as_named_input('val_set'),\n",
        "        '--test-dataset', ds_test_set.as_named_input('test_set'),\n",
        "        '--text-field', 'reviewText',\n",
        "        '--is-test', 0,\n",
        "        '--is-final', 0,\n",
        "        '--is-jump', 1,\n",
        "        '--is-local', 0,\n",
        "        '--evaluation-strategy', \"epoch\",\n",
        "        '--collect-resource-utilization', 1, # \n",
        "        '--resource-utilization-interval', 5.0 # seconds\n",
        "]\n",
        "\n",
        "src = ScriptRunConfig(source_directory=source_directory,\n",
        "                      script='train_transformer.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=env)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1670350251613
        }
      },
      "outputs": [],
      "source": [
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "ps = RandomParameterSampling(\n",
        "    {\n",
        "        # bert-base-cased model could fit into all NC series, but if you're interested in trying larger models, then you need to make sure the VM type can handle the size of the model\n",
        "        '--base-checkpoint': choice(\"bert-base-cased\", \"bert-large-cased\", \"microsoft/deberta-v3-base\"), # , \"distilbert-base-uncased\", \"bert-base-uncased\"),\n",
        "        '--batch-size': choice(16),\n",
        "        '--no-epochs': choice(3),\n",
        "        '--learning-rate': choice(2e-5, 3e-5, 5.5e-5, 5e-5, 4.5e-5, 4e-5, 5.5e-5, 6e-5),\n",
        "        '--warmup-steps': choice(0),\n",
        "        '--weight-decay': choice(0.0),\n",
        "        '--adam-beta1': choice(0.9),\n",
        "        '--adam-beta2': choice(0.999),\n",
        "        '--adam-epsilon': choice(1e-8)\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1670350251738
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'src' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m policy \u001b[39m=\u001b[39m BanditPolicy(evaluation_interval\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, slack_factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m hyperdrive_config \u001b[39m=\u001b[39m HyperDriveConfig(run_config\u001b[39m=\u001b[39msrc,\n\u001b[1;32m      3\u001b[0m                                      hyperparameter_sampling\u001b[39m=\u001b[39mps,\n\u001b[1;32m      4\u001b[0m                                      policy\u001b[39m=\u001b[39mpolicy,\n\u001b[1;32m      5\u001b[0m                                      primary_metric_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39meval_auc_weighted\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                                      primary_metric_goal\u001b[39m=\u001b[39mPrimaryMetricGoal\u001b[39m.\u001b[39mMAXIMIZE,\n\u001b[1;32m      7\u001b[0m                                      max_total_runs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[1;32m      8\u001b[0m                                      max_concurrent_runs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'src' is not defined"
          ]
        }
      ],
      "source": [
        "policy = BanditPolicy(evaluation_interval=5, slack_factor=0.1)\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                     hyperparameter_sampling=ps,\n",
        "                                     policy=policy,\n",
        "                                     primary_metric_name='eval_auc_weighted',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs=20,\n",
        "                                     max_concurrent_runs=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1670350251864
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'hyperdrive_config' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [17], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazureml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpipeline\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msteps\u001b[39;00m \u001b[39mimport\u001b[39;00m HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n\u001b[1;32m      3\u001b[0m hd_step_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mHyperDrive_Step\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      4\u001b[0m hd_step \u001b[39m=\u001b[39m HyperDriveStep(\n\u001b[1;32m      5\u001b[0m     name\u001b[39m=\u001b[39mhd_step_name,\n\u001b[0;32m----> 6\u001b[0m     hyperdrive_config\u001b[39m=\u001b[39mhyperdrive_config,\n\u001b[1;32m      7\u001b[0m     allow_reuse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hyperdrive_config' is not defined"
          ]
        }
      ],
      "source": [
        "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n",
        "\n",
        "hd_step_name='HyperDrive_Step'\n",
        "hd_step = HyperDriveStep(\n",
        "    name=hd_step_name,\n",
        "    hyperdrive_config=hyperdrive_config,\n",
        "    allow_reuse=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1670350252004
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cpu_compute = ComputeTarget(workspace=ws, name=\"cpu-cluster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1670350252434
        }
      },
      "outputs": [],
      "source": [
        "env_cpu = Environment.get(workspace=ws, name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Blobstore's name: workspaceblobstore\n"
          ]
        }
      ],
      "source": [
        "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
        "print(\"Blobstore's name: {}\".format(def_blob_store.name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path = \"https://dprepdata.blob.core.windows.net/demo/Titanic.csv\"\n",
        "blob_input_data = Dataset.File.from_files(data_path).as_named_input(\"test_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1670350252611
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--is-test', 0,\n",
        "                                                  '--test-run-id', '',\n",
        "                                                  '--metric-name', 'test_f1_weighted',\n",
        "                                                  '--second-metric', 'test_f1',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       # runconfig=rcfg\n",
        "                                       )\n",
        "\n",
        "# register_model_step.run_after(hd_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.data import OutputFileDatasetConfig\n",
        "processed_data1 = OutputFileDatasetConfig(name=\"processed_data1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainStep created\n"
          ]
        }
      ],
      "source": [
        "# trainStep consumes the datasource (Datareference) in the previous step\n",
        "# and produces processed_data1\n",
        "\n",
        "source_directory_temp = \"temp2\"\n",
        "\n",
        "trainStep = PythonScriptStep(\n",
        "    script_name=\"train.py\", \n",
        "        arguments=[\"--input_data\", blob_input_data.as_mount(), \"--output_train\", processed_data1],\n",
        "    compute_target=cpu_compute, \n",
        "    source_directory=source_directory_temp,\n",
        "    allow_reuse=True\n",
        ")\n",
        "print(\"trainStep created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670350252756
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "\n",
        "# rcfg = RunConfiguration() # conda_dependencies=conda_dep)\n",
        "# rcfg.environment = env_cpu\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--endpoint-name', 'sentiment-endpoint-2',\n",
        "                                                  '--model-name', 'sentiment_classifier',\n",
        "                                                  \"--input_extract\", processed_data1.as_input()],\n",
        "                                       allow_reuse=True,\n",
        "                                       # runconfig=rcfg\n",
        "                                       )\n",
        "\n",
        "# deploy_model_step.run_after(register_model_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1670350255342
        }
      },
      "outputs": [],
      "source": [
        "exp = Experiment(workspace=ws, name='transformer_hp')\n",
        "steps = [deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1670350261139
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submitted PipelineRun 6a0a53f8-6038-4087-b793-55a225ccd24f\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/6a0a53f8-6038-4087-b793-55a225ccd24f?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/learning/workspaces/learningmain&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>transformer_hp</td><td>6a0a53f8-6038-4087-b793-55a225ccd24f</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/6a0a53f8-6038-4087-b793-55a225ccd24f?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/learning/workspaces/learningmain&amp;tid=16b3c013-d300-468d-ac64-7eda0820b6d3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: transformer_hp,\n",
              "Id: 6a0a53f8-6038-4087-b793-55a225ccd24f,\n",
              "Type: azureml.PipelineRun,\n",
              "Status: Preparing)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.submit(exp.name, credential_passthrough=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1670350261503
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment-Classifier-2023-01-11-21-28-Pipeline\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "timenow = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "\n",
        "pipeline_name = f\"Sentiment-Classifier-{timenow}-Pipeline\"\n",
        "print(pipeline_name)\n",
        "\n",
        "# published_pipeline = pipeline.publish(\n",
        "#     name=pipeline_name, \n",
        "#     description=pipeline_name)\n",
        "# print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "azureml_py38",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
