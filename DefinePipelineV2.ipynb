{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1668533978662
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dac8073e-1c2d-4a7d-a53b-c3655e291d58\n",
            "Learning\n",
            "learningmain\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Enter details of your AML workspace\n",
        "subscription_id = \"dac8073e-1c2d-4a7d-a53b-c3655e291d58\"\n",
        "resource_group = \"Learning\"\n",
        "workspace = \"learningmain\"\n",
        "\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")\n",
        "\n",
        "print(ml_client.subscription_id, ml_client.resource_group_name, ml_client.workspace_name, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-13 18:17:55--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4669048 (4.5M) [application/x-gzip]\n",
            "Saving to: ‘data/reviews_Automotive_5.json.gz.16’\n",
            "\n",
            "reviews_Automotive_ 100%[===================>]   4.45M  3.24MB/s    in 1.4s    \n",
            "\n",
            "2023-01-13 18:17:57 (3.24 MB/s) - ‘data/reviews_Automotive_5.json.gz.16’ saved [4669048/4669048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# to get larger datasets, visit: http://jmcauley.ucsd.edu/data/amazon/\n",
        "\n",
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz -P data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20473, 9)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "pdf_main = getDF('data/reviews_Automotive_5.json.gz')\n",
        "pdf_main.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20473.000000</td>\n",
              "      <td>2.047300e+04</td>\n",
              "      <td>19043.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.471841</td>\n",
              "      <td>1.365018e+09</td>\n",
              "      <td>0.939715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.940337</td>\n",
              "      <td>3.621266e+07</td>\n",
              "      <td>0.238020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.121386e+09</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.354838e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.373414e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.390435e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.405901e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            overall  unixReviewTime     sentiment\n",
              "count  20473.000000    2.047300e+04  19043.000000\n",
              "mean       4.471841    1.365018e+09      0.939715\n",
              "std        0.940337    3.621266e+07      0.238020\n",
              "min        1.000000    1.121386e+09      0.000000\n",
              "25%        4.000000    1.354838e+09      1.000000\n",
              "50%        5.000000    1.373414e+09      1.000000\n",
              "75%        5.000000    1.390435e+09      1.000000\n",
              "max        5.000000    1.405901e+09      1.000000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_main.loc[pdf_main['overall'] >= 4, 'sentiment'] = 1\n",
        "pdf_main.loc[pdf_main['overall'] < 3, 'sentiment'] = 0\n",
        "\n",
        "pdf_main.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_datasets(pdf_target_training, label = 'sentiment'):\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(pdf_target_training.drop(label, axis=1), pdf_target_training[label],\n",
        "                                                        stratify=pdf_target_training[label],\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.20)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        "                                                        stratify=y_test_val,\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.5)\n",
        "    pdf_X_train = X_train\n",
        "    pdf_X_val = X_val\n",
        "    pdf_X_test = X_test\n",
        "\n",
        "    pdf_X_train['sentiment'] = y_train\n",
        "    pdf_X_val['sentiment'] = y_val\n",
        "    pdf_X_test['sentiment'] = y_test\n",
        "    \n",
        "    print(f'Total records for: \"pdf_X_train\": [{pdf_X_train.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_val\": [{pdf_X_val.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_test\": [{pdf_X_test.shape[0]}]')\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "    return pdf_X_train, pdf_X_val, pdf_X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records for: \"pdf_X_train\": [15234]\n",
            "Total records for: \"pdf_X_val\": [1904]\n",
            "Total records for: \"pdf_X_test\": [1905]\n"
          ]
        }
      ],
      "source": [
        "pdf_train, pdf_val, pdf_test = generate_datasets(pdf_main[['reviewText', 'sentiment']].dropna(), 'sentiment')\n",
        "\n",
        "pdf_train.to_csv('data/pdf_train.csv')\n",
        "pdf_val.to_csv('data/pdf_val.csv')\n",
        "pdf_test.to_csv('data/pdf_test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# === Note on path ===\n",
        "# can be can be a local path or a cloud path. AzureML supports https://`, `abfss://`, `wasbs://` and `azureml://` URIs.\n",
        "# Local paths are automatically uploaded to the default datastore in the cloud.\n",
        "# More details on supported paths: https://docs.microsoft.com/azure/machine-learning/how-to-read-write-data-v2#supported-paths\n",
        "\n",
        "def gen_input_data(url):\n",
        "    inputs = {\n",
        "        \"input_data\": Input(type=AssetTypes.URI_FILE, path=url)\n",
        "    }\n",
        "\n",
        "    return inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_train = gen_input_data('data/pdf_test.csv')\n",
        "ds_val = gen_input_data('data/pdf_val.csv')\n",
        "ds_test = gen_input_data('data/pdf_test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1668533982929
        }
      },
      "outputs": [],
      "source": [
        "source_directory = \"./project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1668533983332
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting environments/conda_dependencies.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile environments/conda_dependencies.yml\n",
        "\n",
        "channels:\n",
        "  - pytorch\n",
        "  - anaconda\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.7\n",
        "  - pip=21.1.2\n",
        "  - pip:\n",
        "      - azure-ai-ml==1.2.0\n",
        "      - mlflow== 1.26.1\n",
        "      - azureml-mlflow==1.42.0\n",
        "      - nvitop\n",
        "  - numpy~=1.21.6\n",
        "  - pandas~=1.1.5\n",
        "  - shap=0.39.0\n",
        "  - scikit-learn~=0.22.1\n",
        "  - pytorch==1.7.1\n",
        "name: nlp_training_environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "ename": "ResourceNotFoundError",
          "evalue": "(UserError) No environment exists for name: nlp-accelerator-sdk-v2, version: latest_version, label: \nCode: UserError\nMessage: No environment exists for name: nlp-accelerator-sdk-v2, version: latest_version, label: ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f64616338303733652d316332642d346137642d613533622d6333363535653239316435382f7265736f7572636547726f7570732f6c6561726e696e672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6c6561726e696e676d61696e2f636f6d70757465732f686f7361727368613233/home/azureuser/cloudfiles/code/Users/hosarsha/nlp-aml/DefinePipelineV2.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ml_client\u001b[39m.\u001b[39;49menvironments\u001b[39m.\u001b[39;49mget(name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnlp-accelerator-sdk-v2\u001b[39;49m\u001b[39m\"\u001b[39;49m, version\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlatest_version\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:259\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    258\u001b[0m     \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, custom_dimensions):\n\u001b[0;32m--> 259\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_environment_operations.py:232\u001b[0m, in \u001b[0;36mEnvironmentOperations.get\u001b[0;34m(self, name, version, label)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[39mraise\u001b[39;00m ValidationException(\n\u001b[1;32m    225\u001b[0m         message\u001b[39m=\u001b[39mmsg,\n\u001b[1;32m    226\u001b[0m         target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mENVIRONMENT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m         error_type\u001b[39m=\u001b[39mValidationErrorType\u001b[39m.\u001b[39mMISSING_FIELD,\n\u001b[1;32m    230\u001b[0m     )\n\u001b[1;32m    231\u001b[0m name \u001b[39m=\u001b[39m _preprocess_environment_name(name)\n\u001b[0;32m--> 232\u001b[0m env_version_resource \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(name, version)\n\u001b[1;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m Environment\u001b[39m.\u001b[39m_from_rest_object(env_version_resource)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_environment_operations.py:170\u001b[0m, in \u001b[0;36mEnvironmentOperations._get\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m, version: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m EnvironmentVersionData:\n\u001b[1;32m    160\u001b[0m     \u001b[39mif\u001b[39;00m version:\n\u001b[1;32m    161\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    162\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_version_operations\u001b[39m.\u001b[39mget(\n\u001b[1;32m    163\u001b[0m                 name\u001b[39m=\u001b[39mname,\n\u001b[1;32m    164\u001b[0m                 version\u001b[39m=\u001b[39mversion,\n\u001b[1;32m    165\u001b[0m                 registry_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_registry_name,\n\u001b[1;32m    166\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scope_kwargs,\n\u001b[1;32m    167\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs,\n\u001b[1;32m    168\u001b[0m             )\n\u001b[1;32m    169\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_registry_name\n\u001b[0;32m--> 170\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_version_operations\u001b[39m.\u001b[39;49mget(\n\u001b[1;32m    171\u001b[0m                 name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    172\u001b[0m                 version\u001b[39m=\u001b[39;49mversion,\n\u001b[1;32m    173\u001b[0m                 workspace_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_workspace_name,\n\u001b[1;32m    174\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_scope_kwargs,\n\u001b[1;32m    175\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_kwargs,\n\u001b[1;32m    176\u001b[0m             )\n\u001b[1;32m    177\u001b[0m         )\n\u001b[1;32m    178\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    179\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_containers_operations\u001b[39m.\u001b[39mget(\n\u001b[1;32m    180\u001b[0m             name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[1;32m    192\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_versions_operations.py:443\u001b[0m, in \u001b[0;36mEnvironmentVersionsOperations.get\u001b[0;34m(self, resource_group_name, workspace_name, name, version, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m response \u001b[39m=\u001b[39m pipeline_response\u001b[39m.\u001b[39mhttp_response\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m200\u001b[39m]:\n\u001b[0;32m--> 443\u001b[0m     map_error(status_code\u001b[39m=\u001b[39;49mresponse\u001b[39m.\u001b[39;49mstatus_code, response\u001b[39m=\u001b[39;49mresponse, error_map\u001b[39m=\u001b[39;49merror_map)\n\u001b[1;32m    444\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deserialize\u001b[39m.\u001b[39mfailsafe_deserialize(_models\u001b[39m.\u001b[39mErrorResponse, pipeline_response)\n\u001b[1;32m    445\u001b[0m     \u001b[39mraise\u001b[39;00m HttpResponseError(response\u001b[39m=\u001b[39mresponse, model\u001b[39m=\u001b[39merror, error_format\u001b[39m=\u001b[39mARMErrorFormat)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/exceptions.py:107\u001b[0m, in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    106\u001b[0m error \u001b[39m=\u001b[39m error_type(response\u001b[39m=\u001b[39mresponse)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
            "\u001b[0;31mResourceNotFoundError\u001b[0m: (UserError) No environment exists for name: nlp-accelerator-sdk-v2, version: latest_version, label: \nCode: UserError\nMessage: No environment exists for name: nlp-accelerator-sdk-v2, version: latest_version, label: "
          ]
        }
      ],
      "source": [
        "ml_client.environments.get(name=\"nlp-accelerator-sdk-v2\", version=\"latest_version\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Environment({'is_anonymous': False, 'auto_increment_version': False, 'name': 'nlp-accelerator-sdk-v2', 'description': 'This environment is curated to run NLP Transformer based models using AML SDK-v2 and native MLFlow integration', 'tags': {}, 'properties': {}, 'id': '/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourceGroups/Learning/providers/Microsoft.MachineLearningServices/workspaces/learningmain/environments/nlp-accelerator-sdk-v2/versions/3', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/hosarsha23/code/Users/hosarsha/nlp-aml', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f6c52b3d570>, 'serialize': <msrest.serialization.Serializer object at 0x7f6c52b3de70>, 'version': '3', 'latest_version': None, 'conda_file': {'channels': ['pytorch', 'anaconda', 'conda-forge'], 'dependencies': ['python=3.7', 'pip=21.1.2', {'pip': ['azure-ai-ml==1.2.0', 'mlflow== 1.26.1', 'azureml-mlflow==1.42.0', 'nvitop']}, 'numpy~=1.21.6', 'pandas~=1.1.5', 'shap=0.39.0', 'scikit-learn~=0.22.1', 'pytorch==1.7.1'], 'name': 'nlp_training_environment'}, 'image': 'mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu20.04:latest', 'build': None, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"channels\": [\\n    \"pytorch\",\\n    \"anaconda\",\\n    \"conda-forge\"\\n  ],\\n  \"dependencies\": [\\n    \"python=3.7\",\\n    \"pip=21.1.2\",\\n    {\\n      \"pip\": [\\n        \"azure-ai-ml==1.2.0\",\\n        \"mlflow== 1.26.1\",\\n        \"azureml-mlflow==1.42.0\",\\n        \"nvitop\"\\n      ]\\n    },\\n    \"numpy~=1.21.6\",\\n    \"pandas~=1.1.5\",\\n    \"shap=0.39.0\",\\n    \"scikit-learn~=0.22.1\",\\n    \"pytorch==1.7.1\"\\n  ],\\n  \"name\": \"nlp_training_environment\"\\n}'})"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "env_list = list(ml_client.environments.list(name=\"nlp-accelerator-sdk-v2\")) # (name=\"nlp-accelerator-sdk-v2\", version='3')\n",
        "if len(env_list) > 0:\n",
        "    env = env_list[0]\n",
        "else:\n",
        "    env = Environment(\n",
        "        image=\"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu20.04:latest\",\n",
        "        conda_file='environments/conda_dependencies.yml',\n",
        "        name=\"nlp-accelerator-sdk-v2\",\n",
        "        description='This environment is curated to run NLP Transformer based models using AML SDK-v2 and native MLFlow integration'\n",
        "    )\n",
        "\n",
        "    ml_client.environments.create_or_update(env)\n",
        "\n",
        "env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1668533987254
        }
      },
      "outputs": [],
      "source": [
        "cluster_name = \"cpu-cluster\" # \"a100-cluster\"\n",
        "compute_target = ml_client.compute.get(cluster_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1668533987898
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records for: \"pdf_X_train\": [15234]\n",
            "Total records for: \"pdf_X_val\": [1904]\n",
            "Total records for: \"pdf_X_test\": [1905]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8121/1221927861.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  pdf_X_val['sentiment'] = y_val\n",
            "/tmp/ipykernel_8121/1221927861.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  pdf_X_test['sentiment'] = y_test\n"
          ]
        }
      ],
      "source": [
        "pdf_train, pdf_val, pdf_test = generate_datasets(pdf_main[['reviewText', 'sentiment']].dropna(), 'sentiment')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1668533997294
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to nlp/610a98c0-026d-4779-8ef4-9d68119149b6/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to nlp/b1370624-cf1e-4032-ab68-0706dcb4d433/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to nlp/9e9e0881-90a4-4978-a280-30eae16fc993/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ]
        }
      ],
      "source": [
        "def_blob_store = ws.get_default_datastore()\n",
        "\n",
        "ds_train_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_train, target=(def_blob_store, 'nlp'), name=\"train_set\", description=\"Small amazon review for sentiment analysis [train set]\")\n",
        "ds_val_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_val, target=(def_blob_store, 'nlp'), name=\"val_set\", description=\"Small amazon review for sentiment analysis [val set]\")\n",
        "ds_test_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_test, target=(def_blob_store, 'nlp'), name=\"test_set\", description=\"Small amazon review for sentiment analysis [test set]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1668533997479
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:You might see network latency and increased data transfer costs if you chose a cluster in a location different from the location of your workspace\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "args = [\n",
        "        '--target-name', 'sentiment',\n",
        "        '--training-dataset', ds_train_set.as_named_input('train_set'),\n",
        "        '--val-dataset', ds_val_set.as_named_input('val_set'),\n",
        "        '--test-dataset', ds_test_set.as_named_input('test_set'),\n",
        "        '--text-field', 'reviewText',\n",
        "        '--is-test', 1,\n",
        "        '--is-final', 0,\n",
        "        '--is-jump', 0,\n",
        "        '--is-local', 0,\n",
        "        '--evaluation-strategy', \"epoch\",\n",
        "        '--collect-resource-utilization', 1, # \n",
        "        '--resource-utilization-interval', 5.0 # seconds\n",
        "]\n",
        "\n",
        "src = ScriptRunConfig(source_directory=source_directory,\n",
        "                      script='train_transformer.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=env)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1668533997662
        }
      },
      "outputs": [],
      "source": [
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "ps = RandomParameterSampling(\n",
        "    {\n",
        "        # bert-base-cased model could fit into all NC series, but if you're interested in trying larger models, then you need to make sure the VM type can handle the size of the model\n",
        "        '--base-checkpoint': choice(\"bert-base-cased\"), #, \"bert-base-cased\"), # , \"bert-large-cased\", \"microsoft/deberta-v3-small\", \"distilbert-base-uncased\", \"bert-base-uncased\"),\n",
        "        '--batch-size': choice(8),\n",
        "        '--no-epochs': choice(4),\n",
        "        '--learning-rate': choice(5.5e-5, 5e-5, 4.5e-5, 4e-5, 5.5e-5, 6e-5, 3.5e-5, 6.5e-5),\n",
        "        '--warmup-steps': choice(0),\n",
        "        '--weight-decay': choice(0.0),\n",
        "        '--adam-beta1': choice(0.9),\n",
        "        '--adam-beta2': choice(0.999),\n",
        "        '--adam-epsilon': choice(1e-8)\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1668533997847
        }
      },
      "outputs": [],
      "source": [
        "policy = BanditPolicy(evaluation_interval=5, slack_factor=0.1)\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                     hyperparameter_sampling=ps,\n",
        "                                     policy=policy,\n",
        "                                     primary_metric_name='eval_f1_weighted',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs=20,\n",
        "                                     max_concurrent_runs=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "gather": {
          "logged": 1668533998029
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n",
        "\n",
        "hd_step_name='HyperDrive_Step'\n",
        "hd_step = HyperDriveStep(\n",
        "    name=hd_step_name,\n",
        "    hyperdrive_config=hyperdrive_config,\n",
        "    allow_reuse=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1668533998282
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cpu_compute = ComputeTarget(workspace=ws, name=\"cpu-cluster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1668533998607
        }
      },
      "outputs": [],
      "source": [
        "env_cpu = Environment.get(workspace=ws, name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\")\n",
        "base_env = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN-Text-GPU\")\n",
        "env = base_env.clone(\"nlp-accelerator\")\n",
        "\n",
        "conda_dep = env.python.conda_dependencies\n",
        "conda_dep.add_pip_package('nvitop')\n",
        "\n",
        "env.python.conda_dependencies = conda_dep\n",
        "\n",
        "env.register(ws)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1668533998809
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--is-test', 0,\n",
        "                                                  '--test-run-id', '',\n",
        "                                                  '--metric-name', 'test_f1_weighted',\n",
        "                                                  '--second-metric', 'test_f1',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "# register_model_step.run_after(hd_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "gather": {
          "logged": 1668533998980
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "\n",
        "rcfg = RunConfiguration() # conda_dependencies=conda_dep)\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--endpoint-name', 'sentiment-endpoint-2',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "deploy_model_step.run_after(register_model_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1668534003413
        }
      },
      "outputs": [],
      "source": [
        "exp = Experiment(workspace=ws, name='transformer_hp')\n",
        "steps = [deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "gather": {
          "logged": 1668534009254
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created step Deploy_Latest_Model [29041d0f][86b676f8-33ab-4ef0-933f-cce4a7f83404], (This step will run and generate new outputs)Created step Register_Best_Model [ef3c94c2][acbc100f-c4b1-4791-94ef-821844982d35], (This step will run and generate new outputs)\n",
            "\n",
            "Submitted PipelineRun ffd4451b-385b-4959-abcc-9c2cf408d66d\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/ffd4451b-385b-4959-abcc-9c2cf408d66d?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/learning/workspaces/learningmain&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>transformer_hp</td><td>ffd4451b-385b-4959-abcc-9c2cf408d66d</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/ffd4451b-385b-4959-abcc-9c2cf408d66d?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/learning/workspaces/learningmain&amp;tid=16b3c013-d300-468d-ac64-7eda0820b6d3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: transformer_hp,\n",
              "Id: ffd4451b-385b-4959-abcc-9c2cf408d66d,\n",
              "Type: azureml.PipelineRun,\n",
              "Status: Preparing)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.submit(exp.name) # , credential_passthrough=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668534009820
        }
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "timenow = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "\n",
        "pipeline_name = f\"Sentiment-Classifier-{timenow}-Pipeline\"\n",
        "print(pipeline_name)\n",
        "\n",
        "# published_pipeline = pipeline.publish(\n",
        "#     name=pipeline_name, \n",
        "#     description=pipeline_name)\n",
        "# print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "azureml_py310_sdkv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
