{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End-to-End Text Classification Pipeline using AzureML V1 and Transformers\n",
        "\n",
        "## Utilizing HyperDrive, AutoML and Managed Online Endpoint for Effective Model Training and Deployment\n",
        "\n",
        "This code base demonstrates an end-to-end machine learning process using AzureML. It starts by setting up the necessary AzureML workspace and compute resources, configuring the environment, and preparing the data by downloading it from a URL, parsing the JSON, and creating a Pandas DataFrame. The data is then split into train, validation, and test sets and registered as datasets in the AzureML workspace. The script then creates a pipeline consisting of a HyperDriveStep for hyperparameter tuning, an AutoMLStep for model selection, and several PythonScriptSteps for testing, registering, and deploying the best model as a web service.\n",
        "\n",
        "The pipeline leverages AzureML's HyperDrive for hyperparameter tuning, using random parameter sampling and a BanditPolicy for early termination. It also employs AzureML's AutoML to automatically select the best model based on the specified primary metric, taking advantage of the platform's built-in algorithms and feature engineering capabilities. The pipeline is then executed, and the results are stored in an AzureML experiment, which allows for easy tracking and comparison of different runs.\n",
        "\n",
        "In summary, this code base provides a comprehensive example of using AzureML to automate the machine learning process, from data preparation to model deployment. It showcases the powerful capabilities of the platform, such as HyperDrive for hyperparameter tuning and AutoML for model selection, and enables seamless integration of various pipeline steps, making it easy to adapt and extend for different use cases."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting up the Azure ML environment and importing necessary libraries\n",
        "\n",
        "The first code block imports the necessary libraries and prints the AzureML SDK version. The second code block retrieves the AzureML workspace information and prints its name, resource group, location, and subscription ID. The third code block retrieves the default datastore for the workspace and prints its name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674553599400
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.core.runconfig import JarLibrary\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.core.databricks import PyPiLibrary\n",
        "\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import DatabricksStep, PythonScriptStep\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674553600494
        }
      },
      "outputs": [],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674553600814
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\n",
        "\n",
        "def_blob_store = ws.get_default_datastore()\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674553601246
        }
      },
      "outputs": [],
      "source": [
        "source_directory = \"./src_v1\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configuring the compute target and creating an environment\n",
        "The code below checks if the specified compute target exists and retrieves it. It also clones the base environment and adds a required pip package to it. If the environment already exists, it is fetched from the workspace. The code block initializes a GPU-based compute target named \"gpu-cluster\" to be used for running the training and hyperparameter tuning jobs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674553601749
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"gpu-cluster\"\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Environment Setup:\n",
        "The code block sets up an environment for the compute target, cloning the existing environment \"AzureML-AutoML-DNN-Text-GPU\" and adding the \"nvitop\" package to the conda dependencies. The environment is then registered with the workspace.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674553602067
        }
      },
      "outputs": [],
      "source": [
        "# %%writefile conda_dependencies.yml\n",
        "# \n",
        "# channels:\n",
        "#   - pytorch\n",
        "#   - anaconda\n",
        "#   - conda-forge\n",
        "# dependencies:\n",
        "#   - python=3.7\n",
        "#   - pip=21.1.2\n",
        "#   - pip:\n",
        "#       - azureml-core==1.44.0\n",
        "#       - azureml-mlflow==1.44.0\n",
        "#       - azureml-automl-core==1.44.0\n",
        "#       - azureml-automl-dnn-nlp==1.44.0\n",
        "#       - azureml-responsibleai==1.44.0\n",
        "#       - azureml-automl-runtime==1.44.0\n",
        "#       - azureml-train-automl-client==1.44.0\n",
        "#       - azureml-train-automl-runtime==1.44.0\n",
        "#       - horovod==0.21.3\n",
        "#   - numpy~=1.18.5\n",
        "#   - pandas~=1.1.5\n",
        "#   - scikit-learn~=0.22.1\n",
        "#   - pytorch==1.7.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674553602393
        }
      },
      "outputs": [],
      "source": [
        "if 'nlp-accelerator' not in ws.environments:\n",
        "    base_env = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN-Text-GPU\")\n",
        "    env = base_env.clone(\"nlp-accelerator\")\n",
        "\n",
        "    conda_dep = env.python.conda_dependencies\n",
        "    conda_dep.add_pip_package('nvitop')\n",
        "\n",
        "    env.python.conda_dependencies = conda_dep\n",
        "\n",
        "    env.register(ws)\n",
        "else:\n",
        "    env = Environment.get(workspace=ws, name=\"nlp-accelerator\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674553602706
        }
      },
      "outputs": [],
      "source": [
        "# to get larger datasets: http://jmcauley.ucsd.edu/data/amazon/"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing the Amazon review dataset\n",
        "The code in this section downloads the Amazon review dataset, processes it to add a sentiment column, and generates training, validation, and test sets. The resulting dataframes are registered as Azure ML datasets. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz -P data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086238720
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "pdf_main = getDF('data/reviews_Automotive_5.json.gz')\n",
        "pdf_main.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086238929
        }
      },
      "outputs": [],
      "source": [
        "pdf_main.loc[pdf_main['overall'] >= 4, 'sentiment'] = 1\n",
        "pdf_main.loc[pdf_main['overall'] < 3, 'sentiment'] = 0\n",
        "\n",
        "pdf_main.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086239108
        }
      },
      "outputs": [],
      "source": [
        "def generate_datasets(pdf_target_training, label = 'sentiment'):\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(pdf_target_training.drop(label, axis=1), pdf_target_training[label],\n",
        "                                                        stratify=pdf_target_training[label],\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.20)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        "                                                        stratify=y_test_val,\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.5)\n",
        "    pdf_X_train = X_train\n",
        "    pdf_X_val = X_val\n",
        "    pdf_X_test = X_test\n",
        "\n",
        "    pdf_X_train['sentiment'] = y_train\n",
        "    pdf_X_val['sentiment'] = y_val\n",
        "    pdf_X_test['sentiment'] = y_test\n",
        "    \n",
        "    print(f'Total records for: \"pdf_X_train\": [{pdf_X_train.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_val\": [{pdf_X_val.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_test\": [{pdf_X_test.shape[0]}]')\n",
        "    \n",
        "    return pdf_X_train, pdf_X_val, pdf_X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086239386
        }
      },
      "outputs": [],
      "source": [
        "pdf_train, pdf_val, pdf_test = generate_datasets(pdf_main[['reviewText', 'sentiment']].dropna(), 'sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086240878
        }
      },
      "outputs": [],
      "source": [
        "def_blob_store = ws.get_default_datastore()\n",
        "\n",
        "ds_train_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_train, target=(def_blob_store, 'nlp'), name=\"train_set\", description=\"Small amazon review for sentiment analysis [train set]\")\n",
        "ds_val_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_val, target=(def_blob_store, 'nlp'), name=\"val_set\", description=\"Small amazon review for sentiment analysis [val set]\")\n",
        "ds_test_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_test, target=(def_blob_store, 'nlp'), name=\"test_set\", description=\"Small amazon review for sentiment analysis [test set]\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ScriptRunConfig and HyperDrive Setup:\n",
        "The code block defines the arguments for the ScriptRunConfig and creates a ScriptRunConfig object. It sets up a random parameter sampling space for HyperDrive and creates a BanditPolicy for early termination. It also configures the HyperDrive step with the specified run configuration, hyperparameter sampling, policy, and primary metric.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086241039
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "args = [\n",
        "        '--target-name', 'sentiment',\n",
        "        '--training-dataset', ds_train_set.as_named_input('train_set'),\n",
        "        '--val-dataset', ds_val_set.as_named_input('val_set'),\n",
        "        '--test-dataset', ds_test_set.as_named_input('test_set'),\n",
        "        '--text-field', 'reviewText',\n",
        "        '--is-test', 1,\n",
        "        '--is-final', 0,\n",
        "        '--is-jump', 0,\n",
        "        '--is-local', 0,\n",
        "        '--evaluation-strategy', \"epoch\",\n",
        "        '--collect-resource-utilization', 1, # \n",
        "        '--resource-utilization-interval', 5.0 # seconds\n",
        "]\n",
        "\n",
        "src = ScriptRunConfig(source_directory=source_directory,\n",
        "                      script='train_transformer.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=env)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This block defines the hyperparameter search space and sampling method for the HyperDrive step using RandomParameterSampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086241211
        }
      },
      "outputs": [],
      "source": [
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "ps = RandomParameterSampling(\n",
        "    {\n",
        "        # bert-base-cased model could fit into all NC series, but if you're interested in trying larger models, then you need to make sure the VM type can handle the size of the model\n",
        "        '--base-checkpoint': choice(\"bert-base-cased\"), #, \"bert-base-cased\"), # , \"bert-large-cased\", \"microsoft/deberta-v3-small\", \"distilbert-base-uncased\", \"bert-base-uncased\"),\n",
        "        '--batch-size': choice(8),\n",
        "        '--no-epochs': choice(4),\n",
        "        '--learning-rate': choice(5.5e-5, 5e-5, 4.5e-5, 4e-5, 5.5e-5, 6e-5, 3.5e-5, 6.5e-5),\n",
        "        '--warmup-steps': choice(0),\n",
        "        '--weight-decay': choice(0.0),\n",
        "        '--adam-beta1': choice(0.9),\n",
        "        '--adam-beta2': choice(0.999),\n",
        "        '--adam-epsilon': choice(1e-8)\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086241397
        }
      },
      "outputs": [],
      "source": [
        "policy = BanditPolicy(evaluation_interval=5, slack_factor=0.1)\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                     hyperparameter_sampling=ps,\n",
        "                                     policy=policy,\n",
        "                                     primary_metric_name='test_AUC_weighted',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs=20,\n",
        "                                     max_concurrent_runs=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086241572
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n",
        "\n",
        "hd_step_name='HyperDrive_Step'\n",
        "hd_step = HyperDriveStep(\n",
        "    name=hd_step_name,\n",
        "    hyperdrive_config=hyperdrive_config,\n",
        "    allow_reuse=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding AutoML step to the pipeline\n",
        "In this part, we set up an AutoML step to find the best model automatically. We use AUC_weighted as the primary metric and configure other AutoML settings. This step will run after the HyperDrive step in the pipeline. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086241747
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import TrainingOutput, PipelineData\n",
        "\n",
        "metrics_data = PipelineData(name='metrics_data',\n",
        "                            datastore=def_blob_store,\n",
        "                            pipeline_output_name='metrics_output',\n",
        "                            training_output=TrainingOutput(type='Metrics'))\n",
        "\n",
        "model_data = PipelineData(name='best_model_data',\n",
        "                          datastore=def_blob_store,\n",
        "                          pipeline_output_name='model_output',\n",
        "                          training_output=TrainingOutput(type='Model'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086241932
        }
      },
      "outputs": [],
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "automl_settings = {\n",
        "    \"verbosity\": logging.INFO,\n",
        "    \"experiment_timeout_minutes\": 240,\n",
        "    \"primary_metric\": \"AUC_weighted\",\n",
        "    \"enable_early_stopping\" : \"true\",\n",
        "    #\"save_mlflow\": \"true\",\n",
        "    \"send_telemetry\" : \"true\",\n",
        "    \"many_models\": True\n",
        "}\n",
        "\n",
        "target_column_name = \"sentiment\"\n",
        "\n",
        "automl_config = AutoMLConfig(\n",
        "    task=\"text-classification\",\n",
        "    debug_log=\"automl_errors.log\",\n",
        "    compute_target=compute_target,\n",
        "    training_data=ds_train_set ,\n",
        "    validation_data=ds_val_set ,\n",
        "    featurization = 'auto',\n",
        "    label_column_name=target_column_name,\n",
        "#    blocked_models=[\"TensorFlowDNN\", \"TensorFlowLinearRegressor\"],\n",
        "    **automl_settings\n",
        ")\n",
        "\n",
        "\n",
        "automl_step = AutoMLStep(name='AutoML_Classification',\n",
        "    automl_config=automl_config,\n",
        "    passthru_automl_config=False,\n",
        "    outputs=[metrics_data,model_data],\n",
        "    enable_default_model_output=False,\n",
        "    enable_default_metrics_output=False,\n",
        "    allow_reuse=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline Steps:\n",
        "The code block creates a HyperDriveStep in the pipeline and sets up the PipelineData objects for metrics and the best model to be used in the AutoML step. It sets up the AutoML configuration and creates an AutoMLStep in the pipeline. It sets up the compute target and environment for the CPU-based compute cluster, which will be used in the testing step. It creates a PythonScriptStep for testing the best model from the AutoML step, and another PythonScriptStep for registering the best model. The pipeline also includes a PythonScriptStep for deploying the best model as a web service.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086242358
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cpu_compute = ComputeTarget(workspace=ws, name=\"cpu-cluster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086242632
        }
      },
      "outputs": [],
      "source": [
        "env_cpu = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN\") # libraries needed for testing automl best model as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086242119
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env\n",
        "\n",
        "test_model_step = PythonScriptStep(script_name='test_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Test_AutoML_Best_Model\",\n",
        "                                       compute_target=compute_target,\n",
        "                                       arguments=[\n",
        "                                                  '--metric-name', 'AUC_weighted',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--text-field-name', 'reviewText',\n",
        "                                                  '--test_dataset', ds_test_set.as_named_input('test_dataset'),\n",
        "                                                  '--model-data', model_data\n",
        "                                                 \n",
        "                                                 ],\n",
        "                                       inputs=[ model_data],          \n",
        "                                       allow_reuse=False,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "\n",
        "\n",
        "test_model_step.run_after(automl_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086242808
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--is-test', 0,\n",
        "                                                  '--test-run-id', '',\n",
        "                                                  '--metric-name', 'test_AUC_weighted',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--model-name', 'sentiment_classifier',\n",
        "                                                \n",
        "                                                  ],\n",
        "                                             \n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "\n",
        "\n",
        "register_model_step.run_after(test_model_step)\n",
        "register_model_step.run_after(hd_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086242976
        }
      },
      "outputs": [],
      "source": [
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--endpoint-name', 'sentiment-endpoint-2',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "deploy_model_step.run_after(register_model_step)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline Creation and Submission:\n",
        "The code block creates an AzureML experiment and initializes a pipeline with the defined steps. The pipeline is submitted for execution, and the results are stored in the experiment. The pipeline is then published with a unique name and description.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086243228
        }
      },
      "outputs": [],
      "source": [
        "exp = Experiment(workspace=ws, name='transformer_hp')\n",
        "steps = [deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086254277
        }
      },
      "outputs": [],
      "source": [
        "pipeline.submit(exp.name) #, credential_passthrough=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674086254839
        }
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "timenow = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "\n",
        "pipeline_name = f\"Sentiment-Classifier-{timenow}-Pipeline\"\n",
        "print(pipeline_name)\n",
        "\n",
        "published_pipeline = pipeline.publish(\n",
        "    name=pipeline_name, \n",
        "    description=pipeline_name)\n",
        "print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
