{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "gather": {
          "logged": 1668792464585
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SDK version: 1.48.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.core.runconfig import JarLibrary\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.core.databricks import PyPiLibrary\n",
        "\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import  PythonScriptStep\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION) \n",
        "\n",
        "# Based on \n",
        "# https://learn.microsoft.com/en-us/azure/machine-learning/v1/how-to-use-automlstep-in-pipelines\n",
        "# https://github.com/Azure/azureml-examples/blob/main/v1/python-sdk/tutorials/automl-with-azureml/regression/auto-ml-regression.ipynb\n",
        "# https://github.com/Azure/azureml-examples/blob/main/v1/python-sdk/tutorials/automl-with-azureml/automl-nlp-multiclass/automl-nlp-text-classification-multiclass.ipynb\n",
        "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-with-automated-machine-learning-step.ipynb "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "gather": {
          "logged": 1668792465393
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nlp-workspace\n",
            "openaml\n",
            "eastus2\n",
            "f9b97038-ed78-4a26-a1a7-51e81e75d867\n"
          ]
        }
      ],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "gather": {
          "logged": 1668792465609
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datastore workspaceblobstore will be used\n"
          ]
        }
      ],
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\n",
        "\n",
        "def_blob_store = ws.get_default_datastore()\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "gather": {
          "logged": 1668792465791
        }
      },
      "outputs": [],
      "source": [
        "source_directory = \"./project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "gather": {
          "logged": 1668792466336
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"gpu-cluster\"\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1668792466578
        }
      },
      "outputs": [],
      "source": [
        "# %%writefile conda_dependencies.yml\n",
        "# \n",
        "# channels:\n",
        "#   - pytorch\n",
        "#   - anaconda\n",
        "#   - conda-forge\n",
        "# dependencies:\n",
        "#   - python=3.7\n",
        "#   - pip=21.1.2\n",
        "#   - pip:\n",
        "#       - azureml-core==1.44.0\n",
        "#       - azureml-mlflow==1.44.0\n",
        "#       - azureml-automl-core==1.44.0\n",
        "#       - azureml-automl-dnn-nlp==1.44.0\n",
        "#       - azureml-responsibleai==1.44.0\n",
        "#       - azureml-automl-runtime==1.44.0\n",
        "#       - azureml-train-automl-client==1.44.0\n",
        "#       - azureml-train-automl-runtime==1.44.0\n",
        "#       - horovod==0.21.3\n",
        "#   - numpy~=1.18.5\n",
        "#   - pandas~=1.1.5\n",
        "#   - scikit-learn~=0.22.1\n",
        "#   - pytorch==1.7.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "gather": {
          "logged": 1668792466747
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "got env Environment(Name: nlp-accelerator,\n",
            "Version: 3)\n"
          ]
        }
      ],
      "source": [
        "if 'nlp-accelerator' not in ws.environments:\n",
        "    base_env = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN-Text-GPU\")\n",
        "    env = base_env.clone(\"nlp-accelerator\")\n",
        "\n",
        "    conda_dep = env.python.conda_dependencies\n",
        "    conda_dep.add_pip_package('nvitop')\n",
        "    conda_dep.add_pip_package('azureml-train-automl==1.48.0')\n",
        "\n",
        "\n",
        "    env.python.conda_dependencies = conda_dep\n",
        "\n",
        "    env.register(ws)\n",
        "    print(f'registering new env {env}')\n",
        "    \n",
        "else:\n",
        "    env = Environment.get(workspace=ws, name=\"nlp-accelerator\")\n",
        "    print(f'got env {env}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "gather": {
          "logged": 1668792466905
        }
      },
      "outputs": [],
      "source": [
        "# to get larger datasets: http://jmcauley.ucsd.edu/data/amazon/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-24 06:08:55--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4669048 (4.5M) [application/x-gzip]\n",
            "Saving to: ‘data/reviews_Automotive_5.json.gz.81’\n",
            "\n",
            "reviews_Automotive_ 100%[===================>]   4.45M  2.18MB/s    in 2.0s    \n",
            "\n",
            "2023-01-24 06:08:57 (2.18 MB/s) - ‘data/reviews_Automotive_5.json.gz.81’ saved [4669048/4669048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz -P data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "gather": {
          "logged": 1668792469751
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20473, 9)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "pdf_main = getDF('data/reviews_Automotive_5.json.gz')\n",
        "pdf_main.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "gather": {
          "logged": 1668792469984
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A3F73SC1LY51OO</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>Alan Montgomery</td>\n",
              "      <td>[4, 4]</td>\n",
              "      <td>I needed a set of jumper cables for my new car...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Work Well - Should Have Bought Longer Ones</td>\n",
              "      <td>1313539200</td>\n",
              "      <td>08 17, 2011</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A20S66SKYXULG2</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>alphonse</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>These long cables work fine for my truck, but ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Okay long cables</td>\n",
              "      <td>1315094400</td>\n",
              "      <td>09 4, 2011</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2I8LFSN2IS5EO</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>Chris</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>Can't comment much on these since they have no...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Looks and feels heavy Duty</td>\n",
              "      <td>1374710400</td>\n",
              "      <td>07 25, 2013</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3GT2EWQSO45ZG</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>DeusEx</td>\n",
              "      <td>[19, 19]</td>\n",
              "      <td>I absolutley love Amazon!!!  For the price of ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Excellent choice for Jumper Cables!!!</td>\n",
              "      <td>1292889600</td>\n",
              "      <td>12 21, 2010</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A3ESWJPAVRPWB4</td>\n",
              "      <td>B00002243X</td>\n",
              "      <td>E. Hernandez</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>I purchased the 12' feet long cable set and th...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Excellent, High Quality Starter Cables</td>\n",
              "      <td>1341360000</td>\n",
              "      <td>07 4, 2012</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID        asin     reviewerName   helpful  \\\n",
              "0  A3F73SC1LY51OO  B00002243X  Alan Montgomery    [4, 4]   \n",
              "1  A20S66SKYXULG2  B00002243X         alphonse    [1, 1]   \n",
              "2  A2I8LFSN2IS5EO  B00002243X            Chris    [0, 0]   \n",
              "3  A3GT2EWQSO45ZG  B00002243X           DeusEx  [19, 19]   \n",
              "4  A3ESWJPAVRPWB4  B00002243X     E. Hernandez    [0, 0]   \n",
              "\n",
              "                                          reviewText  overall  \\\n",
              "0  I needed a set of jumper cables for my new car...      5.0   \n",
              "1  These long cables work fine for my truck, but ...      4.0   \n",
              "2  Can't comment much on these since they have no...      5.0   \n",
              "3  I absolutley love Amazon!!!  For the price of ...      5.0   \n",
              "4  I purchased the 12' feet long cable set and th...      5.0   \n",
              "\n",
              "                                      summary  unixReviewTime   reviewTime  \\\n",
              "0  Work Well - Should Have Bought Longer Ones      1313539200  08 17, 2011   \n",
              "1                            Okay long cables      1315094400   09 4, 2011   \n",
              "2                  Looks and feels heavy Duty      1374710400  07 25, 2013   \n",
              "3       Excellent choice for Jumper Cables!!!      1292889600  12 21, 2010   \n",
              "4      Excellent, High Quality Starter Cables      1341360000   07 4, 2012   \n",
              "\n",
              "   sentiment  \n",
              "0        1.0  \n",
              "1        1.0  \n",
              "2        1.0  \n",
              "3        1.0  \n",
              "4        1.0  "
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_main.loc[pdf_main['overall'] >= 4, 'sentiment'] = 1\n",
        "pdf_main.loc[pdf_main['overall'] < 3, 'sentiment'] = 0\n",
        "\n",
        "pdf_main.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "gather": {
          "logged": 1668792470148
        }
      },
      "outputs": [],
      "source": [
        "def generate_datasets(pdf_target_training, label = 'sentiment'):\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(pdf_target_training.drop(label, axis=1), pdf_target_training[label],\n",
        "                                                        stratify=pdf_target_training[label],\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.20)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        "                                                        stratify=y_test_val,\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.5)\n",
        "    pdf_X_train = X_train\n",
        "    pdf_X_val = X_val\n",
        "    pdf_X_test = X_test\n",
        "\n",
        "    pdf_X_train['sentiment'] = y_train\n",
        "    pdf_X_val['sentiment'] = y_val\n",
        "    pdf_X_test['sentiment'] = y_test\n",
        "    \n",
        "    print(f'Total records for: \"pdf_X_train\": [{pdf_X_train.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_val\": [{pdf_X_val.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_test\": [{pdf_X_test.shape[0]}]')\n",
        "    \n",
        "    return pdf_X_train, pdf_X_val, pdf_X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "gather": {
          "logged": 1668792470320
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records for: \"pdf_X_train\": [15234]\n",
            "Total records for: \"pdf_X_val\": [1904]\n",
            "Total records for: \"pdf_X_test\": [1905]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_82053/595391838.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  pdf_X_val['sentiment'] = y_val\n",
            "/tmp/ipykernel_82053/595391838.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  pdf_X_test['sentiment'] = y_test\n"
          ]
        }
      ],
      "source": [
        "pdf_train, pdf_val, pdf_test = generate_datasets(pdf_main[['reviewText', 'sentiment']].dropna(), 'sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "gather": {
          "logged": 1668792477981
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to nlp/247f6522-e5c4-4da7-b0a9-e3fedd0cf0f4/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Successfully created and registered a new dataset.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to nlp/7bc0f143-940b-42ca-bb18-26be7aeafe78/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to nlp/ee96c4df-7310-4315-8ae8-a3ffd5f27577/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ]
        }
      ],
      "source": [
        "def_blob_store = ws.get_default_datastore()\n",
        "\n",
        "ds_train_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_train, target=(def_blob_store, 'nlp'), name=\"train_set\", description=\"Small amazon review for sentiment analysis [train set]\")\n",
        "ds_val_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_val, target=(def_blob_store, 'nlp'), name=\"val_set\", description=\"Small amazon review for sentiment analysis [val set]\")\n",
        "ds_test_set = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_test, target=(def_blob_store, 'nlp'), name=\"test_set\", description=\"Small amazon review for sentiment analysis [test set]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add AutoML Step \n",
        "Compare results from AutoML steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import TrainingOutput, PipelineData\n",
        "\n",
        "metrics_data = PipelineData(name='automl_metrics_data',\n",
        "                            datastore=def_blob_store,\n",
        "                            pipeline_output_name='metrics_output',\n",
        "                            training_output=TrainingOutput(type='Metrics'))\n",
        "\n",
        "model_data = PipelineData(name='automl_best_model_data',\n",
        "                          datastore=def_blob_store,\n",
        "                          pipeline_output_name='model_output',\n",
        "                          training_output=TrainingOutput(type='Model'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AutoML Parameters\n",
        "\n",
        "\n",
        "```json\n",
        "{ \n",
        "    \"experiment_timeout_minutes\": 120,\n",
        "    \"primary_metric\": \"accuracy\",\n",
        "    \"primary_metric\" : \"AUC_weighted\",\n",
        "    \"iteration_timeout_minutes\" : 10,\n",
        "    \"iterations\" : 20,\n",
        "    \"experiment_timeout_hours\" : 1,\n",
        "    \"max_concurrent_iterations\": 1,\n",
        "    \"max_cores_per_iteration\": -1,\n",
        "    \"enable_early_stopping\": \"True\",\n",
        "    \"enable_dnn\": \"True\",\n",
        "    \"blacklist_algos\":[\"TensorFlowDNN\",\"TensorFlowLinearRegressor\"],\n",
        "    \"max_concurrent_iterations\": 1,\n",
        "    \"enable_batch_run\":\"False\",\n",
        "    \"enable_dnn\": \"true\",\n",
        "     \"model_explainability\" : \"True\"\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "automl_settings = {\n",
        "    \"verbosity\": logging.INFO,\n",
        "    \"experiment_timeout_minutes\": 240,\n",
        "    \"primary_metric\": \"AUC_weighted\",\n",
        "    \"enable_early_stopping\" : \"true\",\n",
        "    #\"ensemble_iterations\" : 3,\n",
        "    #\"enable_stack_ensembling\" : \"true\",\n",
        "    #\"enable_ensembling\" : \"true\",\n",
        "    #\"save_mlflow\": \"true\",\n",
        "    #\"max_cores_per_iteration\": -1,\n",
        "    #\"max_concurrent_iterations\": 3,\n",
        "    \"send_telemetry\" : \"true\",\n",
        "    #\"experiment_timeout_minutes\": 1440,\n",
        "    #\"iteration_timeout_minutes\": 1440,\n",
        "    \"many_models\": True,\n",
        "    #\"pipeline_fetch_max_batch_size\": 15,\n",
        "    #\"iteration_timeout_minutes\" : 30,\n",
        "    #\"iterations\" : 5 \n",
        "}\n",
        "\n",
        "target_column_name = \"sentiment\"\n",
        "\n",
        "automl_config = AutoMLConfig(\n",
        "    task=\"text-classification\",\n",
        "    debug_log=\"automl_errors.log\",\n",
        "    compute_target=compute_target,\n",
        "    training_data=ds_train_set ,\n",
        "    validation_data=ds_val_set ,\n",
        "    featurization = 'auto',\n",
        "    label_column_name=target_column_name,\n",
        "#    blocked_models=[\"TensorFlowDNN\", \"TensorFlowLinearRegressor\"],\n",
        "    **automl_settings\n",
        ")\n",
        "\n",
        "\n",
        "automl_step = AutoMLStep(name='AutoML_Classification',\n",
        "    automl_config=automl_config,\n",
        "    passthru_automl_config=False,\n",
        "    outputs=[metrics_data,model_data],\n",
        "    enable_default_model_output=False,\n",
        "    enable_default_metrics_output=False,\n",
        "    allow_reuse=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "gather": {
          "logged": 1668792478737
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cpu_compute = ComputeTarget(workspace=ws, name=\"cpu-cluster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "gather": {
          "logged": 1668792478887
        }
      },
      "outputs": [],
      "source": [
        "env_cpu = Environment.get(workspace=ws, name=\"AzureML-AutoML-DNN\") #name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env\n",
        "\n",
        "test_model_step = PythonScriptStep(script_name='test_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Test_AutoML_Best_Model\",\n",
        "                                       compute_target=compute_target,\n",
        "                                       arguments=[\n",
        "                                                  '--metric-name', 'AUC_weighted',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--text-field-name', 'reviewText',\n",
        "                                                  '--test_dataset', ds_test_set.as_named_input('test_dataset'),\n",
        "                                                  '--model-data', model_data\n",
        "                                                 \n",
        "                                                 ],\n",
        "                                       inputs=[ model_data],          \n",
        "                                       allow_reuse=False,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "\n",
        "\n",
        "test_model_step.run_after(automl_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "gather": {
          "logged": 1668792479034
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--is-test', 0,\n",
        "                                                  '--test-run-id', '',\n",
        "                                                  '--metric-name', 'test_AUC_weighted',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--model-name', 'sentiment_classifier',\n",
        "                                                \n",
        "                                                  ],\n",
        "                                             \n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "\n",
        "\n",
        "register_model_step.run_after(test_model_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--endpoint-name', 'sentiment-endpoint-2',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "deploy_model_step.run_after(register_model_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "gather": {
          "logged": 1668792480981
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:azureml._base_sdk_common._docstring_wrapper:Class KubernetesCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
          ]
        }
      ],
      "source": [
        "exp = Experiment(workspace=ws, name='transformer_automl')\n",
        "steps = [deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "gather": {
          "logged": 1668792486889
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created step Deploy_Latest_Model [7037a9b9][1605d197-56a3-4234-8452-732254c35bb5], (This step will run and generate new outputs)\n",
            "Created step Register_Best_Model [11a58ddd][62cdbfeb-387f-4b8b-b689-18867e43379f], (This step is eligible to reuse a previous run's output)\n",
            "Created step AutoML_Classification [c625ee21][6218ec49-b1d1-4bf0-8702-947659cdfee9], (This step will run and generate new outputs)\n",
            "Created step Test_AutoML_Best_Model [e7114312][7fb2a3ae-0427-48f9-93c0-07f81b792233], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun 5cefd160-80db-4f7c-a314-8f24fbbaed25\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/5cefd160-80db-4f7c-a314-8f24fbbaed25?wsid=/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourcegroups/openaml/workspaces/nlp-workspace&tid=4460d6c7-3cdd-4d85-bda4-87c85c98af04\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>transformer_automl</td><td>5cefd160-80db-4f7c-a314-8f24fbbaed25</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/5cefd160-80db-4f7c-a314-8f24fbbaed25?wsid=/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourcegroups/openaml/workspaces/nlp-workspace&amp;tid=4460d6c7-3cdd-4d85-bda4-87c85c98af04\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: transformer_automl,\n",
              "Id: 5cefd160-80db-4f7c-a314-8f24fbbaed25,\n",
              "Type: azureml.PipelineRun,\n",
              "Status: Preparing)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.submit(exp.name) #, credential_passthrough=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "gather": {
          "logged": 1668792488233
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment-Classifier-2023-01-24-06-09-Pipeline\n",
            "Newly published pipeline id: 1fc79a99-bdac-406e-804b-8301cc6532a4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n",
            "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\n",
            "Getting data access token with Assigned Identity (client_id=027830ec-9e17-4601-ba77-d1f7524c9599) and endpoint type based on configuration\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "timenow = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "\n",
        "pipeline_name = f\"Sentiment-Classifier-{timenow}-Pipeline\"\n",
        "print(pipeline_name)\n",
        "\n",
        "published_pipeline = pipeline.publish(\n",
        "    name=pipeline_name, \n",
        "    description=pipeline_name)\n",
        "print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
